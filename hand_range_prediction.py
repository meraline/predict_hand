"""
hand_range_prediction.py - –ú–æ–¥–µ–ª—å RWKV –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä—É–∫ –≤ –ø–æ–∫–µ—Ä–µ
"""

import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import pickle
import json
import glob
from datetime import datetime


def safe_json_serialize(obj):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–ª—è JSON"""
    import numpy as np

    if isinstance(obj, (np.integer, np.int64, np.int32, np.int16, np.int8)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32, np.float16)):
        return float(obj)
    elif isinstance(obj, (np.bool_, np.bool8)):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: safe_json_serialize(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [safe_json_serialize(item) for item in obj]
    else:
        return obj


import itertools
from collections import Counter


class PokerHandEvaluator:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ä—É–∫–∏ –∏–∑ 73 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π HM3"""

    RANK_VALUES = {
        "2": 2,
        "3": 3,
        "4": 4,
        "5": 5,
        "6": 6,
        "7": 7,
        "8": 8,
        "9": 9,
        "T": 10,
        "J": 11,
        "Q": 12,
        "K": 13,
        "A": 14,
    }

    SUIT_MAP = {"s": 0, "h": 1, "d": 2, "c": 3}

    def __init__(self):
        self.hand_type_to_strength = self._create_strength_mapping()

    def _create_strength_mapping(self):
        """–°–æ–∑–¥–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ —Ä—É–∫ –≤ 5 –∫–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã"""
        return {
            # –ö–ª–∞—Å—Å 4: –ú–û–ù–°–¢–†–´
            "TwoCardStraightFlush": 4,
            "OneCardStraightFlush": 4,
            "FourOfAKindWithPocketPair": 4,
            "FourOfAKindWithoutPocketPair": 4,
            "FourOfAKindOnBoard": 4,
            "OneCardFullHouseTopPair": 4,
            "OneCardFullHouseTripsOnBoard": 4,
            "FullHouseWithPocketPairNoTripsOnBoard": 4,
            "TwoCardFullHouseWithoutPocketPair": 4,
            "FullHouseWithPocketPairTripsOnBoard": 4,
            "ThreeFlushBoardNutFlush": 4,
            "FourFlushBoardNutFlush": 4,
            "TwoCardNutStraight": 4,
            "OneCardNutStraight": 4,
            # –ö–ª–∞—Å—Å 3: –°–ò–õ–¨–ù–´–ï
            "ThreeFlushBoardHighFlush": 3,
            "FourFlushBoardHighFlush": 3,
            "TwoCardStraight": 3,
            "OneCardStraight": 3,
            "HighSet": 3,
            "SecondSet": 3,
            "LowSet": 3,
            "HighTripsHighKicker": 3,
            "HighTripsLowKicker": 3,
            "TopTwoPair": 3,
            # –ö–ª–∞—Å—Å 2: –°–†–ï–î–ù–ò–ï
            "ThreeFlushBoardLowFlush": 2,
            "FourFlushBoardLowFlush": 2,
            "SecondTripsHighKicker": 2,
            "SecondTripsLowKicker": 2,
            "LowTripsHighKicker": 2,
            "LowTripsLowKicker": 2,
            "TripsOnBoard": 2,
            "TopPairPlusPair": 2,
            "NonTopTwoPair": 2,
            "PocketPairOverPairPlusLowerPairedBoard": 2,
            "PocketPairPlusHigherPairedBoard": 2,
            "PocketPairPlusLowerPairedBoard": 2,
            "TopPairPlusPairedBoard": 2,
            "SecondPairPlusPairedBoard": 2,
            "LowPairPlusPairedBoard": 2,
            "TwoPairsOnBoard": 2,
            "OverPair": 2,
            "TopPairTopKicker": 2,
            "TopPairGoodKicker": 2,
            # –ö–ª–∞—Å—Å 1: –°–õ–ê–ë–´–ï
            "TopPairWeakKicker": 1,
            "SecondPocketPair": 1,
            "SecondPairAceKicker": 1,
            "SecondPairNonAceKicker": 1,
            "LowPocketPair": 1,
            "BottomPairAceKicker": 1,
            "BottomPairNonAceKicker": 1,
            "PairedBoardNoOvercards": 1,
            "PairedBoardOneOvercard": 1,
            "PairedBoardTwoOvercards": 1,
            "TwoCardNutFlushDraw": 1,
            "TwoCardHighFlushDraw": 1,
            "OneCardNutFlushDraw": 1,
            "OneCardHighFlushDraw": 1,
            # –ö–ª–∞—Å—Å 0: –ú–£–°–û–†
            "TwoCardLowFlushDraw": 0,
            "OneCardLowFlushDraw": 0,
            "TwoCardBackdoorNutFlushDraw": 0,
            "TwoCardBackdoorFlushDraw": 0,
            "OneCardBackDoorNutFlushDraw": 0,
            "OneCardBackDoorFlushDraw": 0,
            "TwoCardDoubleGutShotStraightDraw": 0,
            "TwoCardOpenEndedStraightDraw": 0,
            "OneCardOpenEndedStraightDraw": 0,
            "TwoCardGutshotStraightDraw": 0,
            "OneCardGutshotStraightDraw": 0,
            "TwoCardBackdoorStraightDraw": 0,
            "OneCardBackdoorStraightDraw": 0,
            "AceOnBoard": 0,
            "KingOnBoard": 0,
            "Other": 0,
        }

    def parse_card(self, card_str):
        """–ü–∞—Ä—Å–∏—Ç –∫–∞—Ä—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        if not card_str or len(card_str) < 2:
            return None, None
        rank = self.RANK_VALUES.get(card_str[0].upper())
        suit = self.SUIT_MAP.get(card_str[1].lower())
        return rank, suit

    def evaluate_hand(self, hole_cards, board_cards):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ä—É–∫–∏ –∏–∑ 73 –∫–æ–º–±–∏–Ω–∞—Ü–∏–π

        Args:
            hole_cards: —Å–ø–∏—Å–æ–∫ –∏–∑ 2 –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞ ['As', 'Kh']
            board_cards: —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç –Ω–∞ –±–æ—Ä–¥–µ ['Qd', 'Js', 'Tc', '9h', '8s']

        Returns:
            tuple: (hand_type_name, strength_class)
        """
        # –ü–∞—Ä—Å–∏–º –∫–∞—Ä—Ç—ã
        hole = [self.parse_card(c) for c in hole_cards if c]
        board = [self.parse_card(c) for c in board_cards if c]

        # –£–±–∏—Ä–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
        hole = [(r, s) for r, s in hole if r is not None]
        board = [(r, s) for r, s in board if r is not None]

        if len(hole) != 2:
            return "Other", 0

        # –í—Å–µ –∫–∞—Ä—Ç—ã –≤–º–µ—Å—Ç–µ
        all_cards = hole + board

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è —Å–∏–ª—ã

        # 1. –°—Ç—Ä–∏—Ç-—Ñ–ª–µ—à
        sf_type = self._check_straight_flush(hole, board, all_cards)
        if sf_type:
            return sf_type, self.hand_type_to_strength[sf_type]

        # 2. –ö–∞—Ä–µ
        quads_type = self._check_four_of_kind(hole, board, all_cards)
        if quads_type:
            return quads_type, self.hand_type_to_strength[quads_type]

        # 3. –§—É–ª–ª-—Ö–∞—É—Å
        fh_type = self._check_full_house(hole, board, all_cards)
        if fh_type:
            return fh_type, self.hand_type_to_strength[fh_type]

        # 4. –§–ª–µ—à
        flush_type = self._check_flush(hole, board, all_cards)
        if flush_type:
            return flush_type, self.hand_type_to_strength[flush_type]

        # 5. –°—Ç—Ä–∏—Ç
        straight_type = self._check_straight(hole, board, all_cards)
        if straight_type:
            return straight_type, self.hand_type_to_strength[straight_type]

        # 6. –°–µ—Ç/–¢—Ä–∏–ø—Å
        trips_type = self._check_three_of_kind(hole, board, all_cards)
        if trips_type:
            return trips_type, self.hand_type_to_strength[trips_type]

        # 7. –î–≤–µ –ø–∞—Ä—ã
        two_pair_type = self._check_two_pair(hole, board, all_cards)
        if two_pair_type:
            return two_pair_type, self.hand_type_to_strength[two_pair_type]

        # 8. –û–¥–Ω–∞ –ø–∞—Ä–∞
        pair_type = self._check_one_pair(hole, board, all_cards)
        if pair_type:
            return pair_type, self.hand_type_to_strength[pair_type]

        # 9. –î—Ä–æ
        draw_type = self._check_draws(hole, board)
        if draw_type:
            return draw_type, self.hand_type_to_strength[draw_type]

        # 10. –í—ã—Å–æ–∫–∏–µ –∫–∞—Ä—Ç—ã
        high_card_type = self._check_high_cards(board)
        if high_card_type:
            return high_card_type, self.hand_type_to_strength[high_card_type]

        return "Other", 0

    def _check_straight_flush(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä–∏—Ç-—Ñ–ª–µ—à"""
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –º–∞—Å—Ç—è–º
        suits = {}
        for rank, suit in all_cards:
            if suit not in suits:
                suits[suit] = []
            suits[suit].append(rank)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∞—Å—Ç—å
        for suit, ranks in suits.items():
            if len(ranks) >= 5:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∏—Ç –≤ —ç—Ç–æ–π –º–∞—Å—Ç–∏
                if self._is_straight_in_ranks(sorted(ranks, reverse=True)):
                    # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç –∏–∑ hole cards —É—á–∞—Å—Ç–≤—É—é—Ç
                    hole_in_sf = sum(1 for r, s in hole if s == suit and r in ranks[:5])
                    if hole_in_sf == 2:
                        return "TwoCardStraightFlush"
                    elif hole_in_sf == 1:
                        return "OneCardStraightFlush"
        return None

    def _check_four_of_kind(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—Ä–µ"""
        rank_counts = Counter(r for r, s in all_cards)

        for rank, count in rank_counts.items():
            if count == 4:
                hole_ranks = [r for r, s in hole]
                board_ranks = [r for r, s in board]

                # –ö–∞—Ä–µ –Ω–∞ –±–æ—Ä–¥–µ
                if board_ranks.count(rank) == 4:
                    return "FourOfAKindOnBoard"
                # –ö–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
                elif hole_ranks[0] == hole_ranks[1] == rank:
                    return "FourOfAKindWithPocketPair"
                else:
                    return "FourOfAKindWithoutPocketPair"
        return None

    def _check_full_house(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ—É–ª–ª-—Ö–∞—É—Å"""
        rank_counts = Counter(r for r, s in all_cards)
        trips = [r for r, c in rank_counts.items() if c >= 3]
        pairs = [r for r, c in rank_counts.items() if c >= 2]

        if trips and len(pairs) >= 2:
            hole_ranks = [r for r, s in hole]
            board_ranks = [r for r, s in board]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Ñ—É–ª–ª-—Ö–∞—É—Å–æ–≤
            if hole_ranks[0] == hole_ranks[1]:  # –ö–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
                if board_ranks.count(trips[0]) == 3:  # –¢—Ä–∏–ø—Å –Ω–∞ –±–æ—Ä–¥–µ
                    return "FullHouseWithPocketPairTripsOnBoard"
                else:
                    return "FullHouseWithPocketPairNoTripsOnBoard"
            elif board_ranks.count(trips[0]) == 3:  # –¢—Ä–∏–ø—Å –Ω–∞ –±–æ—Ä–¥–µ
                return "OneCardFullHouseTripsOnBoard"
            elif max(hole_ranks) in trips and max(board_ranks) == max(hole_ranks):
                return "OneCardFullHouseTopPair"
            else:
                return "TwoCardFullHouseWithoutPocketPair"
        return None

    def _check_flush(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–ª–µ—à"""
        suit_counts = Counter(s for r, s in all_cards)

        for suit, count in suit_counts.items():
            if count >= 5:
                # –ö–∞—Ä—Ç—ã —ç—Ç–æ–π –º–∞—Å—Ç–∏
                suited_cards = sorted(
                    [r for r, s in all_cards if s == suit], reverse=True
                )
                hole_suited = [r for r, s in hole if s == suit]
                board_suited = [r for r, s in board if s == suit]

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—É —Ñ–ª–µ—à–∞
                if 14 in hole_suited:  # –¢—É–∑ —É –∏–≥—Ä–æ–∫–∞
                    if len(board_suited) == 3:
                        return "ThreeFlushBoardNutFlush"
                    else:
                        return "FourFlushBoardNutFlush"
                elif max(hole_suited) >= 11:  # K, Q, J
                    if len(board_suited) == 3:
                        return "ThreeFlushBoardHighFlush"
                    else:
                        return "FourFlushBoardHighFlush"
                else:
                    if len(board_suited) == 3:
                        return "ThreeFlushBoardLowFlush"
                    else:
                        return "FourFlushBoardLowFlush"
        return None

    def _check_straight(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä–∏—Ç"""
        ranks = sorted(set(r for r, s in all_cards), reverse=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–µ—Å–æ (A-2-3-4-5)
        if set([14, 2, 3, 4, 5]).issubset(ranks):
            ranks.append(1)  # –¢—É–∑ –∫–∞–∫ –µ–¥–∏–Ω–∏—Ü–∞

        # –ò—â–µ–º —Å—Ç—Ä–∏—Ç
        for i in range(len(ranks) - 4):
            if ranks[i] - ranks[i + 4] == 4:
                straight_ranks = ranks[i : i + 5]
                hole_ranks = [r for r, s in hole]

                # –°—á–∏—Ç–∞–µ–º –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –≤ —Å—Ç—Ä–∏—Ç–µ
                hole_in_straight = sum(1 for r in hole_ranks if r in straight_ranks)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Ç—Å–æ–≤–æ—Å—Ç—å
                is_nut = straight_ranks[0] == max(ranks) or (
                    14 in straight_ranks and 13 in straight_ranks
                )

                if hole_in_straight == 2:
                    return "TwoCardNutStraight" if is_nut else "TwoCardStraight"
                elif hole_in_straight == 1:
                    return "OneCardNutStraight" if is_nut else "OneCardStraight"
        return None

    def _check_three_of_kind(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–µ—Ç/—Ç—Ä–∏–ø—Å"""
        rank_counts = Counter(r for r, s in all_cards)

        for rank, count in rank_counts.items():
            if count == 3:
                hole_ranks = [r for r, s in hole]
                board_ranks = sorted([r for r, s in board], reverse=True)

                # –¢—Ä–∏–ø—Å –Ω–∞ –±–æ—Ä–¥–µ
                if board_ranks.count(rank) == 3:
                    return "TripsOnBoard"

                # –°–µ—Ç (–∫–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞)
                if hole_ranks[0] == hole_ranks[1] == rank:
                    board_higher = [r for r in board_ranks if r > rank]
                    if len(board_higher) == 0:
                        return "HighSet"
                    elif len(board_higher) == 1:
                        return "SecondSet"
                    else:
                        return "LowSet"

                # –¢—Ä–∏–ø—Å (–æ–¥–Ω–∞ –∫–∞—Ä—Ç–∞ –≤ —Ä—É–∫–µ)
                else:
                    kicker = max(r for r in hole_ranks if r != rank)
                    board_higher = [r for r in board_ranks if r > rank]

                    if len(board_higher) == 0:  # –¢–æ–ø —Ç—Ä–∏–ø—Å
                        return (
                            "HighTripsHighKicker"
                            if kicker >= 12
                            else "HighTripsLowKicker"
                        )
                    elif len(board_higher) == 1:  # –°—Ä–µ–¥–Ω–∏–π —Ç—Ä–∏–ø—Å
                        return (
                            "SecondTripsHighKicker"
                            if kicker >= 12
                            else "SecondTripsLowKicker"
                        )
                    else:  # –ú–ª–∞–¥—à–∏–π —Ç—Ä–∏–ø—Å
                        return (
                            "LowTripsHighKicker"
                            if kicker >= 12
                            else "LowTripsLowKicker"
                        )
        return None

    def _check_two_pair(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–≤–µ –ø–∞—Ä—ã"""
        rank_counts = Counter(r for r, s in all_cards)
        pairs = sorted([r for r, c in rank_counts.items() if c >= 2], reverse=True)

        if len(pairs) >= 2:
            hole_ranks = [r for r, s in hole]
            board_ranks = sorted([r for r, s in board], reverse=True)

            top_board = board_ranks[0] if board_ranks else 0

            # –û–±–µ –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ —Å–ø–∞—Ä–µ–Ω—ã
            if (
                hole_ranks[0] in pairs
                and hole_ranks[1] in pairs
                and hole_ranks[0] != hole_ranks[1]
            ):
                if hole_ranks[0] == top_board and hole_ranks[1] == board_ranks[1]:
                    return "TopTwoPair"
                elif max(hole_ranks) == top_board:
                    return "TopPairPlusPair"
                else:
                    return "NonTopTwoPair"

            # –ö–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
            elif hole_ranks[0] == hole_ranks[1] and hole_ranks[0] in pairs:
                board_pairs = [r for r in board_ranks if rank_counts[r] >= 2]
                if board_pairs:
                    if hole_ranks[0] > board_pairs[0]:
                        return "PocketPairOverPairPlusLowerPairedBoard"
                    elif hole_ranks[0] > min(board_pairs):
                        return "PocketPairPlusHigherPairedBoard"
                    else:
                        return "PocketPairPlusLowerPairedBoard"

            # –û–¥–Ω–∞ –ø–∞—Ä–∞ —Å –∏–≥—Ä–æ–∫–æ–º + –ø–∞—Ä–∞ –Ω–∞ –±–æ—Ä–¥–µ
            elif any(r in pairs for r in hole_ranks):
                player_pair = next(r for r in hole_ranks if r in pairs)
                if player_pair == top_board:
                    return "TopPairPlusPairedBoard"
                elif board_ranks.index(player_pair) == 1:
                    return "SecondPairPlusPairedBoard"
                else:
                    return "LowPairPlusPairedBoard"

            # –î–≤–µ –ø–∞—Ä—ã –Ω–∞ –±–æ—Ä–¥–µ
            else:
                return "TwoPairsOnBoard"
        return None

    def _check_one_pair(self, hole, board, all_cards):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–Ω—É –ø–∞—Ä—É"""
        rank_counts = Counter(r for r, s in all_cards)
        pairs = [r for r, c in rank_counts.items() if c == 2]

        if pairs:
            hole_ranks = sorted([r for r, s in hole], reverse=True)
            board_ranks = sorted([r for r, s in board], reverse=True)
            pair_rank = max(pairs)

            # –ö–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
            if hole_ranks[0] == hole_ranks[1] == pair_rank:
                if not board_ranks or pair_rank > max(board_ranks):
                    return "OverPair"
                elif pair_rank in board_ranks:
                    board_position = board_ranks.index(pair_rank)
                    if board_position == 1:
                        return "SecondPocketPair"
                    else:
                        return "LowPocketPair"
                else:
                    return "LowPocketPair"

            # –ü–∞—Ä–∞ —Å –±–æ—Ä–¥–æ–º
            elif pair_rank in hole_ranks:
                kicker = max(r for r in hole_ranks if r != pair_rank)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ pair_rank –≤ board_ranks –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º index()
                if pair_rank in board_ranks:
                    board_position = board_ranks.index(pair_rank)

                    if board_position == 0:  # –¢–æ–ø –ø–∞—Ä–∞
                        if kicker == 14:
                            return "TopPairTopKicker"
                        elif kicker >= 11:
                            return "TopPairGoodKicker"
                        else:
                            return "TopPairWeakKicker"
                    elif board_position == 1:  # –°—Ä–µ–¥–Ω—è—è –ø–∞—Ä–∞
                        return (
                            "SecondPairAceKicker"
                            if kicker == 14
                            else "SecondPairNonAceKicker"
                        )
                    else:  # –ú–ª–∞–¥—à–∞—è –ø–∞—Ä–∞
                        return (
                            "BottomPairAceKicker"
                            if kicker == 14
                            else "BottomPairNonAceKicker"
                        )
                else:
                    # –ï—Å–ª–∏ pair_rank –Ω–µ—Ç –≤ board_ranks, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞—Ä–º–∞–Ω–Ω–∞—è –ø–∞—Ä–∞
                    return "LowPocketPair"

            # –ü–∞—Ä–∞ –Ω–∞ –±–æ—Ä–¥–µ
            else:
                if board_ranks:
                    overcards = sum(1 for r in hole_ranks if r > max(board_ranks))
                    if overcards == 0:
                        return "PairedBoardNoOvercards"
                    elif overcards == 1:
                        return "PairedBoardOneOvercard"
                    else:
                        return "PairedBoardTwoOvercards"
                else:
                    return "PairedBoardTwoOvercards"

        return None

    def _check_draws(self, hole, board):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥—Ä–æ"""
        if len(board) < 5:  # –¢–æ–ª—å–∫–æ –Ω–∞ —Ñ–ª–æ–ø–µ –∏ —Ç–µ—Ä–Ω–µ –µ—Å—Ç—å –¥—Ä–æ
            # –§–ª–µ—à-–¥—Ä–æ
            flush_draw = self._check_flush_draw(hole, board)
            if flush_draw:
                return flush_draw

            # –°—Ç—Ä–∏—Ç-–¥—Ä–æ
            straight_draw = self._check_straight_draw(hole, board)
            if straight_draw:
                return straight_draw
        return None

    def _check_flush_draw(self, hole, board):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–ª–µ—à-–¥—Ä–æ"""
        all_cards = hole + board
        suit_counts = Counter(s for r, s in all_cards)

        for suit, count in suit_counts.items():
            if count == 4:  # –§–ª–µ—à-–¥—Ä–æ
                hole_suited = [r for r, s in hole if s == suit]
                if len(hole_suited) == 2:
                    if 14 in hole_suited:
                        return "TwoCardNutFlushDraw"
                    elif max(hole_suited) >= 11:
                        return "TwoCardHighFlushDraw"
                    else:
                        return "TwoCardLowFlushDraw"
                elif len(hole_suited) == 1:
                    if hole_suited[0] == 14:
                        return "OneCardNutFlushDraw"
                    elif hole_suited[0] >= 11:
                        return "OneCardHighFlushDraw"
                    else:
                        return "OneCardLowFlushDraw"
            elif count == 3 and len(board) == 3:  # –ë—ç–∫–¥–æ—Ä–Ω–æ–µ —Ñ–ª–µ—à-–¥—Ä–æ
                hole_suited = [r for r, s in hole if s == suit]
                if len(hole_suited) == 2:
                    if 14 in hole_suited:
                        return "TwoCardBackdoorNutFlushDraw"
                    else:
                        return "TwoCardBackdoorFlushDraw"
                elif len(hole_suited) == 1:
                    if hole_suited[0] == 14:
                        return "OneCardBackDoorNutFlushDraw"
                    else:
                        return "OneCardBackDoorFlushDraw"
        return None

    def _check_straight_draw(self, hole, board):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä–∏—Ç-–¥—Ä–æ"""
        all_ranks = sorted(set(r for r, s in hole + board), reverse=True)
        hole_ranks = [r for r, s in hole]

        # OESD –∏ –≥–∞—Ç—à–æ—Ç—ã
        outs = 0
        draw_type = None

        for target in range(14, 4, -1):
            straight_cards = list(range(target - 4, target + 1))
            have = sum(1 for r in straight_cards if r in all_ranks)
            hole_in = sum(1 for r in straight_cards if r in hole_ranks)

            if have == 4 and hole_in >= 1:
                missing = [r for r in straight_cards if r not in all_ranks][0]
                if missing == straight_cards[0] or missing == straight_cards[4]:
                    # OESD
                    if hole_in == 2:
                        return "TwoCardOpenEndedStraightDraw"
                    else:
                        return "OneCardOpenEndedStraightDraw"
                else:
                    # –ì–∞—Ç—à–æ—Ç
                    if hole_in == 2:
                        draw_type = "TwoCardGutshotStraightDraw"
                    else:
                        draw_type = "OneCardGutshotStraightDraw"
                    outs += 4

        if outs >= 8:
            return "TwoCardDoubleGutShotStraightDraw"
        elif draw_type:
            return draw_type

        # –ë—ç–∫–¥–æ—Ä–Ω–æ–µ —Å—Ç—Ä–∏—Ç-–¥—Ä–æ (—Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–ª–æ–ø–µ)
        if len(board) == 3:
            for target in range(14, 4, -1):
                straight_cards = list(range(target - 4, target + 1))
                have = sum(1 for r in straight_cards if r in all_ranks)
                hole_in = sum(1 for r in straight_cards if r in hole_ranks)

                if have == 3 and hole_in >= 1:
                    if hole_in == 2:
                        return "TwoCardBackdoorStraightDraw"
                    else:
                        return "OneCardBackdoorStraightDraw"

        return None

    def _check_high_cards(self, board):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—ã—Å–æ–∫–∏–µ –∫–∞—Ä—Ç—ã –Ω–∞ –±–æ—Ä–¥–µ"""
        board_ranks = [r for r, s in board]
        if 14 in board_ranks:
            return "AceOnBoard"
        elif 13 in board_ranks:
            return "KingOnBoard"
        return None

    def _is_straight_in_ranks(self, ranks):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –µ—Å—Ç—å –ª–∏ —Å—Ç—Ä–∏—Ç –≤ —Å–ø–∏—Å–∫–µ —Ä–∞–Ω–≥–æ–≤"""
        ranks = sorted(set(ranks), reverse=True)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–µ —Å—Ç—Ä–∏—Ç—ã
        for i in range(len(ranks) - 4):
            if ranks[i] - ranks[i + 4] == 4:
                return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–µ—Å–æ (A-5)
        if set([14, 2, 3, 4, 5]).issubset(ranks):
            return True

        return False


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
def add_hand_evaluation_to_dataframe(df):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ç–∏–ø–∞ —Ä—É–∫–∏ –∏ —Å–∏–ª—ã –∫ DataFrame

    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ Showdown_1, Showdown_2, Card1-Card5

    Returns:
        df: DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ hand_type_hm3 –∏ hand_strength_class
    """
    evaluator = PokerHandEvaluator()

    hand_types = []
    strength_classes = []

    for idx, row in df.iterrows():
        # –ö–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞
        hole_cards = [row.get("Showdown_1"), row.get("Showdown_2")]

        # –ö–∞—Ä—Ç—ã –±–æ—Ä–¥–∞
        board_cards = []
        for i in range(1, 6):
            card = row.get(f"Card{i}")
            if pd.notna(card) and card:
                board_cards.append(card)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä—É–∫—É
        if all(pd.notna(c) for c in hole_cards):
            hand_type, strength_class = evaluator.evaluate_hand(hole_cards, board_cards)
        else:
            hand_type, strength_class = "Other", 0

        hand_types.append(hand_type)
        strength_classes.append(strength_class)

    df["hand_type_hm3"] = hand_types
    df["hand_strength_class"] = strength_classes

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ä—É–∫:")
    type_counts = df["hand_type_hm3"].value_counts()
    for hand_type, count in type_counts.head(20).items():
        strength = evaluator.hand_type_to_strength.get(hand_type, 0)
        print(
            f"   {hand_type:40s}: {count:5d} ({count/len(df)*100:5.1f}%) - –°–∏–ª–∞: {strength}"
        )

    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã:")
    strength_dist = df["hand_strength_class"].value_counts().sort_index()
    class_names = ["–ú—É—Å–æ—Ä/–î—Ä–æ", "–°–ª–∞–±—ã–µ", "–°—Ä–µ–¥–Ω–∏–µ", "–°–∏–ª—å–Ω—ã–µ", "–ú–æ–Ω—Å—Ç—Ä—ã"]
    for strength, count in strength_dist.items():
        print(
            f"   –ö–ª–∞—Å—Å {strength} ({class_names[strength]}): {count:5d} ({count/len(df)*100:5.1f}%)"
        )

    return df


# ---------------------- 1. –ú–æ–¥–µ–ª—å RWKV ----------------------


class SequenceHandRangeRWKV(nn.Module):
    def __init__(
        self,
        input_dim,
        hidden_dim,
        num_layers=3,
        max_sequence_length=20,
        num_strength_classes=5,
        num_categories=73,
    ):
        super(
            SequenceHandRangeRWKV, self
        ).__init__()  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        self.max_sequence_length = max_sequence_length
        self.num_strength_classes = num_strength_classes
        self.num_categories = num_categories

        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–∏
        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.rwkv_layers = nn.ModuleList(
            [RWKV_Block(hidden_dim) for _ in range(num_layers)]
        )
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.3)

        # –í—ã—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.hand_strength_head = nn.Linear(hidden_dim, num_strength_classes)
        self.category_head = nn.Linear(hidden_dim, num_categories)
        self.specific_hand_head = nn.Linear(hidden_dim, 13)  # 13 —Ä–∞–Ω–≥–æ–≤ –∫–∞—Ä—Ç

        # Sigmoid —Ç–æ–ª—å–∫–æ –¥–ª—è specific_hand
        self.sigmoid = nn.Sigmoid()

    def reset_states(self):
        """–°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—Å–µ—Ö RWKV —Å–ª–æ–µ–≤"""
        for layer in self.rwkv_layers:
            layer.reset_state()

    def forward(self, x, return_all_timesteps=False):
        """
        x: [batch_size, sequence_length, input_dim]
        return_all_timesteps: –µ—Å–ª–∏ True, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤
        """
        batch_size, seq_len, _ = x.size()

        # –ü—Ä–∏–º–µ–Ω—è–µ–º embedding
        x = self.embedding(x)  # [batch_size, seq_len, hidden_dim]

        # –ü—Ä–æ—Ö–æ–¥–∏–º —á–µ—Ä–µ–∑ RWKV —Å–ª–æ–∏
        for layer in self.rwkv_layers:
            residual = x
            x = layer(x)
            x = residual + x
            x = self.norm(x)
            x = self.dropout(x)

        # –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —à–∞–≥–∏
        if return_all_timesteps:
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —à–∞–≥–∞
            all_predictions = []
            for t in range(seq_len):
                xt = x[:, t, :]  # [batch_size, hidden_dim]

                hand_strength = self.hand_strength_head(xt)
                category_logits = self.category_head(xt)
                specific_hand = self.sigmoid(self.specific_hand_head(xt))

                all_predictions.append(
                    {
                        "hand_strength": hand_strength,
                        "category_probs": category_logits,
                        "specific_hand": specific_hand,
                    }
                )
            return all_predictions
        else:
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            x = x[:, -1, :]  # [batch_size, hidden_dim]

            # –ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω—ã–π –≤—ã—Ö–æ–¥
            hand_strength = self.hand_strength_head(x)
            category_logits = self.category_head(x)
            specific_hand = self.sigmoid(self.specific_hand_head(x))

            return {
                "hand_strength": hand_strength,
                "category_probs": category_logits,
                "specific_hand": specific_hand,
            }


class SequenceHandRangeDataset(Dataset):
    def __init__(self, sequences, feature_columns, targets=None, max_length=20):
        """
        sequences: —Å–ø–∏—Å–æ–∫ DataFrame'–æ–≤, –∫–∞–∂–¥—ã–π - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –∏–≥—Ä–æ–∫–∞
        feature_columns: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        targets: —Å–ª–æ–≤–∞—Ä—å —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        max_length: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–¥–ª—è padding)
        """
        self.sequences = sequences
        self.feature_columns = feature_columns
        self.max_length = max_length
        self.has_targets = targets is not None

        if self.has_targets:
            self.targets = targets

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        self.processed_sequences = []
        self.valid_indices = []

        for idx, seq_df in enumerate(sequences):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                features = seq_df[feature_columns].values.astype(np.float32)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                if not np.any(np.isnan(features)) and len(features) > 0:
                    self.processed_sequences.append(features)
                    self.valid_indices.append(idx)

            except Exception as e:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                continue

        print(
            f"üìä Dataset —Å–æ–∑–¥–∞–Ω: {len(self.valid_indices)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–∑ {len(sequences)}"
        )

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx):
        actual_idx = self.valid_indices[idx]
        features = self.processed_sequences[idx]

        # Padding/truncation –¥–æ max_length
        seq_len = min(len(features), self.max_length)

        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä —Å padding
        padded_features = np.zeros(
            (self.max_length, len(self.feature_columns)), dtype=np.float32
        )
        padded_features[:seq_len] = features[:seq_len]

        features_tensor = torch.tensor(padded_features, dtype=torch.float32)

        if self.has_targets:
            # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            target_dict = {
                "hand_strength": torch.tensor(
                    self.targets["hand_strength"][actual_idx], dtype=torch.long
                ),
                "category_probs": torch.tensor(
                    self.targets["category_probs"][actual_idx], dtype=torch.float32
                ),
                "specific_hand": torch.tensor(
                    self.targets["specific_hand"][actual_idx], dtype=torch.float32
                ),
                "sequence_length": torch.tensor(seq_len, dtype=torch.long),
            }
            return features_tensor, target_dict
        else:
            return features_tensor, torch.tensor(seq_len, dtype=torch.long)


def create_sequences_with_targets(df, feature_columns, max_sequence_length=20):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    """
    print(f"üéØ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏...")

    # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    sequences, sequence_info = create_player_sequences(
        df, max_sequence_length=max_sequence_length
    )

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    targets = {"hand_strength": [], "category_probs": [], "specific_hand": []}

    valid_sequences = []

    for i, (seq_df, seq_info) in enumerate(zip(sequences, sequence_info)):
        try:
            # –ë–µ—Ä–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            last_row = seq_df.iloc[-1]

            if pd.notna(last_row.get("hand_strength")):
                targets["hand_strength"].append(int(last_row["hand_strength"]))

                # –ù–∞—Ö–æ–¥–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                category_idx = 8  # default "other"
                if pd.notna(last_row.get("hand_category")):
                    category_mapping = PokerHandAnalyzer.get_category_mapping()
                    category_idx = category_mapping.get(last_row["hand_category"], 8)

                category_probs = np.zeros(9)
                category_probs[category_idx] = 1.0
                targets["category_probs"].append(category_probs)

                # –°–æ–∑–¥–∞–µ–º specific_hand –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç
                specific_hand = np.zeros(13)
                analyzer = PokerHandAnalyzer()

                card1 = last_row.get("Showdown_1")
                card2 = last_row.get("Showdown_2")

                if pd.notna(card1) and pd.notna(card2):
                    rank1, _ = analyzer.parse_card(card1)
                    rank2, _ = analyzer.parse_card(card2)

                    if rank1 is not None and rank2 is not None:
                        rank1_idx = max(0, min(12, rank1 - 2))
                        rank2_idx = max(0, min(12, rank2 - 2))
                        specific_hand[rank1_idx] = 0.6
                        specific_hand[rank2_idx] = 0.6

                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                        if specific_hand.sum() > 0:
                            specific_hand = specific_hand / specific_hand.sum()
                        else:
                            specific_hand = np.ones(13) / 13
                    else:
                        specific_hand = np.ones(13) / 13
                else:
                    specific_hand = np.ones(13) / 13

                targets["specific_hand"].append(specific_hand)
                valid_sequences.append(seq_df)

        except Exception as e:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            continue

    print(
        f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(valid_sequences)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏"
    )

    return valid_sequences, targets


class RWKV_Block(nn.Module):
    def __init__(self, hidden_dim):
        super(RWKV_Block, self).__init__()
        self.hidden_dim = hidden_dim

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã time-mixing
        self.time_decay = nn.Parameter(torch.randn(hidden_dim) * 0.01)
        self.time_mix_k = nn.Parameter(torch.ones(hidden_dim) * 0.5)
        self.time_mix_v = nn.Parameter(torch.ones(hidden_dim) * 0.5)
        self.time_mix_r = nn.Parameter(torch.ones(hidden_dim) * 0.5)

        # –°–ª–æ–∏
        self.key = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.value = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.receptance = nn.Linear(hidden_dim, hidden_dim, bias=False)
        self.output = nn.Linear(hidden_dim, hidden_dim, bias=False)

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.register_buffer("state", None, persistent=False)

    def reset_state(self):
        self.state = None

    def _init_state(self, batch_size):
        return torch.zeros(batch_size, self.hidden_dim).to(self.time_decay.device)

    def forward(self, x):
        batch_size, seq_len, _ = x.size()
        if self.state is None or self.state.size(0) != batch_size:
            self.state = self._init_state(batch_size)

        output = []
        for t in range(seq_len):
            xt = x[:, t]

            # Time-mixing
            k = self.key(xt * self.time_mix_k + self.state * (1 - self.time_mix_k))
            v = self.value(xt * self.time_mix_v + self.state * (1 - self.time_mix_v))
            r = torch.sigmoid(
                self.receptance(
                    xt * self.time_mix_r + self.state * (1 - self.time_mix_r)
                )
            )

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self.state = xt + self.state * torch.exp(-torch.exp(self.time_decay))

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—ã—Ö–æ–¥–∞
            out = r * self.output(v)
            output.append(out)

        return torch.stack(output, dim=1)


class HandRangeRWKV(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers=3):
        super(HandRangeRWKV, self).__init__()

        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.rwkv_layers = nn.ModuleList(
            [RWKV_Block(hidden_dim) for _ in range(num_layers)]
        )
        self.norm = nn.LayerNorm(hidden_dim)
        self.dropout = nn.Dropout(0.3)

        # –í—ã—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.hand_strength_head = nn.Linear(
            hidden_dim, 10
        )  # 10 —É—Ä–æ–≤–Ω–µ–π —Å–∏–ª—ã —Ä—É–∫–∏ (0-9)
        self.category_head = nn.Linear(hidden_dim, 9)  # 9 –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ä—É–∫
        self.specific_hand_head = nn.Linear(hidden_dim, 13)  # 13 —Ä–∞–Ω–≥–æ–≤ –∫–∞—Ä—Ç

        # Sigmoid —Ç–æ–ª—å–∫–æ –¥–ª—è specific_hand
        self.sigmoid = nn.Sigmoid()

    def reset_states(self):
        for layer in self.rwkv_layers:
            layer.reset_state()

    def forward(self, x):
        x = self.embedding(x).unsqueeze(1)  # [batch_size, 1, hidden_dim]

        for layer in self.rwkv_layers:
            residual = x
            x = layer(x)
            x = residual + x
            x = self.norm(x)
            x = self.dropout(x)

        x = x.squeeze(1)  # [batch_size, hidden_dim]

        # –ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω—ã–π –≤—ã—Ö–æ–¥
        hand_strength = self.hand_strength_head(x)
        category_logits = self.category_head(x)
        specific_hand = self.sigmoid(self.specific_hand_head(x))

        return {
            "hand_strength": hand_strength,
            "category_probs": category_logits,
            "specific_hand": specific_hand,
        }


# ---------------------- 2. –ê–Ω–∞–ª–∏–∑ –ø–æ–∫–µ—Ä–Ω—ã—Ö —Ä—É–∫ ----------------------
class PokerHandAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∏–ª—ã –ø–æ–∫–µ—Ä–Ω—ã—Ö —Ä—É–∫"""

    RANK_MAP = {
        "A": 14,
        "K": 13,
        "Q": 12,
        "J": 11,
        "T": 10,
        "9": 9,
        "8": 8,
        "7": 7,
        "6": 6,
        "5": 5,
        "4": 4,
        "3": 3,
        "2": 2,
    }

    SUIT_MAP = {"s": 0, "h": 1, "d": 2, "c": 3}

    HAND_CATEGORIES = {
        "premium_pair": ["AA", "KK", "QQ"],
        "strong_pair": ["JJ", "TT", "99"],
        "medium_pair": ["88", "77", "66", "55"],
        "small_pair": ["44", "33", "22"],
        "premium_ace": ["AKs", "AKo", "AQs", "AQo"],
        "strong_ace": ["AJs", "AJo", "ATs", "ATo"],
        "suited_connector": ["KQs", "QJs", "JTs", "T9s", "98s", "87s", "76s"],
        "offsuit_broadway": ["KQo", "QJo", "JTo", "KJo"],
    }

    @staticmethod
    def get_all_categories():
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        return list(PokerHandAnalyzer.HAND_CATEGORIES.keys()) + ["other"]

    @staticmethod
    def get_category_mapping():
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è JSON"""
        category_mapping = {
            "premium_pair": 0,
            "strong_pair": 1,
            "medium_pair": 2,
            "small_pair": 3,
            "premium_ace": 4,
            "strong_ace": 5,
            "suited_connector": 6,
            "offsuit_broadway": 7,
            "other": 8,
        }
        return category_mapping

    @staticmethod
    def get_rank_names():
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–∞–Ω–≥–æ–≤ –¥–ª—è JSON"""
        return ["2", "3", "4", "5", "6", "7", "8", "9", "T", "J", "Q", "K", "A"]

    @staticmethod
    def parse_card(card_str):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'As' -> (14, 0))"""
        if pd.isna(card_str) or card_str == "" or len(card_str) < 2:
            return None, None

        rank_char = card_str[0].upper()
        suit_char = card_str[1].lower()

        rank = PokerHandAnalyzer.RANK_MAP.get(rank_char)
        suit = PokerHandAnalyzer.SUIT_MAP.get(suit_char)

        return rank, suit

    @staticmethod
    def analyze_hand_strength(card1, card2):
        """–ê–Ω–∞–ª–∏–∑ —Å–∏–ª—ã —Å—Ç–∞—Ä—Ç–æ–≤–æ–π —Ä—É–∫–∏ (–ø—Ä–µ—Ñ–ª–æ–ø)"""
        rank1, suit1 = PokerHandAnalyzer.parse_card(card1)
        rank2, suit2 = PokerHandAnalyzer.parse_card(card2)

        if rank1 is None or rank2 is None:
            return 0, "unknown"

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ä—Ç (—Å—Ç–∞—Ä—à–∞—è –ø–µ—Ä–≤–æ–π)
        if rank1 < rank2:
            rank1, rank2 = rank2, rank1
            suit1, suit2 = suit2, suit1

        is_suited = suit1 == suit2
        is_pair = rank1 == rank2

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å–∏–ª—ã
        hand_str = PokerHandAnalyzer._format_hand_string(
            rank1, rank2, is_suited, is_pair
        )
        category = PokerHandAnalyzer._get_hand_category(hand_str)
        strength = PokerHandAnalyzer._calculate_hand_strength(
            rank1, rank2, is_suited, is_pair
        )

        return strength, category

    @staticmethod
    def _format_hand_string(rank1, rank2, is_suited, is_pair):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä—É–∫–∏ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É"""
        rank_chars = {v: k for k, v in PokerHandAnalyzer.RANK_MAP.items()}

        if is_pair:
            return f"{rank_chars[rank1]}{rank_chars[rank2]}"
        else:
            suffix = "s" if is_suited else "o"
            return f"{rank_chars[rank1]}{rank_chars[rank2]}{suffix}"

    @staticmethod
    def _get_hand_category(hand_str):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä—É–∫–∏"""
        for category, hands in PokerHandAnalyzer.HAND_CATEGORIES.items():
            if hand_str in hands:
                return category
        return "other"

    @staticmethod
    def _calculate_hand_strength(rank1, rank2, is_suited, is_pair):
        """–†–∞—Å—á–µ—Ç —Å–∏–ª—ã —Ä—É–∫–∏ (0-9 —à–∫–∞–ª–∞)"""
        if is_pair:
            if rank1 >= 14:  # AA
                return 9
            elif rank1 >= 13:  # KK
                return 8
            elif rank1 >= 12:  # QQ
                return 7
            elif rank1 >= 11:  # JJ
                return 6
            elif rank1 >= 10:  # TT
                return 5
            elif rank1 >= 9:  # 99
                return 4
            elif rank1 >= 8:  # 88
                return 3
            elif rank1 >= 7:  # 77
                return 2
            elif rank1 >= 6:  # 66
                return 1
            else:
                return 0
        else:
            # –ù–µ–ø–∞—Ä–Ω—ã–µ —Ä—É–∫–∏
            high_card_bonus = max(0, rank1 - 10)
            second_card_bonus = max(0, rank2 - 8)
            suited_bonus = 1 if is_suited else 0
            connector_bonus = 1 if abs(rank1 - rank2) == 1 else 0

            base_strength = (
                high_card_bonus + second_card_bonus + suited_bonus + connector_bonus
            )
            return min(9, max(0, base_strength))


# ---------------------- 3. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ----------------------
class HandRangeDataset(Dataset):
    def __init__(self, features, targets=None):
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º DataFrame –∏ numpy –º–∞—Å—Å–∏–≤—ã
        if hasattr(features, "values"):
            self.features = torch.tensor(
                features.values.astype(np.float32), dtype=torch.float32
            )
        else:
            self.features = torch.tensor(
                features.astype(np.float32), dtype=torch.float32
            )

        self.has_targets = targets is not None

        if self.has_targets:
            self.hand_strength = torch.tensor(
                targets["hand_strength"], dtype=torch.long
            )
            self.category_probs = torch.tensor(
                targets["category_probs"], dtype=torch.float32
            )
            self.specific_hand = torch.tensor(
                targets["specific_hand"], dtype=torch.float32
            )

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        if self.has_targets:
            return (
                self.features[idx],
                {
                    "hand_strength": self.hand_strength[idx],
                    "category_probs": self.category_probs[idx],
                    "specific_hand": self.specific_hand[idx],
                },
            )
        else:
            return self.features[idx]


def create_target_variables(df, use_hm3_classification=True):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    n_samples = len(df)

    if use_hm3_classification:
        # –î–ª—è HM3: 5 –∫–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã
        num_strength_classes = 5

        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã —Ä—É–∫ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        unique_hand_types = df["hand_type_hm3"].unique()
        category_mapping = {ht: i for i, ht in enumerate(sorted(unique_hand_types))}
        num_categories = len(unique_hand_types)

        print(f"üìä HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:")
        print(f"   –ö–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã: {num_strength_classes}")
        print(f"   –¢–∏–ø–æ–≤ —Ä—É–∫: {num_categories}")

    else:
        # –°—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞
        num_strength_classes = 10
        category_mapping = PokerHandAnalyzer.get_category_mapping()
        num_categories = 9

    # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    targets = {
        "hand_strength": df["hand_strength"].values.astype(int),
        "category_probs": np.zeros((n_samples, num_categories)),
        "specific_hand": np.zeros((n_samples, 13)),  # –†–∞–Ω–≥–∏ –∫–∞—Ä—Ç
    }

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    for i, row in df.iterrows():
        if use_hm3_classification:
            cat_idx = category_mapping.get(row["hand_type_hm3"], 0)
        else:
            cat_idx = category_mapping.get(row["hand_category"], 8)

        targets["category_probs"][i, cat_idx] = 1.0

        # Specific hand (—Ä–∞–Ω–≥–∏ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞)
        analyzer = PokerHandAnalyzer()
        try:
            card1 = row["Showdown_1"]
            card2 = row["Showdown_2"]

            if pd.notna(card1) and pd.notna(card2):
                rank1, _ = analyzer.parse_card(card1)
                rank2, _ = analyzer.parse_card(card2)

                if rank1 is not None and rank2 is not None:
                    rank1_idx = max(0, min(12, rank1 - 2))
                    rank2_idx = max(0, min(12, rank2 - 2))

                    targets["specific_hand"][i, rank1_idx] = 0.6
                    targets["specific_hand"][i, rank2_idx] = 0.6

                    # –ù–µ–º–Ω–æ–≥–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–µ —Ä–∞–Ω–≥–∏
                    for offset in [-1, 1]:
                        for rank_idx in [rank1_idx, rank2_idx]:
                            neighbor_idx = rank_idx + offset
                            if 0 <= neighbor_idx < 13:
                                targets["specific_hand"][i, neighbor_idx] = 0.1
        except Exception:
            targets["specific_hand"][i, :] = 1 / 13

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º specific_hand
    for i in range(n_samples):
        row_sum = targets["specific_hand"][i, :].sum()
        if row_sum > 0:
            targets["specific_hand"][i, :] /= row_sum
        else:
            targets["specific_hand"][i, :] = 1 / 13

    return targets


def prepare_hand_range_data(file_path, include_hole_cards=True):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä—É–∫"""
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {file_path}...")
    df = pd.read_csv(file_path)
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏
    mask = (df["Showdown_1"].notna()) & (df["Showdown_2"].notna())
    df_filtered = df[mask].copy().reset_index(drop=True)

    print(f"–ù–∞–π–¥–µ–Ω–æ {len(df_filtered)} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

    if len(df_filtered) == 0:
        print("–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏!")
        return None

    # –ê–Ω–∞–ª–∏–∑ —Ä—É–∫ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    analyzer = PokerHandAnalyzer()
    hand_analysis = df_filtered.apply(
        lambda row: analyzer.analyze_hand_strength(
            row["Showdown_1"], row["Showdown_2"]
        ),
        axis=1,
    )
    df_filtered["hand_strength"] = [x[0] for x in hand_analysis]
    df_filtered["hand_category"] = [x[1] for x in hand_analysis]

    print(
        f"–ê–Ω–∞–ª–∏–∑ —Ä—É–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ú–æ–¥–µ–ª—å {'–í–ò–î–ò–¢' if include_hole_cards else '–ù–ï –í–ò–î–ò–¢'} –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö."
    )

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_columns = [
        "Level",
        "Pot",
        "Stack",
        "SPR",
        "Street_id",
        "Round",
        "ActionOrder",
        "Seat",
        "Dealer",
        "Bet",
        "Allin",
        "PlayerWins",
        "WinAmount",
    ]

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—Ä—Ç–∞—Ö —Å—Ç–æ–ª–∞
    board_columns = ["Card1", "Card2", "Card3", "Card4", "Card5"]
    for col in board_columns:
        if col in df_filtered.columns:
            df_filtered[f"{col}_rank"], df_filtered[f"{col}_suit"] = zip(
                *df_filtered[col].apply(
                    lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
                )
            )
            feature_columns.extend([f"{col}_rank", f"{col}_suit"])

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —ç—Ç–æ –º–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏
    if include_hole_cards:
        print("–î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏...")
        df_filtered["hole1_rank"], df_filtered["hole1_suit"] = zip(
            *df_filtered["Showdown_1"].apply(
                lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
            )
        )
        df_filtered["hole2_rank"], df_filtered["hole2_suit"] = zip(
            *df_filtered["Showdown_2"].apply(
                lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
            )
        )
        feature_columns.extend(["hole1_rank", "hole1_suit", "hole2_rank", "hole2_suit"])
    else:
        print("–ö–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –ù–ï –≤–∫–ª—é—á–µ–Ω—ã –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏")

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    if "Position" in df_filtered.columns:
        position_encoder = LabelEncoder()
        df_filtered["Position_encoded"] = position_encoder.fit_transform(
            df_filtered["Position"].fillna("Unknown")
        )
        feature_columns.append("Position_encoded")

    if "Action" in df_filtered.columns:
        action_encoder = LabelEncoder()
        df_filtered["Action_encoded_feature"] = action_encoder.fit_transform(
            df_filtered["Action"].fillna("Unknown")
        )
        feature_columns.append("Action_encoded_feature")

    if "TypeBuyIn" in df_filtered.columns:
        buyin_encoder = LabelEncoder()
        df_filtered["TypeBuyIn_encoded"] = buyin_encoder.fit_transform(
            df_filtered["TypeBuyIn"].fillna("Unknown")
        )
        feature_columns.append("TypeBuyIn_encoded")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π...")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ SPR
    if "SPR" in df_filtered.columns:
        pot_zero_mask = (df_filtered["Pot"] == 0) | (df_filtered["Pot"].isnull())
        if pot_zero_mask.any():
            df_filtered.loc[pot_zero_mask, "SPR"] = 100.0

        spr_95th = df_filtered["SPR"].quantile(0.95)
        extreme_spr_mask = df_filtered["SPR"] > spr_95th * 2
        if extreme_spr_mask.any():
            df_filtered.loc[extreme_spr_mask, "SPR"] = spr_95th

        spr_median = df_filtered["SPR"].median()
        df_filtered["SPR"] = df_filtered["SPR"].fillna(spr_median)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    for col in feature_columns:
        if col in df_filtered.columns:
            if df_filtered[col].dtype in ["int64", "float64"]:
                df_filtered[col] = df_filtered[col].replace([np.inf, -np.inf], np.nan)
                median_val = df_filtered[col].median()
                if pd.isna(median_val):
                    median_val = 0
                df_filtered[col] = df_filtered[col].fillna(median_val)
            else:
                df_filtered[col] = df_filtered[col].fillna(0)

    # –û—Ç–±–æ—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    available_features = [col for col in feature_columns if col in df_filtered.columns]
    X = df_filtered[available_features].copy()

    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(available_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    y = create_target_variables(df_filtered)

    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    unique_strengths = np.unique(y["hand_strength"])
    min_class_count = min(
        [np.sum(y["hand_strength"] == strength) for strength in unique_strengths]
    )

    # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–µ
    use_stratify = len(df_filtered) >= 10 and min_class_count >= 2

    if not use_stratify:
        print(
            f"‚ö†Ô∏è  –û—Ç–∫–ª—é—á–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑-–∑–∞ –º–∞–ª–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (min_class_count={min_class_count})"
        )

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_hand_train, y_hand_test = train_test_split(
        X,
        y["hand_strength"],
        test_size=0.2,
        random_state=42,
        stratify=y["hand_strength"] if use_stratify else None,
    )

    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è train/test
    train_indices = X_train.index
    test_indices = X_test.index

    y_train = {
        "hand_strength": y["hand_strength"][train_indices],
        "category_probs": y["category_probs"][train_indices],
        "specific_hand": y["specific_hand"][train_indices],
    }
    y_test = {
        "hand_strength": y["hand_strength"][test_indices],
        "category_probs": y["category_probs"][test_indices],
        "specific_hand": y["specific_hand"][test_indices],
    }

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_train_scaled = pd.DataFrame(
        scaler.fit_transform(X_train), columns=X_train.columns
    )
    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    train_dataset = HandRangeDataset(X_train_scaled, y_train)
    test_dataset = HandRangeDataset(X_test_scaled, y_test)

    batch_size = min(32, max(4, len(train_dataset) // 4))
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)

    return {
        "train_loader": train_loader,
        "test_loader": test_loader,
        "X_train": X_train_scaled,
        "X_test": X_test_scaled,
        "y_train": y_train,
        "y_test": y_test,
        "scaler": scaler,
        "feature_columns": available_features,
        "input_dim": len(available_features),
        "include_hole_cards": include_hole_cards,
    }


# ---------------------- 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ----------------------
def train_hand_range_model(
    data_dict, hidden_dim=128, num_layers=3, epochs=20, lr=0.001
):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä—É–∫"""

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    train_size = len(data_dict["train_loader"].dataset)
    test_size = len(data_dict["test_loader"].dataset)
    print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {train_size}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {test_size}")

    if train_size == 0:
        print("–û—à–∏–±–∫–∞: –ø—É—Å—Ç–∞—è –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞!")
        return None, None

    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = HandRangeRWKV(
        input_dim=data_dict["input_dim"], hidden_dim=hidden_dim, num_layers=num_layers
    ).to(device)

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)

    # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
    strength_criterion = nn.CrossEntropyLoss()
    category_criterion = nn.BCEWithLogitsLoss()
    specific_criterion = nn.MSELoss()

    # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
    history = {"train_loss": [], "val_loss": [], "strength_acc": []}
    best_val_loss = float("inf")

    for epoch in range(epochs):
        # –û–±—É—á–µ–Ω–∏–µ
        model.train()
        train_losses = []
        strength_correct = 0
        strength_total = 0

        for batch_idx, (inputs, targets) in enumerate(data_dict["train_loader"]):
            inputs = inputs.to(device)
            target_strength = targets["hand_strength"].to(device)
            target_category = targets["category_probs"].to(device)
            target_specific = targets["specific_hand"].to(device)

            model.reset_states()
            optimizer.zero_grad()

            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            outputs = model(inputs)

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
            strength_loss = strength_criterion(
                outputs["hand_strength"], target_strength
            )
            category_loss = category_criterion(
                outputs["category_probs"], target_category
            )
            specific_loss = specific_criterion(
                outputs["specific_hand"], target_specific
            )

            # –û–±—â–∞—è –ø–æ—Ç–µ—Ä—è
            total_loss = strength_loss + 0.5 * category_loss + 0.3 * specific_loss

            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            train_losses.append(total_loss.item())

            # –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏
            _, predicted = torch.max(outputs["hand_strength"], 1)
            strength_total += target_strength.size(0)
            strength_correct += (predicted == target_strength).sum().item()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_losses = []
        val_strength_correct = 0
        val_strength_total = 0

        with torch.no_grad():
            for inputs, targets in data_dict["test_loader"]:
                inputs = inputs.to(device)
                target_strength = targets["hand_strength"].to(device)
                target_category = targets["category_probs"].to(device)
                target_specific = targets["specific_hand"].to(device)

                model.reset_states()
                outputs = model(inputs)

                # –ü–æ—Ç–µ—Ä–∏
                strength_loss = strength_criterion(
                    outputs["hand_strength"], target_strength
                )
                category_loss = category_criterion(
                    outputs["category_probs"], target_category
                )
                specific_loss = specific_criterion(
                    outputs["specific_hand"], target_specific
                )
                total_loss = strength_loss + 0.5 * category_loss + 0.3 * specific_loss

                val_losses.append(total_loss.item())

                # –¢–æ—á–Ω–æ—Å—Ç—å
                _, predicted = torch.max(outputs["hand_strength"], 1)
                val_strength_total += target_strength.size(0)
                val_strength_correct += (predicted == target_strength).sum().item()

        # –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏
        avg_train_loss = np.mean(train_losses) if train_losses else 0
        avg_val_loss = np.mean(val_losses) if val_losses else 0
        train_strength_acc = strength_correct / max(strength_total, 1)
        val_strength_acc = val_strength_correct / max(val_strength_total, 1)

        history["train_loss"].append(avg_train_loss)
        history["val_loss"].append(avg_val_loss)
        history["strength_acc"].append(val_strength_acc)

        print(f"–≠–ø–æ—Ö–∞ {epoch+1}/{epochs}:")
        print(f"  –ü–æ—Ç–µ—Ä–∏: train={avg_train_loss:.4f}, val={avg_val_loss:.4f}")
        print(
            f"  –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏: train={train_strength_acc:.3f}, val={val_strength_acc:.3f}"
        )

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss

        scheduler.step(avg_val_loss)

    return model, history


# ---------------------- 5. –û—Ü–µ–Ω–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ----------------------
def evaluate_model_performance(model, data_dict, include_hole_cards=True):
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    all_outputs = {
        "strength_pred": [],
        "strength_true": [],
        "category_pred": [],
        "category_true": [],
        "specific_pred": [],
        "specific_true": [],
    }

    with torch.no_grad():
        for inputs, targets in data_dict["test_loader"]:
            inputs = inputs.to(device)
            model.reset_states()
            outputs = model(inputs)

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            _, strength_pred = torch.max(outputs["hand_strength"], 1)
            all_outputs["strength_pred"].extend(strength_pred.cpu().numpy())
            all_outputs["strength_true"].extend(targets["hand_strength"].numpy())

            category_pred = torch.sigmoid(outputs["category_probs"]).cpu().numpy()
            category_true = targets["category_probs"].numpy()
            all_outputs["category_pred"].extend(np.argmax(category_pred, axis=1))
            all_outputs["category_true"].extend(np.argmax(category_true, axis=1))

            all_outputs["specific_pred"].extend(outputs["specific_hand"].cpu().numpy())
            all_outputs["specific_true"].extend(targets["specific_hand"].numpy())

    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import (
        accuracy_score,
        classification_report,
        mean_squared_error,
    )

    strength_accuracy = accuracy_score(
        all_outputs["strength_true"], all_outputs["strength_pred"]
    )
    category_accuracy = accuracy_score(
        all_outputs["category_true"], all_outputs["category_pred"]
    )
    specific_mse = mean_squared_error(
        all_outputs["specific_true"], all_outputs["specific_pred"]
    )

    print(
        f"\n=== –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ ({'—Å –∫–∞—Ä—Ç–∞–º–∏' if include_hole_cards else '–±–µ–∑ –∫–∞—Ä—Ç'}) ==="
    )
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–ª—ã —Ä—É–∫–∏: {strength_accuracy:.3f}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_accuracy:.3f}")
    print(f"MSE –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–æ–≤: {specific_mse:.4f}")

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_names = PokerHandAnalyzer.get_all_categories()
    print(f"\n–û—Ç—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ä—É–∫:")
    print(
        classification_report(
            all_outputs["category_true"],
            all_outputs["category_pred"],
            target_names=category_names,
            zero_division=0,
        )
    )

    return {
        "strength_accuracy": strength_accuracy,
        "category_accuracy": category_accuracy,
        "specific_mse": specific_mse,
        **all_outputs,
    }


def visualize_results(model, data_dict, history, include_hole_cards=True):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""

    # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # –ü–æ—Ç–µ—Ä–∏
    axes[0, 0].plot(history["train_loss"], label="Train")
    axes[0, 0].plot(history["val_loss"], label="Validation")
    axes[0, 0].set_title("–ü–æ—Ç–µ—Ä–∏ –æ–±—É—á–µ–Ω–∏—è")
    axes[0, 0].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[0, 0].set_ylabel("–ü–æ—Ç–µ—Ä–∏")
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # –¢–æ—á–Ω–æ—Å—Ç—å
    axes[0, 1].plot(history["strength_acc"], label="–¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏")
    axes[0, 1].set_title("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–ª—ã —Ä—É–∫–∏")
    axes[0, 1].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[0, 1].set_ylabel("–¢–æ—á–Ω–æ—Å—Ç—å")
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for inputs, targets in data_dict["test_loader"]:
            inputs = inputs.to(device)
            model.reset_states()
            outputs = model(inputs)

            _, strength_pred = torch.max(outputs["hand_strength"], 1)
            all_predictions.extend(strength_pred.cpu().numpy())
            all_targets.extend(targets["hand_strength"].numpy())

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è —Å–∏–ª—ã —Ä—É–∫–∏
    from sklearn.metrics import confusion_matrix

    cm_strength = confusion_matrix(all_targets, all_predictions)

    im1 = axes[1, 0].imshow(cm_strength, interpolation="nearest", cmap=plt.cm.Blues)
    axes[1, 0].set_title("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: –°–∏–ª–∞ —Ä—É–∫–∏")
    axes[1, 0].set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å–∏–ª–∞")
    axes[1, 0].set_ylabel("–ò—Å—Ç–∏–Ω–Ω–∞—è —Å–∏–ª–∞")

    # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –≤ –º–∞—Ç—Ä–∏—Ü—É
    for i in range(cm_strength.shape[0]):
        for j in range(cm_strength.shape[1]):
            axes[1, 0].text(
                j,
                i,
                str(cm_strength[i, j]),
                ha="center",
                va="center",
                color="white" if cm_strength[i, j] > cm_strength.max() / 2 else "black",
            )

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å–∏–ª
    axes[1, 1].hist(
        all_predictions, bins=10, alpha=0.7, label="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ", density=True
    )
    axes[1, 1].hist(all_targets, bins=10, alpha=0.7, label="–ò—Å—Ç–∏–Ω–Ω—ã–µ", density=True)
    axes[1, 1].set_title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Ä—É–∫")
    axes[1, 1].set_xlabel("–°–∏–ª–∞ —Ä—É–∫–∏ (0-9)")
    axes[1, 1].set_ylabel("–ü–ª–æ—Ç–Ω–æ—Å—Ç—å")
    axes[1, 1].legend()

    model_type = "—Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞" if include_hole_cards else "–±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞"
    plt.suptitle(
        f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä—É–∫ ({model_type})", fontsize=16
    )
    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_name = f"training_results_{'with_cards' if include_hole_cards else 'without_cards'}_{timestamp}.png"

    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É plots –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs("plots", exist_ok=True)
    plot_path = os.path.join("plots", plot_name)
    plt.savefig(plot_path, dpi=300, bbox_inches="tight")
    print(f"–ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")

    return fig, plot_path


def predict_hand_ranges(model, data_dict, sample_hands=5):
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"""

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    category_names = PokerHandAnalyzer.get_all_categories()
    rank_names = PokerHandAnalyzer.get_rank_names()

    print(f"\n=== –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ===")

    with torch.no_grad():
        for i, (inputs, targets) in enumerate(data_dict["test_loader"]):
            if i >= sample_hands:
                break

            inputs = inputs.to(device)
            model.reset_states()
            outputs = model(inputs)

            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –±–∞—Ç—á–∞
            sample_idx = 0

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            strength_probs = torch.softmax(outputs["hand_strength"], dim=1)[sample_idx]
            predicted_strength = torch.argmax(strength_probs).item()

            category_probs = torch.sigmoid(outputs["category_probs"])[sample_idx]
            predicted_category = torch.argmax(category_probs).item()

            specific_probs = outputs["specific_hand"][sample_idx]

            # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            true_strength = targets["hand_strength"][sample_idx].item()
            true_category = torch.argmax(targets["category_probs"][sample_idx]).item()

            print(f"\n–ü—Ä–∏–º–µ—Ä {i+1}:")
            print(f"  –ò—Å—Ç–∏–Ω–Ω–∞—è —Å–∏–ª–∞ —Ä—É–∫–∏: {true_strength}")
            print(
                f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å–∏–ª–∞: {predicted_strength} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {strength_probs[predicted_strength]:.3f})"
            )
            print(f"  –ò—Å—Ç–∏–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_names[true_category]}")
            print(
                f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_names[predicted_category]} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {category_probs[predicted_category]:.3f})"
            )

            # –¢–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–∞
            top_ranks = torch.topk(specific_probs, 3)
            print(f"  –¢–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–∞:")
            for j, (prob, rank_idx) in enumerate(
                zip(top_ranks.values, top_ranks.indices)
            ):
                print(f"    {j+1}. {rank_names[rank_idx]}: {prob:.3f}")


# ---------------------- 6. –£—Ç–∏–ª–∏—Ç—ã ----------------------


# 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —É—Ç–∏–ª–∏—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ JSON
def convert_to_json_serializable(obj):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç numpy/torch —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã –¥–ª—è JSON"""
    import numpy as np

    if isinstance(obj, (np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_to_json_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_to_json_serializable(item) for item in obj]
    else:
        return obj


# 5. –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è setup_directories
def setup_directories():
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–ø–æ–∫"""
    directories = [
        "models",
        "plots",
        "data",
        "data/combined",  # –ü–æ–¥–ø–∞–ø–∫–∞ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        "results",
    ]
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    print("üìÅ –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫:")
    for directory in directories:
        print(f"   ‚úÖ {directory}/")


# 2. –§—É–Ω–∫—Ü–∏—è find_data_files –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
def find_data_files(data_dir="data"):
    """–ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ (–∏–≥–Ω–æ—Ä–∏—Ä—É—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ)"""
    if not os.path.exists(data_dir):
        data_dir = "."  # –¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞ –µ—Å–ª–∏ –Ω–µ—Ç –ø–∞–ø–∫–∏ data

    # –ò—â–µ–º CSV —Ñ–∞–π–ª—ã —Å –ø–æ–∫–µ—Ä–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    patterns = ["parsed_*.csv", "*poker*.csv", "*PDOM*.csv", "*.csv"]

    data_files = []
    for pattern in patterns:
        files = glob.glob(os.path.join(data_dir, pattern))
        # –§–∏–ª—å—Ç—Ä—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        files = [f for f in files if "combined" not in os.path.dirname(f)]
        data_files.extend(files)

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    data_files = sorted(list(set(data_files)))
    return data_files


def save_categories_json():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏"""
    categories_info = {
        "hand_categories": PokerHandAnalyzer.HAND_CATEGORIES,
        "all_categories": PokerHandAnalyzer.get_all_categories(),
        "category_mapping": PokerHandAnalyzer.get_category_mapping(),
        "rank_names": PokerHandAnalyzer.get_rank_names(),
        "strength_levels": {
            "0": "–û—á–µ–Ω—å —Å–ª–∞–±–∞—è —Ä—É–∫–∞",
            "1": "–°–ª–∞–±–∞—è —Ä—É–∫–∞",
            "2": "–ù–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–π",
            "3": "–°—Ä–µ–¥–Ω—è—è —Ä—É–∫–∞",
            "4": "–í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–π",
            "5": "–•–æ—Ä–æ—à–∞—è —Ä—É–∫–∞",
            "6": "–°–∏–ª—å–Ω–∞—è —Ä—É–∫–∞",
            "7": "–û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è",
            "8": "–ü—Ä–µ–º–∏—É–º —Ä—É–∫–∞",
            "9": "–õ—É—á—à–∏–µ —Ä—É–∫–∏",
        },
        "description": {
            "categories": "–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–∫–µ—Ä–Ω—ã—Ö —Ä—É–∫ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            "strength_levels": "–£—Ä–æ–≤–Ω–∏ —Å–∏–ª—ã —Ä—É–∫ –æ—Ç 0 (—Å–ª–∞–±–µ–π—à–∏–µ) –¥–æ 9 (—Å–∏–ª—å–Ω–µ–π—à–∏–µ)",
            "rank_names": "–ù–∞–∑–≤–∞–Ω–∏—è —Ä–∞–Ω–≥–æ–≤ –∫–∞—Ä—Ç –æ—Ç 2 –¥–æ Ace",
        },
    }

    os.makedirs("results", exist_ok=True)
    with open("results/poker_categories.json", "w", encoding="utf-8") as f:
        json.dump(categories_info, f, indent=2, ensure_ascii=False)

    print("–°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: results/poker_categories.json")
    return categories_info


# 6. –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è choose_data_file –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
def choose_data_file():
    """–í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏"""
    data_files = find_data_files()

    if not data_files:
        print("‚ùå CSV —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("–ü–æ–º–µ—Å—Ç–∏—Ç–µ CSV —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É 'data' –∏–ª–∏ –≤ —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é")
        print("(–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ data/combined/)")
        return None

    if len(data_files) == 1:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {data_files[0]}")
        return data_files[0]

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    total_size_mb = 0
    file_stats = []

    for file in data_files:
        size_mb = os.path.getsize(file) / 1024 / 1024
        total_size_mb += size_mb
        file_stats.append((file, size_mb))

    print(
        f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(data_files)} —Ñ–∞–π–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ (–æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size_mb:.1f} MB):"
    )

    # –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –±–æ–ª—å—à–µ 10, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    if len(data_files) > 10:
        print(f"üìä –¢–æ–ø-10 –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (–ø–æ —Ä–∞–∑–º–µ—Ä—É):")
        sorted_files = sorted(file_stats, key=lambda x: x[1], reverse=True)[:10]
        for i, (file, size_mb) in enumerate(sorted_files):
            percentage = (size_mb / total_size_mb) * 100
            print(
                f"  {i+1}. {os.path.basename(file)} ({size_mb:.1f} MB, {percentage:.1f}%)"
            )

        print(f"\nüìã –ü–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–æ–ø-10 —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(data_files)}")
        print(f"üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ü–∏—é 0 –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏
        for i, (file, size_mb) in enumerate(file_stats):
            percentage = (size_mb / total_size_mb) * 100
            print(
                f"  {i+1}. {os.path.basename(file)} ({size_mb:.1f} MB, {percentage:.1f}%)"
            )

    print(f"  0. ‚≠ê –û–ë–™–ï–î–ò–ù–ò–¢–¨ –í–°–ï {len(data_files)} –§–ê–ô–õ–û–í –ò –û–ë–£–ß–ò–¢–¨ –ú–û–©–ù–£–Æ –ú–û–î–ï–õ–¨")
    print(f"\nüí° –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/combined/")

    while True:
        try:
            if len(data_files) > 10:
                choice = input(
                    f"\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (0=–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ, 1-10=—Ç–æ–ø —Ñ–∞–π–ª—ã): "
                ).strip()
            else:
                choice = input(
                    f"\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (0-{len(data_files)}, 0=–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ): "
                ).strip()

            if choice.lower() in ["q", "quit", "exit"]:
                return None

            choice_idx = int(choice)

            if choice_idx == 0:
                print(
                    f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ {len(data_files)} —Ñ–∞–π–ª–æ–≤ –∏ –æ–±—É—á–∏—Ç—å –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å"
                )
                return "COMBINE_ALL"
            elif len(data_files) > 10:
                # –î–ª—è –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ - –≤—ã–±–∏—Ä–∞–µ–º –∏–∑ —Ç–æ–ø-10
                if 1 <= choice_idx <= 10:
                    sorted_files = sorted(file_stats, key=lambda x: x[1], reverse=True)
                    selected_file = sorted_files[choice_idx - 1][0]
                    print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {selected_file}")
                    return selected_file
                else:
                    print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ 10")
            else:
                # –î–ª—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ - –≤—ã–±–∏—Ä–∞–µ–º –∏–∑ –≤—Å–µ—Ö
                if 1 <= choice_idx <= len(data_files):
                    selected_file = data_files[choice_idx - 1]
                    print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {selected_file}")
                    return selected_file
                else:
                    print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 0 –¥–æ {len(data_files)}")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
        except KeyboardInterrupt:
            print("\nüëã –í—ã—Ö–æ–¥...")
            return None


def combine_all_data_files():
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç"""
    data_files = find_data_files()

    if not data_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        return None

    print(f"\nüîó === –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï {len(data_files)} –§–ê–ô–õ–û–í ===")

    all_dataframes = []
    total_records = 0
    total_showdowns = 0

    for i, data_path in enumerate(data_files, 1):
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª {i}/{len(data_files)}: {data_path}")

        try:
            df = pd.read_csv(data_path)

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –¥–∞–Ω–Ω—ã—Ö
            df["source_file"] = os.path.basename(data_path)
            df["file_index"] = i

            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            showdowns_in_file = (
                (df["Showdown_1"].notna()) & (df["Showdown_2"].notna())
            ).sum()

            print(f"   üìä –†–∞–∑–º–µ—Ä: {len(df):,} —Å—Ç—Ä–æ–∫, —à–æ—É–¥–∞—É–Ω–æ–≤: {showdowns_in_file:,}")

            all_dataframes.append(df)
            total_records += len(df)
            total_showdowns += showdowns_in_file

        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {data_path}: {e}")
            continue

    if not all_dataframes:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        return None

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    print(f"\nüîÑ –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
    combined_df = pd.concat(all_dataframes, ignore_index=True, sort=False)

    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
    print(f"   üìà –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_records:,} —Å—Ç—Ä–æ–∫")
    print(f"   üÉè –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–æ—É–¥–∞—É–Ω–æ–≤: {total_showdowns:,}")
    print(
        f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º: {total_showdowns/total_records*100:.1f}%"
    )
    print(f"   üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ñ–∞–π–ª–æ–≤: {len(data_files)}")

    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫—É –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    combined_dir = os.path.join("data", "combined")
    os.makedirs(combined_dir, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –ø–æ–¥–ø–∞–ø–∫—É
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_filename = os.path.join(
        combined_dir, f"combined_poker_data_{timestamp}.csv"
    )

    combined_df.to_csv(combined_filename, index=False)
    print(f"üíæ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {combined_filename}")

    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ —Ñ–∞–π–ª–∞–º
    file_summary = {}
    for file_path in data_files:
        file_df = combined_df[combined_df["source_file"] == os.path.basename(file_path)]
        file_showdowns = (
            (file_df["Showdown_1"].notna()) & (file_df["Showdown_2"].notna())
        ).sum()

        file_summary[file_path] = {
            "records": len(file_df),
            "showdowns": int(file_showdowns),
            "showdown_percentage": (
                float(file_showdowns / len(file_df) * 100) if len(file_df) > 0 else 0
            ),
        }

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É
    summary_path = f"results/data_combination_summary_{timestamp}.json"
    combination_summary = {
        "timestamp": datetime.now().isoformat(),
        "total_files": len(data_files),
        "total_records": int(total_records),
        "total_showdowns": int(total_showdowns),
        "combined_file": combined_filename,
        "source_files": file_summary,
    }

    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(combination_summary, f, indent=2, ensure_ascii=False)

    print(f"üìã –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_path}")

    return combined_filename, combination_summary


def process_all_files():
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ - –ù–û–í–ê–Ø –í–ï–†–°–ò–Ø —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö"""

    print(f"\nüöÄ === –ú–ê–°–°–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –° –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï–ú –î–ê–ù–ù–´–• ===")

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    result = combine_all_data_files()
    if result is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã")
        return

    combined_filename, combination_summary = result

    # –¢–µ–ø–µ—Ä—å –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüéØ === –û–ë–£–ß–ï–ù–ò–ï –ù–ê –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–• ===")
    print(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª: {combined_filename}")
    print(f"üìä –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–æ—É–¥–∞—É–Ω–æ–≤: {combination_summary['total_showdowns']:,}")

    if combination_summary["total_showdowns"] < 50:
        print(
            "‚ö†Ô∏è  –î–∞–∂–µ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö —Å —à–æ—É–¥–∞—É–Ω–æ–º –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!"
        )
        return

    results = {}
    all_plots = []

    # –û–±—É—á–∞–µ–º –æ–±–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    for model_type, include_cards in [("–ë–ï–ó –∫–∞—Ä—Ç", False), ("–° –∫–∞—Ä—Ç–∞–º–∏", True)]:
        print(f"\n{'='*80}")
        print(f"üé≤ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_type} –∏–≥—Ä–æ–∫–∞ –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        print(f"{'='*80}")

        try:
            data_dict = prepare_hand_range_data(
                combined_filename, include_hole_cards=include_cards
            )

            if data_dict is not None:
                # –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å —Ö–æ—Ä–æ—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                model, history = train_hand_range_model(
                    data_dict,
                    hidden_dim=128,  # –ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤
                    num_layers=3,  # –ë–æ–ª—å—à–µ —Å–ª–æ–µ–≤
                    epochs=25,  # –ë–æ–ª—å—à–µ —ç–ø–æ—Ö
                    lr=0.001,
                )

                # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                performance = evaluate_model_performance(
                    model, data_dict, include_hole_cards=include_cards
                )

                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                fig, plot_path = visualize_results(
                    model, data_dict, history, include_cards
                )
                all_plots.append(plot_path)
                plt.show()

                # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                predict_hand_ranges(model, data_dict, sample_hands=5)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                model_path, best_path = save_best_model(
                    model, data_dict, performance, include_cards
                )

                model_key = "with_cards" if include_cards else "without_cards"
                results[model_key] = performance

                print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_type} –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                print(
                    f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏: {performance['strength_accuracy']:.3f}"
                )
                print(
                    f"   üè∑Ô∏è  –¢–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {performance['category_accuracy']:.3f}"
                )
                print(f"   üìä MSE —Ä–∞–Ω–≥–æ–≤: {performance['specific_mse']:.4f}")

            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏ {model_type}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_type}: {e}")
            import traceback

            traceback.print_exc()
            continue

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    if "with_cards" in results and "without_cards" in results:
        print(f"\n" + "=" * 80)
        print(f"üèÜ === –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô (–Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö) ===")

        with_cards_acc = results["with_cards"]["strength_accuracy"]
        without_cards_acc = results["without_cards"]["strength_accuracy"]

        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_acc:.3f}")
        print(f"   üé≤ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ë–ï–ó –∫–∞—Ä—Ç: {without_cards_acc:.3f}")
        print(f"   üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_acc - without_cards_acc:.3f}")

        if with_cards_acc > without_cards_acc:
            print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        else:
            print(
                f"   üéØ –ú–æ–¥–µ–ª—å –±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            )

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "combined_data_file": combined_filename,
            "data_combination_summary": combination_summary,
            "models": {
                "with_cards": {
                    "strength_accuracy": float(with_cards_acc),
                    "category_accuracy": float(
                        results["with_cards"]["category_accuracy"]
                    ),
                    "specific_mse": float(results["with_cards"]["specific_mse"]),
                },
                "without_cards": {
                    "strength_accuracy": float(without_cards_acc),
                    "category_accuracy": float(
                        results["without_cards"]["category_accuracy"]
                    ),
                    "specific_mse": float(results["without_cards"]["specific_mse"]),
                },
            },
            "plots": all_plots,
            "training_summary": {
                "total_source_files": combination_summary["total_files"],
                "total_records_used": combination_summary["total_records"],
                "total_showdowns_used": combination_summary["total_showdowns"],
                "models_trained": len(results),
            },
        }

        report_path = f"results/combined_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)

        print(f"   üìã –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    print(f"\nüéâ === –û–ë–£–ß–ï–ù–ò–ï –ù–ê –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù–û ===")
    print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   üìÅ –§–∞–π–ª–æ–≤: {combination_summary['total_files']}")
    print(f"   üìà –ó–∞–ø–∏—Å–µ–π: {combination_summary['total_records']:,}")
    print(f"   üÉè –®–æ—É–¥–∞—É–Ω–æ–≤: {combination_summary['total_showdowns']:,}")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–∞—Ö models/, plots/, results/")

    return results


def save_best_model(model, data_dict, performance, include_hole_cards):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_type = "with_cards" if include_hole_cards else "without_cards"

    model_name = f"hand_range_model_{model_type}"
    model_file = f"{model_name}_{timestamp}.pth"

    os.makedirs("models", exist_ok=True)
    model_path = os.path.join("models", model_file)

    torch.save(
        {
            "model_state": model.state_dict(),
            "scaler": data_dict["scaler"],
            "feature_columns": data_dict["feature_columns"],
            "input_dim": data_dict["input_dim"],
            "include_hole_cards": include_hole_cards,
            "performance": performance,
            "timestamp": timestamp,
            "categories": PokerHandAnalyzer.get_all_categories(),
            "category_mapping": PokerHandAnalyzer.get_category_mapping(),
            "rank_names": PokerHandAnalyzer.get_rank_names(),
        },
        model_path,
    )

    # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_path = os.path.join("models", f"{model_name}_best.pth")
    if os.path.exists(best_model_path):
        os.remove(best_model_path)

    # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è –∂–µ—Å—Ç–∫–æ–π —Å—Å—ã–ª–∫–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –û–°)
    import shutil

    shutil.copy2(model_path, best_model_path)

    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:")
    print(f"   üìÅ {model_path}")
    print(f"   üîó {best_model_path} (–ª—É—á—à–∞—è)")

    return model_path, best_model_path


def smart_train_val_test_split(df, test_size=0.15, val_size=0.15, random_state=42):
    """
    –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: –ø–æ –∏–≥—Ä–æ–∫–∞–º + –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    """
    print(f"üéØ === –£–ú–ù–û–ï –†–ê–ó–î–ï–õ–ï–ù–ò–ï –î–ê–ù–ù–´–• ===")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_cols = ["PlayerID", "Timestamp", "HandID"]
    missing_cols = [col for col in required_cols if col not in df.columns]

    if missing_cols:
        print(f"‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
        print(f"üìù –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ-–∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è...")

        # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ PlayerID –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if "PlayerID" not in df.columns:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é —Ñ–∞–π–ª–∞ –∏ –º–µ—Å—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–≥—Ä–æ–∫–∞
            if "source_file" in df.columns and "Seat" in df.columns:
                df["PlayerID"] = (
                    df["source_file"].astype(str) + "_seat_" + df["Seat"].astype(str)
                )
            else:
                # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ - –ø—Ä–æ—Å—Ç–æ –≥—Ä—É–ø–ø—ã —Å—Ç—Ä–æ–∫
                df["PlayerID"] = (df.index // 50).astype(str)  # –≥—Ä—É–ø–ø—ã –ø–æ 50 –∑–∞–ø–∏—Å–µ–π

        # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ Timestamp –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if "Timestamp" not in df.columns:
            if "Round" in df.columns:
                df["Timestamp"] = df["Round"]
            else:
                df["Timestamp"] = df.index

        # –°–æ–∑–¥–∞–µ–º –ø—Å–µ–≤–¥–æ HandID –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if "HandID" not in df.columns:
            if "Round" in df.columns:
                df["HandID"] = df["Round"].astype(str) + "_" + df.index.astype(str)
            else:
                df["HandID"] = (df.index // 10).astype(str)  # –≥—Ä—É–ø–ø—ã –ø–æ 10 –∑–∞–ø–∏—Å–µ–π

    # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    unique_players = df["PlayerID"].unique()
    total_players = len(unique_players)
    total_records = len(df)

    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   üë• –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–≥—Ä–æ–∫–æ–≤: {total_players:,}")
    print(f"   üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {total_records:,}")
    print(f"   üìä –ó–∞–ø–∏—Å–µ–π –Ω–∞ –∏–≥—Ä–æ–∫–∞: {total_records/total_players:.1f}")

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –ø–æ –∏–≥—Ä–æ–∫–∞–º
    player_counts = df["PlayerID"].value_counts()
    print(f"   üìã –ú–∏–Ω –∑–∞–ø–∏—Å–µ–π —É –∏–≥—Ä–æ–∫–∞: {player_counts.min()}")
    print(f"   üìã –ú–∞–∫—Å –∑–∞–ø–∏—Å–µ–π —É –∏–≥—Ä–æ–∫–∞: {player_counts.max()}")
    print(f"   üìã –ú–µ–¥–∏–∞–Ω–∞ –∑–∞–ø–∏—Å–µ–π: {player_counts.median():.0f}")

    # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–≥—Ä–æ–∫–æ–≤ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–∏—Å–µ–π
    min_records_per_player = 5  # –º–∏–Ω–∏–º—É–º –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    good_players = player_counts[player_counts >= min_records_per_player].index

    if len(good_players) < total_players:
        filtered_out = total_players - len(good_players)
        print(
            f"   üö® –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {filtered_out} –∏–≥—Ä–æ–∫–æ–≤ —Å < {min_records_per_player} –∑–∞–ø–∏—Å–µ–π"
        )
        df = df[df["PlayerID"].isin(good_players)]
        unique_players = good_players
        total_players = len(unique_players)

    print(f"   ‚úÖ –ò—Ç–æ–≥–æ –∏–≥—Ä–æ–∫–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: {total_players}")
    print(f"   ‚úÖ –ò—Ç–æ–≥–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(df):,}")

    # –†–∞–∑–¥–µ–ª—è–µ–º –∏–≥—Ä–æ–∫–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø—ã
    np.random.seed(random_state)
    shuffled_players = np.random.permutation(unique_players)

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø
    test_players_count = max(1, int(total_players * test_size))
    val_players_count = max(1, int(total_players * val_size))
    train_players_count = total_players - test_players_count - val_players_count

    print(f"\nüéØ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏–≥—Ä–æ–∫–æ–≤:")
    print(
        f"   üéì Train: {train_players_count} –∏–≥—Ä–æ–∫–æ–≤ ({train_players_count/total_players*100:.1f}%)"
    )
    print(
        f"   üîç Validation: {val_players_count} –∏–≥—Ä–æ–∫–æ–≤ ({val_players_count/total_players*100:.1f}%)"
    )
    print(
        f"   üß™ Test: {test_players_count} –∏–≥—Ä–æ–∫–æ–≤ ({test_players_count/total_players*100:.1f}%)"
    )

    # –ù–∞–∑–Ω–∞—á–∞–µ–º –∏–≥—Ä–æ–∫–æ–≤ –≤ –≥—Ä—É–ø–ø—ã
    train_players = shuffled_players[:train_players_count]
    val_players = shuffled_players[
        train_players_count : train_players_count + val_players_count
    ]
    test_players = shuffled_players[train_players_count + val_players_count :]

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_data_list = []
    val_data_list = []
    test_data_list = []

    # –î–ª—è train –∏–≥—Ä–æ–∫–æ–≤: —Ä–∞–Ω–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ train, –ø–æ–∑–¥–Ω–∏–µ –≤ validation
    print(f"\nüìÖ –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ train –∏–≥—Ä–æ–∫–æ–≤...")
    for player_id in train_players:
        player_data = df[df["PlayerID"] == player_id].copy()
        player_data = player_data.sort_values("Timestamp")

        # 80% —Ä–∞–Ω–Ω–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏–≥—Ä–æ–∫–∞ –≤ train, 20% –ø–æ–∑–¥–Ω–∏—Ö –≤ validation
        split_idx = max(1, int(len(player_data) * 0.8))
        train_data_list.append(player_data.iloc[:split_idx])

        if len(player_data) > split_idx:
            val_data_list.append(player_data.iloc[split_idx:])

    # –î–ª—è validation –∏–≥—Ä–æ–∫–æ–≤: –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤ validation
    print(f"üìù –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ validation –∏–≥—Ä–æ–∫–æ–≤...")
    for player_id in val_players:
        player_data = df[df["PlayerID"] == player_id].copy()
        val_data_list.append(player_data)

    # –î–ª—è test –∏–≥—Ä–æ–∫–æ–≤: –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤ test
    print(f"üß™ –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ test –∏–≥—Ä–æ–∫–æ–≤...")
    for player_id in test_players:
        player_data = df[df["PlayerID"] == player_id].copy()
        test_data_list.append(player_data)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    train_df = (
        pd.concat(train_data_list, ignore_index=True)
        if train_data_list
        else pd.DataFrame()
    )
    val_df = (
        pd.concat(val_data_list, ignore_index=True) if val_data_list else pd.DataFrame()
    )
    test_df = (
        pd.concat(test_data_list, ignore_index=True)
        if test_data_list
        else pd.DataFrame()
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è:")
    print(f"   üéì Train: {len(train_df):,} –∑–∞–ø–∏—Å–µ–π ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   üîç Validation: {len(val_df):,} –∑–∞–ø–∏—Å–µ–π ({len(val_df)/len(df)*100:.1f}%)")
    print(f"   üß™ Test: {len(test_df):,} –∑–∞–ø–∏—Å–µ–π ({len(test_df)/len(df)*100:.1f}%)")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∏–≥—Ä–æ–∫–æ–≤
    train_player_set = (
        set(train_df["PlayerID"].unique()) if len(train_df) > 0 else set()
    )
    val_player_set = set(val_df["PlayerID"].unique()) if len(val_df) > 0 else set()
    test_player_set = set(test_df["PlayerID"].unique()) if len(test_df) > 0 else set()

    train_val_overlap = train_player_set & val_player_set
    train_test_overlap = train_player_set & test_player_set
    val_test_overlap = val_player_set & test_player_set

    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏–≥—Ä–æ–∫–æ–≤:")
    print(f"   Train ‚à© Val: {len(train_val_overlap)} –∏–≥—Ä–æ–∫–æ–≤ (–æ–∂–∏–¥–∞–µ—Ç—Å—è > 0)")
    print(f"   Train ‚à© Test: {len(train_test_overlap)} –∏–≥—Ä–æ–∫–æ–≤ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0)")
    print(f"   Val ‚à© Test: {len(val_test_overlap)} –∏–≥—Ä–æ–∫–æ–≤ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0)")

    if train_test_overlap or val_test_overlap:
        print(f"‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ï—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –∏–≥—Ä–æ–∫–æ–≤ –º–µ–∂–¥—É train/val –∏ test!")
    else:
        print(f"‚úÖ –û—Ç–ª–∏—á–Ω–æ! –ù–µ—Ç —É—Ç–µ—á–µ–∫ –º–µ–∂–¥—É train/val –∏ test –≤—ã–±–æ—Ä–∫–∞–º–∏")

    return train_df, val_df, test_df


def create_player_sequences(df, max_sequence_length=20, min_sequence_length=3):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–µ–π—Å—Ç–≤–∏–π –∏–≥—Ä–æ–∫–æ–≤ –¥–ª—è RWKV
    """
    print(f"üîÑ === –°–û–ó–î–ê–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô ===")
    print(f"   üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {max_sequence_length}")
    print(f"   üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {min_sequence_length}")

    sequences = []
    sequence_info = []

    for player_id in df["PlayerID"].unique():
        player_data = df[df["PlayerID"] == player_id].copy()
        player_data = player_data.sort_values("Timestamp")

        # –°–æ–∑–¥–∞–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–≥—Ä–æ–∫–∞
        for start_idx in range(len(player_data)):
            for end_idx in range(
                start_idx + min_sequence_length,
                min(start_idx + max_sequence_length + 1, len(player_data) + 1),
            ):

                sequence = player_data.iloc[start_idx:end_idx].copy()

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                sequence_info.append(
                    {
                        "player_id": player_id,
                        "sequence_length": len(sequence),
                        "start_idx": start_idx,
                        "end_idx": end_idx,
                        "start_time": sequence["Timestamp"].iloc[0],
                        "end_time": sequence["Timestamp"].iloc[-1],
                    }
                )

                sequences.append(sequence)

    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(sequences):,} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üìä –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {np.mean([len(seq) for seq in sequences]):.1f}")
    print(f"   üìä –ò–≥—Ä–æ–∫–æ–≤: {df['PlayerID'].nunique()}")

    return sequences, sequence_info


def prepare_sequence_hand_range_data_with_hm3(
    file_path,
    include_hole_cards=True,
    max_sequence_length="auto",
    balance_strategy="adaptive",
    use_hm3_classification=True,  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Ä—É–∫
    """
    print(f"üéØ === –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –° –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–Ø–ú–ò ===")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if isinstance(file_path, str):
        df = pd.read_csv(file_path)
    else:
        df = file_path

    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–µ–π —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏
    mask = (df["Showdown_1"].notna()) & (df["Showdown_2"].notna())
    df_filtered = df[mask].copy().reset_index(drop=True)

    print(f"üé≤ –ù–∞–π–¥–µ–Ω–æ {len(df_filtered)} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏")

    if len(df_filtered) == 0:
        print("‚ùå –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏!")
        return None

    # –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
    if use_hm3_classification:
        print("üÉè –ê–Ω–∞–ª–∏–∑ —Ä—É–∫ –ø–æ —Å–∏—Å—Ç–µ–º–µ HM3 (73 —Ç–∏–ø–∞)...")
        df_filtered = add_hand_evaluation_to_dataframe(df_filtered)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä–æ–π
        df_filtered["hand_strength"] = df_filtered["hand_strength_class"]
        df_filtered["hand_category"] = df_filtered["hand_type_hm3"]
    else:
        # –°—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞ (–ø—Ä–µ—Ñ–ª–æ–ø —Å–∏–ª–∞)
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—ã —Ä—É–∫ (—Å—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞)...")
        analyzer = PokerHandAnalyzer()
        hand_analysis = df_filtered.apply(
            lambda row: analyzer.analyze_hand_strength(
                row["Showdown_1"], row["Showdown_2"]
            ),
            axis=1,
        )
        df_filtered["hand_strength"] = [x[0] for x in hand_analysis]
        df_filtered["hand_category"] = [x[1] for x in hand_analysis]

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
    column_mapping = {
        "PlayerId": "PlayerID",
        "Hand": "HandID",
        "StartDateUtc": "Timestamp",
    }

    for old_col, new_col in column_mapping.items():
        if old_col in df_filtered.columns and new_col not in df_filtered.columns:
            df_filtered[new_col] = df_filtered[old_col]
            print(f"üîÑ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞: {old_col} ‚Üí {new_col}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    if "PlayerID" not in df_filtered.columns:
        df_filtered["PlayerID"] = (
            df_filtered["Seat"].astype(str)
            + "_"
            + df_filtered.get("TournamentNumber", df_filtered.index // 100).astype(str)
        )

    if "Timestamp" not in df_filtered.columns:
        df_filtered["Timestamp"] = df_filtered.get("Round", df_filtered.index)

    if "HandID" not in df_filtered.columns:
        df_filtered["HandID"] = df_filtered.get("Hand", df_filtered.index // 10)

    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Ä—É–∫:")
    strength_dist = df_filtered["hand_strength"].value_counts().sort_index()

    if use_hm3_classification:
        class_names = ["–ú—É—Å–æ—Ä/–î—Ä–æ", "–°–ª–∞–±—ã–µ", "–°—Ä–µ–¥–Ω–∏–µ", "–°–∏–ª—å–Ω—ã–µ", "–ú–æ–Ω—Å—Ç—Ä—ã"]
        for strength, count in strength_dist.items():
            name = (
                class_names[strength]
                if strength < len(class_names)
                else f"–ö–ª–∞—Å—Å {strength}"
            )
            print(f"   {name}: {count} —Ä—É–∫ ({count/len(df_filtered)*100:.1f}%)")
    else:
        for strength, count in strength_dist.items():
            print(
                f"   –°–∏–ª–∞ {strength}: {count} —Ä—É–∫ ({count/len(df_filtered)*100:.1f}%)"
            )

    # –ê–Ω–∞–ª–∏–∑ —Ä—É–∫ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print("üîç –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—ã —Ä—É–∫...")
    analyzer = PokerHandAnalyzer()

    hand_analysis = df_filtered.apply(
        lambda row: analyzer.analyze_hand_strength(
            row["Showdown_1"], row["Showdown_2"]
        ),
        axis=1,
    )

    df_filtered["hand_strength"] = [x[0] for x in hand_analysis]
    df_filtered["hand_category"] = [x[1] for x in hand_analysis]

    print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Ä—É–∫:")
    strength_dist = df_filtered["hand_strength"].value_counts().sort_index()
    for strength, count in strength_dist.items():
        print(f"   –°–∏–ª–∞ {strength}: {count} —Ä—É–∫ ({count/len(df_filtered)*100:.1f}%)")

    # –£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüéØ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    train_df, val_df, test_df = smart_train_val_test_split(df_filtered)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_columns = [
        "Level",
        "Pot",
        "Stack",
        "SPR",
        "Street_id",
        "Round",
        "ActionOrder",
        "Seat",
        "Dealer",
        "Bet",
        "Allin",
        "PlayerWins",
        "WinAmount",
    ]

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç—ã —Å—Ç–æ–ª–∞
    board_columns = ["Card1", "Card2", "Card3", "Card4", "Card5"]
    for col in board_columns:
        if col in df_filtered.columns:
            df_filtered[f"{col}_rank"], df_filtered[f"{col}_suit"] = zip(
                *df_filtered[col].apply(
                    lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
                )
            )
            feature_columns.extend([f"{col}_rank", f"{col}_suit"])

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if include_hole_cards:
        print("üÉè –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç—ã –∏–≥—Ä–æ–∫–∞ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏...")
        df_filtered["hole1_rank"], df_filtered["hole1_suit"] = zip(
            *df_filtered["Showdown_1"].apply(
                lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
            )
        )
        df_filtered["hole2_rank"], df_filtered["hole2_suit"] = zip(
            *df_filtered["Showdown_2"].apply(
                lambda x: analyzer.parse_card(x) if pd.notna(x) else (0, 0)
            )
        )
        feature_columns.extend(["hole1_rank", "hole1_suit", "hole2_rank", "hole2_suit"])

    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    encoders = {}

    if "Position" in df_filtered.columns:
        encoders["position"] = LabelEncoder()
        df_filtered["Position_encoded"] = encoders["position"].fit_transform(
            df_filtered["Position"].fillna("Unknown")
        )
        feature_columns.append("Position_encoded")

    if "Action" in df_filtered.columns:
        encoders["action"] = LabelEncoder()
        df_filtered["Action_encoded"] = encoders["action"].fit_transform(
            df_filtered["Action"].fillna("Unknown")
        )
        feature_columns.append("Action_encoded")

    if "TypeBuyIn" in df_filtered.columns:
        encoders["buyin"] = LabelEncoder()
        df_filtered["TypeBuyIn_encoded"] = encoders["buyin"].fit_transform(
            df_filtered["TypeBuyIn"].fillna("Unknown")
        )
        feature_columns.append("TypeBuyIn_encoded")

    # –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—ã
    for split_df in [train_df, val_df, test_df]:
        for col in df_filtered.columns:
            if (
                col.endswith("_encoded")
                or col.endswith("_rank")
                or col.endswith("_suit")
            ):
                split_df[col] = df_filtered.loc[split_df.index, col]

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    print("üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    for split_df in [train_df, val_df, test_df]:
        # SPR
        if "SPR" in split_df.columns:
            pot_zero_mask = (split_df["Pot"] == 0) | (split_df["Pot"].isnull())
            split_df.loc[pot_zero_mask, "SPR"] = 100.0

            spr_95th = split_df["SPR"].quantile(0.95)
            extreme_spr_mask = split_df["SPR"] > spr_95th * 2
            split_df.loc[extreme_spr_mask, "SPR"] = spr_95th

            spr_median = split_df["SPR"].median()
            split_df["SPR"] = split_df["SPR"].fillna(spr_median)

        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        for col in feature_columns:
            if col in split_df.columns:
                if split_df[col].dtype in ["int64", "float64"]:
                    split_df[col] = split_df[col].replace([np.inf, -np.inf], np.nan)
                    median_val = split_df[col].median()
                    if pd.isna(median_val):
                        median_val = 0
                    split_df[col] = split_df[col].fillna(median_val)
                else:
                    split_df[col] = split_df[col].fillna(0)

    # –û—Ç–±–æ—Ä –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    available_features = [col for col in feature_columns if col in train_df.columns]
    print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(available_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("üìä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    scaler = StandardScaler()

    # –û–±—É—á–∞–µ–º scaler —Ç–æ–ª—å–∫–æ –Ω–∞ train –¥–∞–Ω–Ω—ã—Ö
    scaler.fit(train_df[available_features])

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ –≤—Å–µ–º –≤—ã–±–æ—Ä–∫–∞–º
    train_scaled = pd.DataFrame(
        scaler.transform(train_df[available_features]),
        columns=available_features,
        index=train_df.index,
    )
    val_scaled = pd.DataFrame(
        scaler.transform(val_df[available_features]),
        columns=available_features,
        index=val_df.index,
    )
    test_scaled = pd.DataFrame(
        scaler.transform(test_df[available_features]),
        columns=available_features,
        index=test_df.index,
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±–æ—Ä–∫–∏
    print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π...")

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if max_sequence_length == "auto":
        sequence_params = analyze_optimal_sequence_length(df_filtered)
        max_sequence_length = sequence_params["max_length"]
        print(
            f"\n‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {max_sequence_length}"
        )
    else:
        # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–æ –≤—Ä—É—á–Ω—É—é, —Å–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        sequence_params = {
            "min_length": 3,
            "recommended_length": min(10, max_sequence_length),
            "max_length": max_sequence_length,
        }

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    train_sequences, train_info, _ = create_adaptive_sequences(
        train_df, sequence_params, balance_strategy
    )

    # Train –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    train_sequences, train_seq_info = create_player_sequences(
        train_df, max_sequence_length=max_sequence_length
    )
    train_sequences_with_targets, train_targets = create_sequences_with_targets(
        train_sequences, available_features, train_scaled
    )

    # Validation –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    val_sequences, val_seq_info = create_player_sequences(
        val_df, max_sequence_length=max_sequence_length
    )
    val_sequences_with_targets, val_targets = create_sequences_with_targets(
        val_sequences, available_features, val_scaled
    )

    # Test –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    test_sequences, test_seq_info = create_player_sequences(
        test_df, max_sequence_length=max_sequence_length
    )
    test_sequences_with_targets, test_targets = create_sequences_with_targets(
        test_sequences, available_features, test_scaled
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
    print("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")

    train_dataset = SequenceHandRangeDataset(
        train_sequences_with_targets,
        available_features,
        train_targets,
        max_sequence_length,
    )
    val_dataset = SequenceHandRangeDataset(
        val_sequences_with_targets, available_features, val_targets, max_sequence_length
    )
    test_dataset = SequenceHandRangeDataset(
        test_sequences_with_targets,
        available_features,
        test_targets,
        max_sequence_length,
    )

    # DataLoaders
    batch_size = min(
        16, max(2, len(train_dataset) // 8)
    )  # –ú–µ–Ω—å—à–∏–π batch_size –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
    print(f"   üéì Train: {len(train_dataset)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üîç Validation: {len(val_dataset)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üß™ Test: {len(test_dataset)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")

    return {
        "train_loader": train_loader,
        "val_loader": val_loader,
        "test_loader": test_loader,
        "scaler": scaler,
        "encoders": encoders,
        "feature_columns": available_features,
        "input_dim": len(available_features),
        "max_sequence_length": max_sequence_length,
        "include_hole_cards": include_hole_cards,
        "train_sequences": train_sequences_with_targets,
        "val_sequences": val_sequences_with_targets,
        "test_sequences": test_sequences_with_targets,
    }


def create_sequences_with_targets(sequences, feature_columns, scaled_data_dict):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
    """
    print(f"üéØ –°–æ–∑–¥–∞–Ω–∏–µ {len(sequences)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å —Ü–µ–ª–µ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏...")

    targets = {"hand_strength": [], "category_probs": [], "specific_hand": []}
    valid_sequences = []
    analyzer = PokerHandAnalyzer()

    for seq_df in sequences:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ –ø—É—Å—Ç–∞—è
            if len(seq_df) == 0:
                continue

            # –ë–µ—Ä–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            last_row = seq_df.iloc[-1]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if (
                pd.notna(last_row.get("hand_strength"))
                and pd.notna(last_row.get("Showdown_1"))
                and pd.notna(last_row.get("Showdown_2"))
            ):

                # –°–∏–ª–∞ —Ä—É–∫–∏
                targets["hand_strength"].append(int(last_row["hand_strength"]))

                # –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ä—É–∫–∏
                category_mapping = PokerHandAnalyzer.get_category_mapping()
                category_idx = category_mapping.get(
                    last_row.get("hand_category", "other"), 8
                )

                category_probs = np.zeros(9)
                category_probs[category_idx] = 1.0
                targets["category_probs"].append(category_probs)

                # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–∞–Ω–≥–∏ –∫–∞—Ä—Ç
                specific_hand = np.zeros(13)
                card1 = last_row["Showdown_1"]
                card2 = last_row["Showdown_2"]

                rank1, _ = analyzer.parse_card(card1)
                rank2, _ = analyzer.parse_card(card2)

                if rank1 is not None and rank2 is not None:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–Ω–≥–∏ –≤ –∏–Ω–¥–µ–∫—Å—ã (A=14 -> 12, K=13 -> 11, ..., 2=2 -> 0)
                    rank1_idx = max(0, min(12, rank1 - 2))
                    rank2_idx = max(0, min(12, rank2 - 2))

                    specific_hand[rank1_idx] = 0.6
                    specific_hand[rank2_idx] = 0.6

                    # –ù–µ–º–Ω–æ–≥–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–µ —Ä–∞–Ω–≥–∏
                    for offset in [-1, 1]:
                        for rank_idx in [rank1_idx, rank2_idx]:
                            neighbor_idx = rank_idx + offset
                            if 0 <= neighbor_idx < 13:
                                specific_hand[neighbor_idx] = 0.1

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                    if specific_hand.sum() > 0:
                        specific_hand = specific_hand / specific_hand.sum()
                    else:
                        specific_hand = np.ones(13) / 13
                else:
                    specific_hand = np.ones(13) / 13

                targets["specific_hand"].append(specific_hand)
                valid_sequences.append(seq_df)

        except Exception as e:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            continue

    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(valid_sequences)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")

    return valid_sequences, targets


def create_player_sequences(df, max_sequence_length=20, min_sequence_length=3):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–µ–π—Å—Ç–≤–∏–π –∏–≥—Ä–æ–∫–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
    """
    print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–≥—Ä–æ–∫–æ–≤...")
    print(f"   üìè –î–ª–∏–Ω–∞: {min_sequence_length}-{max_sequence_length}")

    sequences = []
    sequence_info = []

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–≥—Ä–æ–∫–∞–º
    for player_id in df["PlayerID"].unique():
        player_data = df[df["PlayerID"] == player_id].copy()

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        if "Timestamp" in player_data.columns:
            player_data = player_data.sort_values("Timestamp")
        elif "Round" in player_data.columns:
            player_data = player_data.sort_values("Round")

        player_records = len(player_data)

        # –ï—Å–ª–∏ —É –∏–≥—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∑–∞–ø–∏—Å–µ–π, —Å–æ–∑–¥–∞–µ–º –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if player_records < min_sequence_length:
            if player_records > 0:
                sequences.append(player_data)
                sequence_info.append(
                    {
                        "player_id": player_id,
                        "sequence_length": player_records,
                        "type": "short_player_sequence",
                    }
                )
            continue

        # –î–ª—è –∏–≥—Ä–æ–∫–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–∏—Å–µ–π —Å–æ–∑–¥–∞–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞
        sequences_created = 0

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ —Å —à–∞–≥–æ–º
        step_size = max(1, max_sequence_length // 4)  # –®–∞–≥ –≤ 1/4 –æ—Ç –º–∞–∫—Å –¥–ª–∏–Ω—ã

        for start_idx in range(0, player_records - min_sequence_length + 1, step_size):
            end_idx = min(start_idx + max_sequence_length, player_records)

            if end_idx - start_idx >= min_sequence_length:
                sequence = player_data.iloc[start_idx:end_idx].copy()
                sequences.append(sequence)

                sequence_info.append(
                    {
                        "player_id": player_id,
                        "sequence_length": len(sequence),
                        "start_idx": start_idx,
                        "end_idx": end_idx,
                        "type": "sliding_window",
                    }
                )

                sequences_created += 1

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ï—Å–ª–∏ —Å–æ–∑–¥–∞–ª–∏ –º–∞–ª–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, –¥–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        if sequences_created < 3 and player_records >= max_sequence_length:
            for _ in range(2):  # –°–æ–∑–¥–∞–µ–º –µ—â–µ 2 —Å–ª—É—á–∞–π–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                start_idx = np.random.randint(
                    0, player_records - min_sequence_length + 1
                )
                seq_length = np.random.randint(
                    min_sequence_length,
                    min(max_sequence_length, player_records - start_idx) + 1,
                )
                end_idx = start_idx + seq_length

                sequence = player_data.iloc[start_idx:end_idx].copy()
                sequences.append(sequence)

                sequence_info.append(
                    {
                        "player_id": player_id,
                        "sequence_length": len(sequence),
                        "start_idx": start_idx,
                        "end_idx": end_idx,
                        "type": "random_segment",
                    }
                )

    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(sequences)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üìä –ò–≥—Ä–æ–∫–æ–≤: {df['PlayerID'].nunique()}")
    print(f"   üìä –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {np.mean([len(seq) for seq in sequences]):.1f}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    type_counts = {}
    for info in sequence_info:
        seq_type = info.get("type", "unknown")
        type_counts[seq_type] = type_counts.get(seq_type, 0) + 1

    print(f"   üìã –ü–æ —Ç–∏–ø–∞–º:")
    for seq_type, count in type_counts.items():
        print(f"      {seq_type}: {count}")

    return sequences, sequence_info


def train_sequence_hand_range_model(
    data_dict, hidden_dim=128, num_layers=3, epochs=25, lr=0.001
):
    """
    –û–±—É—á–µ–Ω–∏–µ RWKV –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    """
    print(f"üöÄ === –û–ë–£–ß–ï–ù–ò–ï RWKV –ú–û–î–ï–õ–ò –° –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–Ø–ú–ò ===")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"üñ•Ô∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–æ–∫
    train_size = len(data_dict["train_loader"].dataset)
    val_size = len(data_dict["val_loader"].dataset)
    test_size = len(data_dict["test_loader"].dataset)

    print(f"üìä –†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–æ–∫:")
    print(f"   üéì Train: {train_size} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üîç Validation: {val_size} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"   üß™ Test: {test_size} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")

    if train_size == 0:
        print("‚ùå –ü—É—Å—Ç–∞—è –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞!")
        return None, None

    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = SequenceHandRangeRWKV(
        input_dim=data_dict["input_dim"],
        hidden_dim=hidden_dim,
        num_layers=num_layers,
        max_sequence_length=data_dict["max_sequence_length"],
    ).to(device)

    print(f"üß† –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞:")
    print(f"   üì• –í—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {data_dict['input_dim']}")
    print(f"   üßÆ –°–∫—Ä—ã—Ç—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤: {hidden_dim}")
    print(f"   üèóÔ∏è  –°–ª–æ–µ–≤ RWKV: {num_layers}")
    print(f"   üìè –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {data_dict['max_sequence_length']}")

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", patience=5, factor=0.5, verbose=True
    )

    # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
    strength_criterion = nn.CrossEntropyLoss()
    category_criterion = nn.BCEWithLogitsLoss()
    specific_criterion = nn.MSELoss()

    # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
    history = {
        "train_loss": [],
        "val_loss": [],
        "train_strength_acc": [],
        "val_strength_acc": [],
        "train_category_acc": [],
        "val_category_acc": [],
        "train_specific_mse": [],
        "val_specific_mse": [],
        "learning_rates": [],
    }

    best_val_loss = float("inf")
    best_model_state = None
    patience_counter = 0
    early_stopping_patience = 8

    print(f"\nüéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {epochs} —ç–ø–æ—Ö...")

    for epoch in range(epochs):
        epoch_start_time = datetime.now()

        # ===================== –û–ë–£–ß–ï–ù–ò–ï =====================
        model.train()
        train_losses = []
        train_strength_correct = 0
        train_strength_total = 0
        train_category_correct = 0
        train_category_total = 0
        train_specific_mse_sum = 0
        train_batches = 0

        print(f"\nüìà –≠–ø–æ—Ö–∞ {epoch+1}/{epochs} - –û–±—É—á–µ–Ω–∏–µ...")

        for batch_idx, (inputs, targets) in enumerate(data_dict["train_loader"]):
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            inputs = inputs.to(device)  # [batch_size, seq_len, features]
            target_strength = targets["hand_strength"].to(device)
            target_category = targets["category_probs"].to(device)
            target_specific = targets["specific_hand"].to(device)
            seq_lengths = targets["sequence_length"].to(device)

            # –í–ê–ñ–ù–û: –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
            model.reset_states()
            optimizer.zero_grad()

            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            outputs = model(inputs)

            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
            strength_loss = strength_criterion(
                outputs["hand_strength"], target_strength
            )
            category_loss = category_criterion(
                outputs["category_probs"], target_category
            )
            specific_loss = specific_criterion(
                outputs["specific_hand"], target_specific
            )

            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ–±—â–∞—è –ø–æ—Ç–µ—Ä—è
            total_loss = strength_loss + 0.5 * category_loss + 0.3 * specific_loss

            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # –ú–µ—Ç—Ä–∏–∫–∏
            train_losses.append(total_loss.item())

            # –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏
            _, predicted_strength = torch.max(outputs["hand_strength"], 1)
            train_strength_total += target_strength.size(0)
            train_strength_correct += (
                (predicted_strength == target_strength).sum().item()
            )

            # –¢–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            predicted_category = (
                torch.sigmoid(outputs["category_probs"]) > 0.5
            ).float()
            train_category_total += target_category.numel()
            train_category_correct += (
                (predicted_category == target_category).sum().item()
            )

            # MSE –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–æ–≤
            train_specific_mse_sum += specific_loss.item()
            train_batches += 1

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            if (batch_idx + 1) % max(1, len(data_dict["train_loader"]) // 10) == 0:
                progress = (batch_idx + 1) / len(data_dict["train_loader"]) * 100
                current_loss = total_loss.item()
                print(f"   üìä {progress:5.1f}% | Loss: {current_loss:.4f}")

        # ===================== –í–ê–õ–ò–î–ê–¶–ò–Ø =====================
        model.eval()
        val_losses = []
        val_strength_correct = 0
        val_strength_total = 0
        val_category_correct = 0
        val_category_total = 0
        val_specific_mse_sum = 0
        val_batches = 0

        print(f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è...")

        with torch.no_grad():
            for inputs, targets in data_dict["val_loader"]:
                inputs = inputs.to(device)
                target_strength = targets["hand_strength"].to(device)
                target_category = targets["category_probs"].to(device)
                target_specific = targets["specific_hand"].to(device)

                model.reset_states()
                outputs = model(inputs)

                # –ü–æ—Ç–µ—Ä–∏
                strength_loss = strength_criterion(
                    outputs["hand_strength"], target_strength
                )
                category_loss = category_criterion(
                    outputs["category_probs"], target_category
                )
                specific_loss = specific_criterion(
                    outputs["specific_hand"], target_specific
                )
                total_loss = strength_loss + 0.5 * category_loss + 0.3 * specific_loss

                val_losses.append(total_loss.item())

                # –ú–µ—Ç—Ä–∏–∫–∏
                _, predicted_strength = torch.max(outputs["hand_strength"], 1)
                val_strength_total += target_strength.size(0)
                val_strength_correct += (
                    (predicted_strength == target_strength).sum().item()
                )

                predicted_category = (
                    torch.sigmoid(outputs["category_probs"]) > 0.5
                ).float()
                val_category_total += target_category.numel()
                val_category_correct += (
                    (predicted_category == target_category).sum().item()
                )

                val_specific_mse_sum += specific_loss.item()
                val_batches += 1

        # ===================== –ú–ï–¢–†–ò–ö–ò –≠–ü–û–•–ò =====================
        avg_train_loss = np.mean(train_losses) if train_losses else 0
        avg_val_loss = np.mean(val_losses) if val_losses else 0

        train_strength_acc = train_strength_correct / max(train_strength_total, 1)
        val_strength_acc = val_strength_correct / max(val_strength_total, 1)

        train_category_acc = train_category_correct / max(train_category_total, 1)
        val_category_acc = val_category_correct / max(val_category_total, 1)

        train_specific_mse = train_specific_mse_sum / max(train_batches, 1)
        val_specific_mse = val_specific_mse_sum / max(val_batches, 1)

        current_lr = optimizer.param_groups[0]["lr"]

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        history["train_loss"].append(avg_train_loss)
        history["val_loss"].append(avg_val_loss)
        history["train_strength_acc"].append(train_strength_acc)
        history["val_strength_acc"].append(val_strength_acc)
        history["train_category_acc"].append(train_category_acc)
        history["val_category_acc"].append(val_category_acc)
        history["train_specific_mse"].append(train_specific_mse)
        history["val_specific_mse"].append(val_specific_mse)
        history["learning_rates"].append(current_lr)

        # –í—Ä–µ–º—è —ç–ø–æ—Ö–∏
        epoch_time = (datetime.now() - epoch_start_time).total_seconds()

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–ø–æ—Ö–∏
        print(f"\nüìä –≠–ø–æ—Ö–∞ {epoch+1}/{epochs} –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {epoch_time:.1f}—Å:")
        print(f"   üìâ –ü–æ—Ç–µ—Ä–∏: train={avg_train_loss:.4f}, val={avg_val_loss:.4f}")
        print(
            f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã: train={train_strength_acc:.3f}, val={val_strength_acc:.3f}"
        )
        print(
            f"   üè∑Ô∏è  –¢–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: train={train_category_acc:.3f}, val={val_category_acc:.3f}"
        )
        print(
            f"   üìä MSE —Ä–∞–Ω–≥–æ–≤: train={train_specific_mse:.4f}, val={val_specific_mse:.4f}"
        )
        print(f"   üìà Learning rate: {current_lr:.6f}")

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞
        scheduler.step(avg_val_loss)

        # –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            print(f"   ‚≠ê –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å! Val loss: {best_val_loss:.4f}")
        else:
            patience_counter += 1
            print(f"   ‚è≥ Patience: {patience_counter}/{early_stopping_patience}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if patience_counter >= early_stopping_patience:
            print(f"\nüõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
            print(f"   üìà –õ—É—á—à–∏–π val loss: {best_val_loss:.4f}")
            break

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–µ –≤–µ—Å–∞
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –≤–µ—Å–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (val loss: {best_val_loss:.4f})")

    print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return model, history


def evaluate_sequence_model_performance(model, data_dict, include_hole_cards=True):
    """
    –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    print(f"\nüîç === –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò ===")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    all_outputs = {
        "strength_pred": [],
        "strength_true": [],
        "category_pred": [],
        "category_true": [],
        "specific_pred": [],
        "specific_true": [],
        "sequence_lengths": [],
    }

    total_sequences = 0
    correct_predictions = 0

    with torch.no_grad():
        for inputs, targets in data_dict["test_loader"]:
            inputs = inputs.to(device)
            seq_lengths = targets["sequence_length"]

            model.reset_states()
            outputs = model(inputs)

            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            _, strength_pred = torch.max(outputs["hand_strength"], 1)
            all_outputs["strength_pred"].extend(strength_pred.cpu().numpy())
            all_outputs["strength_true"].extend(targets["hand_strength"].numpy())

            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
            category_pred = torch.sigmoid(outputs["category_probs"]).cpu().numpy()
            category_true = targets["category_probs"].numpy()
            all_outputs["category_pred"].extend(np.argmax(category_pred, axis=1))
            all_outputs["category_true"].extend(np.argmax(category_true, axis=1))

            # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–∞–Ω–≥–∏
            all_outputs["specific_pred"].extend(outputs["specific_hand"].cpu().numpy())
            all_outputs["specific_true"].extend(targets["specific_hand"].numpy())

            # –î–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
            all_outputs["sequence_lengths"].extend(seq_lengths.numpy())

            total_sequences += len(strength_pred)
            correct_predictions += (
                (strength_pred.cpu() == targets["hand_strength"]).sum().item()
            )

    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    from sklearn.metrics import (
        accuracy_score,
        classification_report,
        mean_squared_error,
    )

    strength_accuracy = accuracy_score(
        all_outputs["strength_true"], all_outputs["strength_pred"]
    )
    category_accuracy = accuracy_score(
        all_outputs["category_true"], all_outputs["category_pred"]
    )
    specific_mse = mean_squared_error(
        all_outputs["specific_true"], all_outputs["specific_pred"]
    )

    model_type = "—Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞" if include_hole_cards else "–±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞"
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏ {model_type}:")
    print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏: {strength_accuracy:.3f}")
    print(f"   üè∑Ô∏è  –¢–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_accuracy:.3f}")
    print(f"   üìä MSE —Ä–∞–Ω–≥–æ–≤ –∫–∞—Ä—Ç: {specific_mse:.4f}")
    print(f"   üìà –í—Å–µ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {total_sequences}")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    seq_lengths = np.array(all_outputs["sequence_lengths"])
    strength_preds = np.array(all_outputs["strength_pred"])
    strength_true = np.array(all_outputs["strength_true"])

    print(f"\nüìè –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:")
    for seq_len in sorted(set(seq_lengths)):
        mask = seq_lengths == seq_len
        if mask.sum() > 0:
            acc = accuracy_score(strength_true[mask], strength_preds[mask])
            count = mask.sum()
            print(f"   –î–ª–∏–Ω–∞ {seq_len:2d}: {acc:.3f} —Ç–æ—á–Ω–æ—Å—Ç—å ({count:3d} –ø—Ä–∏–º–µ—Ä–æ–≤)")

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    category_names = PokerHandAnalyzer.get_all_categories()
    print(f"\nüè∑Ô∏è  –û—Ç—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Ä—É–∫:")
    try:
        class_report = classification_report(
            all_outputs["category_true"],
            all_outputs["category_pred"],
            target_names=category_names,
            zero_division=0,
            output_dict=True,
        )

        for category, metrics in class_report.items():
            if isinstance(metrics, dict) and category in category_names:
                print(
                    f"   {category:20s}: precision={metrics['precision']:.3f}, "
                    f"recall={metrics['recall']:.3f}, f1={metrics['f1-score']:.3f}"
                )

    except Exception as e:
        print(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {e}")

    return {
        "strength_accuracy": strength_accuracy,
        "category_accuracy": category_accuracy,
        "specific_mse": specific_mse,
        "total_sequences": total_sequences,
        **all_outputs,
    }


def visualize_sequence_results(model, data_dict, history, include_hole_cards=True):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")

    fig, axes = plt.subplots(3, 2, figsize=(15, 18))

    # 1. –ü–æ—Ç–µ—Ä–∏ –æ–±—É—á–µ–Ω–∏—è
    axes[0, 0].plot(history["train_loss"], label="Train", linewidth=2)
    axes[0, 0].plot(history["val_loss"], label="Validation", linewidth=2)
    axes[0, 0].set_title("–ü–æ—Ç–µ—Ä–∏ –æ–±—É—á–µ–Ω–∏—è", fontsize=14, fontweight="bold")
    axes[0, 0].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[0, 0].set_ylabel("–ü–æ—Ç–µ—Ä–∏")
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # 2. –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏
    axes[0, 1].plot(history["train_strength_acc"], label="Train", linewidth=2)
    axes[0, 1].plot(history["val_strength_acc"], label="Validation", linewidth=2)
    axes[0, 1].set_title(
        "–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–ª—ã —Ä—É–∫–∏", fontsize=14, fontweight="bold"
    )
    axes[0, 1].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[0, 1].set_ylabel("–¢–æ—á–Ω–æ—Å—Ç—å")
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # 3. –¢–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    axes[1, 0].plot(history["train_category_acc"], label="Train", linewidth=2)
    axes[1, 0].plot(history["val_category_acc"], label="Validation", linewidth=2)
    axes[1, 0].set_title(
        "–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π", fontsize=14, fontweight="bold"
    )
    axes[1, 0].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[1, 0].set_ylabel("–¢–æ—á–Ω–æ—Å—Ç—å")
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # 4. MSE –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–æ–≤
    axes[1, 1].plot(history["train_specific_mse"], label="Train", linewidth=2)
    axes[1, 1].plot(history["val_specific_mse"], label="Validation", linewidth=2)
    axes[1, 1].set_title("MSE –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–∞–Ω–≥–æ–≤ –∫–∞—Ä—Ç", fontsize=14, fontweight="bold")
    axes[1, 1].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[1, 1].set_ylabel("MSE")
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    # 5. Learning Rate
    axes[2, 0].plot(history["learning_rates"], linewidth=2, color="red")
    axes[2, 0].set_title("Learning Rate", fontsize=14, fontweight="bold")
    axes[2, 0].set_xlabel("–≠–ø–æ—Ö–∞")
    axes[2, 0].set_ylabel("Learning Rate")
    axes[2, 0].set_yscale("log")
    axes[2, 0].grid(True, alpha=0.3)

    # 6. –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –¥–ª—è —Å–∏–ª—ã —Ä—É–∫–∏
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    all_predictions = []
    all_targets = []

    with torch.no_grad():
        for inputs, targets in data_dict["test_loader"]:
            inputs = inputs.to(device)
            model.reset_states()
            outputs = model(inputs)

            _, strength_pred = torch.max(outputs["hand_strength"], 1)
            all_predictions.extend(strength_pred.cpu().numpy())
            all_targets.extend(targets["hand_strength"].numpy())

    from sklearn.metrics import confusion_matrix

    cm = confusion_matrix(all_targets, all_predictions)

    im = axes[2, 1].imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
    axes[2, 1].set_title("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: –°–∏–ª–∞ —Ä—É–∫–∏", fontsize=14, fontweight="bold")
    axes[2, 1].set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å–∏–ª–∞")
    axes[2, 1].set_ylabel("–ò—Å—Ç–∏–Ω–Ω–∞—è —Å–∏–ª–∞")

    # –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–∞ –≤ –º–∞—Ç—Ä–∏—Ü—É
    thresh = cm.max() / 2.0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            axes[2, 1].text(
                j,
                i,
                str(cm[i, j]),
                ha="center",
                va="center",
                color="white" if cm[i, j] > thresh else "black",
                fontsize=8,
            )

    # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    model_type = "—Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞" if include_hole_cards else "–±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞"
    fig.suptitle(
        f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è RWKV –º–æ–¥–µ–ª–∏ ({model_type})",
        fontsize=16,
        fontweight="bold",
    )

    plt.tight_layout()

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_name = f"sequence_training_results_{'with_cards' if include_hole_cards else 'without_cards'}_{timestamp}.png"

    os.makedirs("plots", exist_ok=True)
    plot_path = os.path.join("plots", plot_name)
    plt.savefig(plot_path, dpi=300, bbox_inches="tight")
    print(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")

    return fig, plot_path


def predict_sequence_hand_ranges(model, data_dict, sample_hands=5):
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    print(f"\nüé≤ === –ü–†–ò–ú–ï–†–´ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ô ===")

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.eval()

    category_names = PokerHandAnalyzer.get_all_categories()
    rank_names = PokerHandAnalyzer.get_rank_names()

    shown_examples = 0

    with torch.no_grad():
        for batch_idx, (inputs, targets) in enumerate(data_dict["test_loader"]):
            if shown_examples >= sample_hands:
                break

            inputs = inputs.to(device)
            seq_lengths = targets["sequence_length"]

            model.reset_states()
            outputs = model(inputs)

            batch_size = inputs.size(0)

            for sample_idx in range(min(batch_size, sample_hands - shown_examples)):
                # –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                seq_len = seq_lengths[sample_idx].item()

                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                strength_probs = torch.softmax(outputs["hand_strength"], dim=1)[
                    sample_idx
                ]
                predicted_strength = torch.argmax(strength_probs).item()
                strength_confidence = strength_probs[predicted_strength].item()

                category_probs = torch.sigmoid(outputs["category_probs"])[sample_idx]
                predicted_category = torch.argmax(category_probs).item()
                category_confidence = category_probs[predicted_category].item()

                specific_probs = outputs["specific_hand"][sample_idx]

                # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                true_strength = targets["hand_strength"][sample_idx].item()
                true_category = torch.argmax(
                    targets["category_probs"][sample_idx]
                ).item()

                print(f"\nüéØ –ü—Ä–∏–º–µ—Ä {shown_examples + 1}:")
                print(f"   üìè –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {seq_len}")
                print(f"   üí™ –ò—Å—Ç–∏–Ω–Ω–∞—è —Å–∏–ª–∞: {true_strength}")
                print(
                    f"   üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å–∏–ª–∞: {predicted_strength} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {strength_confidence:.3f})"
                )
                print(f"   üè∑Ô∏è  –ò—Å—Ç–∏–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_names[true_category]}")
                print(
                    f"   üè∑Ô∏è  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category_names[predicted_category]} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {category_confidence:.3f})"
                )

                # –¢–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–∞
                top_ranks = torch.topk(specific_probs, 3)
                print(f"   üÉè –¢–æ–ø-3 –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ä–∞–Ω–≥–∞:")
                for j, (prob, rank_idx) in enumerate(
                    zip(top_ranks.values, top_ranks.indices)
                ):
                    print(f"      {j+1}. {rank_names[rank_idx]}: {prob:.3f}")

                # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏
                strength_correct = "‚úÖ" if predicted_strength == true_strength else "‚ùå"
                category_correct = "‚úÖ" if predicted_category == true_category else "‚ùå"
                print(
                    f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: —Å–∏–ª–∞ {strength_correct}, –∫–∞—Ç–µ–≥–æ—Ä–∏—è {category_correct}"
                )

                shown_examples += 1

                if shown_examples >= sample_hands:
                    break

    print(f"\nüí° –ü–æ–∫–∞–∑–∞–Ω–æ {shown_examples} –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")


def analyze_optimal_sequence_length(df, percentile=95):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        percentile: –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 95%)

    Returns:
        dict —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    print(f"üìä === –ê–ù–ê–õ–ò–ó –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ô –î–õ–ò–ù–´ –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ò ===")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–≥—Ä–æ–∫–∞–º –∏ —Ä—É–∫–∞–º
    if "HandID" in df.columns:
        hand_lengths = df.groupby("HandID").size()
        print(f"üìã –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä—É–∫–∞–º (HandID):")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä—É–∫: {len(hand_lengths):,}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ä—É–∫–∏: {hand_lengths.mean():.1f} –¥–µ–π—Å—Ç–≤–∏–π")
        print(f"   –ú–µ–¥–∏–∞–Ω–∞: {hand_lengths.median():.0f}")
        print(f"   –ú–∏–Ω/–ú–∞–∫—Å: {hand_lengths.min()}/{hand_lengths.max()}")

        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω
        print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —Ä—É–∫:")
        for pct in [50, 75, 90, 95, 99]:
            pct_value = hand_lengths.quantile(pct / 100)
            print(f"   {pct}%: {pct_value:.0f} –¥–µ–π—Å—Ç–≤–∏–π")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ –∏–≥—Ä–æ–∫–∞–º –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å–µ—Å—Å–∏—è–º
    player_sequences = []

    for player_id in df["PlayerID"].unique():
        player_data = df[df["PlayerID"] == player_id].copy()

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        if "Timestamp" in player_data.columns:
            player_data = player_data.sort_values("Timestamp")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ—Å—Å–∏–∏ (–≥—Ä—É–ø–ø—ã –¥–µ–π—Å—Ç–≤–∏–π —Å —Ä–∞–∑—Ä—ã–≤–æ–º < threshold)
        if "Timestamp" in player_data.columns and player_data["Timestamp"].dtype in [
            "int64",
            "float64",
        ]:
            time_diffs = player_data["Timestamp"].diff()

            # –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Å–µ—Å—Å–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 30 –º–∏–Ω—É—Ç –∏–ª–∏ 30 —Ä–∞—É–Ω–¥–æ–≤)
            session_threshold = time_diffs.quantile(0.9) if len(time_diffs) > 10 else 30

            # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—ã —Å–µ—Å—Å–∏–π
            session_breaks = (time_diffs > session_threshold).cumsum()
            sessions = player_data.groupby(session_breaks).size()

            player_sequences.extend(sessions.tolist())
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫, –±–µ—Ä–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –∏–≥—Ä–æ–∫–∞ –∫–∞–∫ –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            player_sequences.append(len(player_data))

    if player_sequences:
        player_sequences = pd.Series(player_sequences)
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏–≥—Ä–æ–∫–æ–≤:")
        print(f"   –ù–∞–π–¥–µ–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(player_sequences):,}")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {player_sequences.mean():.1f}")
        print(f"   –ú–µ–¥–∏–∞–Ω–∞: {player_sequences.median():.0f}")
        print(f"   –°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {player_sequences.std():.1f}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        optimal_max = int(player_sequences.quantile(percentile / 100))
        optimal_min = max(3, int(player_sequences.quantile(0.1)))  # –ú–∏–Ω–∏–º—É–º 3 –¥–µ–π—Å—Ç–≤–∏—è
        recommended = int(
            player_sequences.quantile(0.75)
        )  # 75 –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –∫–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

        print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {optimal_min}")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –¥–ª–∏–Ω–∞: {recommended}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {optimal_max} ({percentile}% –ø–æ–∫—Ä—ã—Ç–∏–µ)")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–∞–Ω–Ω—ã—Ö
        coverage_80 = (
            (player_sequences <= recommended).sum() / len(player_sequences) * 100
        )
        coverage_95 = (
            (player_sequences <= optimal_max).sum() / len(player_sequences) * 100
        )

        print(f"\nüìà –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
        print(f"   –ü—Ä–∏ –¥–ª–∏–Ω–µ {recommended}: {coverage_80:.1f}% –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"   –ü—Ä–∏ –¥–ª–∏–Ω–µ {optimal_max}: {coverage_95:.1f}% –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –æ–±—Ä–µ–∑–∫–µ
        truncated_actions = (
            player_sequences[player_sequences > optimal_max].sum()
            - len(player_sequences[player_sequences > optimal_max]) * optimal_max
        )
        total_actions = player_sequences.sum()
        loss_percentage = truncated_actions / total_actions * 100

        print(f"\n‚úÇÔ∏è –ü–æ—Ç–µ—Ä–∏ –ø—Ä–∏ –æ–±—Ä–µ–∑–∫–µ –¥–æ {optimal_max}:")
        print(f"   –û–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π: {truncated_actions:,}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ—Ç–µ—Ä—å: {loss_percentage:.2f}%")

        return {
            "min_length": optimal_min,
            "recommended_length": recommended,
            "max_length": optimal_max,
            "mean_length": player_sequences.mean(),
            "median_length": player_sequences.median(),
            "coverage_at_max": coverage_95,
            "data_loss_percentage": loss_percentage,
            "total_sequences": len(player_sequences),
        }

    else:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return {
            "min_length": 3,
            "recommended_length": 10,
            "max_length": 20,
            "mean_length": 10,
            "median_length": 10,
            "coverage_at_max": 100,
            "data_loss_percentage": 0,
            "total_sequences": 0,
        }


def create_adaptive_sequences(df, sequence_params, balance_strategy="adaptive"):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        sequence_params: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ analyze_optimal_sequence_length
        balance_strategy: —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ('adaptive', 'fixed', 'mixed')
    """
    print(f"\nüîÑ === –°–û–ó–î–ê–ù–ò–ï –ê–î–ê–ü–¢–ò–í–ù–´–• –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô ===")
    print(f"üìè –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"   –ú–∏–Ω–∏–º—É–º: {sequence_params['min_length']}")
    print(f"   –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è: {sequence_params['recommended_length']}")
    print(f"   –ú–∞–∫—Å–∏–º—É–º: {sequence_params['max_length']}")
    print(f"   –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {balance_strategy}")

    sequences = []
    sequence_info = []

    for player_id in df["PlayerID"].unique():
        player_data = df[df["PlayerID"] == player_id].copy()

        if "Timestamp" in player_data.columns:
            player_data = player_data.sort_values("Timestamp")

        player_records = len(player_data)

        if balance_strategy == "adaptive":
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: —Ä–∞–∑–Ω—ã–µ –¥–ª–∏–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏–≥—Ä–æ–∫–æ–≤
            if player_records < sequence_params["min_length"]:
                continue

            # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∏–≥—Ä–æ–∫–æ–≤ —Å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
            if player_records < sequence_params["recommended_length"]:
                sequences.append(player_data)
                sequence_info.append(
                    {
                        "player_id": player_id,
                        "length": player_records,
                        "type": "short_full",
                    }
                )

            # –°—Ä–µ–¥–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            elif player_records < sequence_params["max_length"]:
                # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –æ–∫–Ω–∞
                step = max(1, player_records // 3)
                for start in range(
                    0, player_records - sequence_params["min_length"] + 1, step
                ):
                    end = min(
                        start + sequence_params["recommended_length"], player_records
                    )
                    sequences.append(player_data.iloc[start:end])
                    sequence_info.append(
                        {
                            "player_id": player_id,
                            "length": end - start,
                            "type": "medium_window",
                        }
                    )

            # –î–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º —à–∞–≥–æ–º
                window_size = sequence_params["recommended_length"]
                step = max(1, window_size // 2)

                for start in range(0, player_records - window_size + 1, step):
                    end = start + window_size
                    sequences.append(player_data.iloc[start:end])
                    sequence_info.append(
                        {
                            "player_id": player_id,
                            "length": window_size,
                            "type": "sliding_window",
                        }
                    )

                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–Ω–æ–π –¥–ª–∏–Ω—ã
                if player_records > sequence_params["max_length"]:
                    sequences.append(player_data.iloc[-sequence_params["max_length"] :])
                    sequence_info.append(
                        {
                            "player_id": player_id,
                            "length": sequence_params["max_length"],
                            "type": "tail_max",
                        }
                    )

        elif balance_strategy == "mixed":
            # –°–º–µ—à–∞–Ω–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Ä–∞–∑–Ω—ã—Ö –¥–ª–∏–Ω
            if player_records >= sequence_params["min_length"]:
                # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–¥–ª—è –Ω–∞—á–∞–ª–∞ –∏–≥—Ä—ã)
                for length in [5, 10, 15]:
                    if length <= player_records:
                        sequences.append(player_data.iloc[:length])
                        sequence_info.append(
                            {
                                "player_id": player_id,
                                "length": length,
                                "type": f"fixed_{length}",
                            }
                        )

                # –°–ª—É—á–∞–π–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                if player_records > sequence_params["recommended_length"]:
                    for _ in range(2):
                        start = np.random.randint(
                            0, player_records - sequence_params["min_length"]
                        )
                        length = np.random.randint(
                            sequence_params["min_length"],
                            min(
                                sequence_params["recommended_length"],
                                player_records - start,
                            ),
                        )
                        sequences.append(player_data.iloc[start : start + length])
                        sequence_info.append(
                            {
                                "player_id": player_id,
                                "length": length,
                                "type": "random_segment",
                            }
                        )

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    lengths = [info["length"] for info in sequence_info]
    type_counts = {}
    for info in sequence_info:
        seq_type = info["type"]
        type_counts[seq_type] = type_counts.get(seq_type, 0) + 1

    print(f"\nüìä –°–æ–∑–¥–∞–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(sequences)}")
    print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {np.mean(lengths):.1f}")
    print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω:")
    print(
        f"   - –ö–æ—Ä–æ—Ç–∫–∏–µ (<{sequence_params['recommended_length']}): "
        f"{sum(1 for l in lengths if l < sequence_params['recommended_length'])}"
    )
    print(
        f"   - –°—Ä–µ–¥–Ω–∏–µ: "
        f"{sum(1 for l in lengths if sequence_params['recommended_length'] <= l < sequence_params['max_length'])}"
    )
    print(
        f"   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ (={sequence_params['max_length']}): "
        f"{sum(1 for l in lengths if l == sequence_params['max_length'])}"
    )

    print(f"\nüìã –ü–æ —Ç–∏–ø–∞–º —Å–æ–∑–¥–∞–Ω–∏—è:")
    for seq_type, count in sorted(
        type_counts.items(), key=lambda x: x[1], reverse=True
    ):
        print(f"   {seq_type}: {count}")

    return sequences, sequence_info, sequence_params


# -----------------------------------------------------------------


# ---------------------- 7. –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ----------------------
def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π"""

    print("üé∞ === –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ä—É–∫ –≤ –ø–æ–∫–µ—Ä–µ ===\n")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
    setup_directories()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
    save_categories_json()

    # –í—ã–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö
    data_choice = choose_data_file()
    if not data_choice:
        print("–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω–∞ –ª–∏ –º–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if data_choice == "COMBINE_ALL":
        process_all_files()
        return

    # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    data_path = data_choice

    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö...")
    df_check = pd.read_csv(data_path)
    showdown_count = (
        (df_check["Showdown_1"].notna()) & (df_check["Showdown_2"].notna())
    ).sum()
    total_rows = len(df_check)
    print(f"   üìà –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {total_rows:,} —Å—Ç—Ä–æ–∫")
    print(f"   üÉè –ù–∞–π–¥–µ–Ω–æ {showdown_count:,} –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏")
    print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º: {showdown_count/total_rows*100:.1f}%")

    if showdown_count < 50:
        print(
            "‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –º–∞–ª–æ –∑–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!"
        )
    else:
        print("‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")

    results = {}
    all_plots = []

    # 1. –ú–æ–¥–µ–ª—å –° –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞
    print(f"\nüéØ 1. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –° –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞...")
    try:
        data_with_cards = prepare_hand_range_data(data_path, include_hole_cards=True)

        if data_with_cards is not None:
            model_with_cards, history_with_cards = train_hand_range_model(
                data_with_cards,
                hidden_dim=128,
                num_layers=3,
                epochs=20,
                lr=0.001,
            )

            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            results["with_cards"] = evaluate_model_performance(
                model_with_cards, data_with_cards, include_hole_cards=True
            )

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig1, plot_path1 = visualize_results(
                model_with_cards, data_with_cards, history_with_cards, True
            )
            all_plots.append(plot_path1)
            plt.show()

            # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predict_hand_ranges(model_with_cards, data_with_cards, sample_hands=3)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path, best_path = save_best_model(
                model_with_cards, data_with_cards, results["with_cards"], True
            )

        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –∫–∞—Ä—Ç–∞–º–∏")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —Å –∫–∞—Ä—Ç–∞–º–∏: {e}")
        import traceback

        traceback.print_exc()

    print(f"\n" + "=" * 60 + "\n")

    # 2. –ú–æ–¥–µ–ª—å –ë–ï–ó –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞
    print(f"üé≤ 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ë–ï–ó –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞...")
    print(
        f"   (—Ç–∞ –∂–µ —Ü–µ–ª—å - —É–≥–∞–¥–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∫–∞—Ä—Ç—ã, –Ω–æ –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–∏—Ö –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö)"
    )
    try:
        data_without_cards = prepare_hand_range_data(
            data_path, include_hole_cards=False
        )

        if data_without_cards is not None:
            model_without_cards, history_without_cards = train_hand_range_model(
                data_without_cards,
                hidden_dim=128,
                num_layers=3,
                epochs=20,
                lr=0.001,
            )

            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            results["without_cards"] = evaluate_model_performance(
                model_without_cards, data_without_cards, include_hole_cards=False
            )

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig2, plot_path2 = visualize_results(
                model_without_cards, data_without_cards, history_without_cards, False
            )
            all_plots.append(plot_path2)
            plt.show()

            # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predict_hand_ranges(model_without_cards, data_without_cards, sample_hands=3)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path, best_path = save_best_model(
                model_without_cards, data_without_cards, results["without_cards"], False
            )

        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –±–µ–∑ –∫–∞—Ä—Ç")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∫–∞—Ä—Ç: {e}")
        import traceback

        traceback.print_exc()

    # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print(f"\n" + "=" * 60)
    print(f"üèÜ === –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô ===")

    if "with_cards" in results and "without_cards" in results:
        with_cards_acc = results["with_cards"]["strength_accuracy"]
        without_cards_acc = results["without_cards"]["strength_accuracy"]

        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_acc:.3f}")
        print(f"   üé≤ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ë–ï–ó –∫–∞—Ä—Ç: {without_cards_acc:.3f}")
        print(f"   üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_acc - without_cards_acc:.3f}")

        if with_cards_acc > without_cards_acc:
            print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        else:
            print(
                f"   üéØ –ú–æ–¥–µ–ª—å –±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        comparison_report = {
            "timestamp": datetime.now().isoformat(),
            "data_file": data_path,
            "total_records": total_rows,
            "showdown_records": showdown_count,
            "models": {
                "with_cards": {
                    "strength_accuracy": float(with_cards_acc),
                    "category_accuracy": float(
                        results["with_cards"]["category_accuracy"]
                    ),
                    "specific_mse": float(results["with_cards"]["specific_mse"]),
                },
                "without_cards": {
                    "strength_accuracy": float(without_cards_acc),
                    "category_accuracy": float(
                        results["without_cards"]["category_accuracy"]
                    ),
                    "specific_mse": float(results["without_cards"]["specific_mse"]),
                },
            },
            "plots": all_plots,
        }

        report_path = (
            f"results/comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(report_path, "w", encoding="utf-8") as f:
            comparison_report_safe = safe_json_serialize(comparison_report)
            json.dump(comparison_report_safe, f, indent=2, ensure_ascii=False)

        print(f"   üìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    print(f"\nüéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–∞—Ö:")
    print(f"   ü§ñ models/     - –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    print(f"   üìä plots/      - –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
    print(f"   üìã results/    - –æ—Ç—á–µ—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    print(f"   üÉè results/poker_categories.json - –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ä—É–∫")


# if __name__ == "__main__":
#     main()


def choose_data_file_with_percentage():
    """–í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤—ã–±–æ—Ä–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Ñ–∞–π–ª–æ–≤"""
    data_files = find_data_files()

    if not data_files:
        print("‚ùå CSV —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("–ü–æ–º–µ—Å—Ç–∏—Ç–µ CSV —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É 'data' –∏–ª–∏ –≤ —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é")
        return None

    if len(data_files) == 1:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {data_files[0]}")
        return data_files[0]

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    total_size_mb = 0
    file_stats = []

    for file in data_files:
        size_mb = os.path.getsize(file) / 1024 / 1024
        total_size_mb += size_mb
        file_stats.append((file, size_mb))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    sorted_files = sorted(file_stats, key=lambda x: x[1], reverse=True)

    print(
        f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(data_files)} —Ñ–∞–π–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ (–æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size_mb:.1f} MB):"
    )

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10 —Ñ–∞–π–ª–æ–≤
    print(f"üìä –¢–æ–ø-10 –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö —Ñ–∞–π–ª–æ–≤:")
    for i, (file, size_mb) in enumerate(sorted_files[:10]):
        percentage = (size_mb / total_size_mb) * 100
        print(
            f"  {i+1}. {os.path.basename(file)} ({size_mb:.1f} MB, {percentage:.1f}%)"
        )

    if len(data_files) > 10:
        print(f"\nüìã –ü–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ —Ç–æ–ø-10 —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(data_files)}")

    print(f"\nüìä –û–ü–¶–ò–ò –í–´–ë–û–†–ê:")
    print(f"  0. ‚≠ê –û–ë–™–ï–î–ò–ù–ò–¢–¨ –í–°–ï {len(data_files)} –§–ê–ô–õ–û–í (100%)")
    print(f"  25. üìä –û–±—ä–µ–¥–∏–Ω–∏—Ç—å 25% —Ñ–∞–π–ª–æ–≤ (~{len(data_files)//4} —Ñ–∞–π–ª–æ–≤)")
    print(f"  50. üìä –û–±—ä–µ–¥–∏–Ω–∏—Ç—å 50% —Ñ–∞–π–ª–æ–≤ (~{len(data_files)//2} —Ñ–∞–π–ª–æ–≤)")
    print(f"  75. üìä –û–±—ä–µ–¥–∏–Ω–∏—Ç—å 75% —Ñ–∞–π–ª–æ–≤ (~{3*len(data_files)//4} —Ñ–∞–π–ª–æ–≤)")
    print(f"  1-10. üìÑ –í—ã–±—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –∏–∑ —Ç–æ–ø-10")
    print(f"  p. üéØ –í–≤–µ—Å—Ç–∏ —Å–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä: p30 –¥–ª—è 30%)")

    while True:
        try:
            choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é: ").strip().lower()

            if choice in ["q", "quit", "exit"]:
                return None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π –≤–≤–æ–¥
            if choice.startswith("p"):
                try:
                    custom_percent = int(choice[1:])
                    if 1 <= custom_percent <= 100:
                        num_files = max(1, int(len(data_files) * custom_percent / 100))
                        print(
                            f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å {custom_percent}% —Ñ–∞–π–ª–æ–≤ ({num_files} –∏–∑ {len(data_files)})"
                        )
                        return ("COMBINE_PERCENT", custom_percent)
                    else:
                        print("‚ùå –ü—Ä–æ—Ü–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ 100")
                        continue
                except ValueError:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ p25 –¥–ª—è 25%")
                    continue

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –≤–≤–æ–¥–æ–≤
            choice_num = int(choice)

            if choice_num == 0:
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ {len(data_files)} —Ñ–∞–π–ª–æ–≤")
                return ("COMBINE_PERCENT", 100)
            elif choice_num == 25:
                print(
                    f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å 25% —Ñ–∞–π–ª–æ–≤ ({len(data_files)//4} –∏–∑ {len(data_files)})"
                )
                return ("COMBINE_PERCENT", 25)
            elif choice_num == 50:
                print(
                    f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å 50% —Ñ–∞–π–ª–æ–≤ ({len(data_files)//2} –∏–∑ {len(data_files)})"
                )
                return ("COMBINE_PERCENT", 50)
            elif choice_num == 75:
                print(
                    f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å 75% —Ñ–∞–π–ª–æ–≤ ({3*len(data_files)//4} –∏–∑ {len(data_files)})"
                )
                return ("COMBINE_PERCENT", 75)
            elif 1 <= choice_num <= min(10, len(data_files)):
                selected_file = sorted_files[choice_num - 1][0]
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {selected_file}")
                return selected_file
            else:
                print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç (p30)")


def combine_percentage_of_files(percentage):
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Ñ–∞–π–ª–æ–≤"""
    data_files = find_data_files()

    if not data_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        return None

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É (–±–µ—Ä–µ–º —Å–Ω–∞—á–∞–ª–∞ –±–æ–ª—å—à–∏–µ)
    file_stats = []
    for file in data_files:
        size = os.path.getsize(file)
        file_stats.append((file, size))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ
    sorted_files = sorted(file_stats, key=lambda x: x[1], reverse=True)

    # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
    num_files_to_take = max(1, int(len(data_files) * percentage / 100))
    selected_files = [f[0] for f in sorted_files[:num_files_to_take]]

    print(f"\nüîó === –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï {percentage}% –§–ê–ô–õ–û–í ===")
    print(f"üìä –í—ã–±—Ä–∞–Ω–æ {num_files_to_take} –∏–∑ {len(data_files)} —Ñ–∞–π–ª–æ–≤")
    print(f"üìà –≠—Ç–æ —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É")

    all_dataframes = []
    total_records = 0
    total_showdowns = 0
    total_size_mb = 0

    for i, data_path in enumerate(selected_files, 1):
        print(
            f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª {i}/{num_files_to_take}: {os.path.basename(data_path)}"
        )

        try:
            df = pd.read_csv(data_path)

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            df["source_file"] = os.path.basename(data_path)
            df["file_index"] = i

            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            showdowns_in_file = (
                (df["Showdown_1"].notna()) & (df["Showdown_2"].notna())
            ).sum()
            file_size_mb = os.path.getsize(data_path) / 1024 / 1024

            print(
                f"   üìä –†–∞–∑–º–µ—Ä: {len(df):,} —Å—Ç—Ä–æ–∫, {file_size_mb:.1f} MB, —à–æ—É–¥–∞—É–Ω–æ–≤: {showdowns_in_file:,}"
            )

            all_dataframes.append(df)
            total_records += len(df)
            total_showdowns += showdowns_in_file
            total_size_mb += file_size_mb

        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            continue

    if not all_dataframes:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        return None

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"\nüîÑ –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
    combined_df = pd.concat(all_dataframes, ignore_index=True, sort=False)

    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:")
    print(f"   üìà –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_records:,} —Å—Ç—Ä–æ–∫")
    print(f"   üíæ –û–±—â–∏–π –æ–±—ä–µ–º: {total_size_mb:.1f} MB")
    print(f"   üÉè –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–æ—É–¥–∞—É–Ω–æ–≤: {total_showdowns:,}")
    print(
        f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º: {total_showdowns/total_records*100:.1f}%"
    )
    print(f"   üìÅ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {num_files_to_take} ({percentage}%)")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    combined_dir = os.path.join("data", "combined")
    os.makedirs(combined_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    combined_filename = os.path.join(
        combined_dir, f"combined_{percentage}pct_poker_data_{timestamp}.csv"
    )

    combined_df.to_csv(combined_filename, index=False)
    print(f"üíæ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {combined_filename}")

    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
    summary = {
        "timestamp": datetime.now().isoformat(),
        "percentage_selected": percentage,
        "total_files_available": len(data_files),
        "files_used": num_files_to_take,
        "total_records": int(total_records),
        "total_showdowns": int(total_showdowns),
        "total_size_mb": float(total_size_mb),
        "combined_file": combined_filename,
        "files_included": [
            os.path.basename(f) for f in selected_files[:10]
        ],  # –ü–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    }

    summary_path = f"results/data_combination_{percentage}pct_summary_{timestamp}.json"
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    print(f"üìã –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_path}")

    return combined_filename, summary


def main_with_sequences():
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–±–æ—Ä–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Ñ–∞–π–ª–æ–≤"""
    print("üé∞ === –û–ë–£–ß–ï–ù–ò–ï RWKV –ú–û–î–ï–õ–ï–ô –° –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–Ø–ú–ò ===\n")

    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
    setup_directories()
    save_categories_json()

    # –í—ã–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö —Å –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
    data_choice = choose_data_file_with_percentage()
    if not data_choice:
        print("üëã –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã.")
        return

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—ã–±–æ—Ä
    if isinstance(data_choice, tuple) and data_choice[0] == "COMBINE_PERCENT":
        percentage = data_choice[1]

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç —Ñ–∞–π–ª–æ–≤
        result = combine_percentage_of_files(percentage)
        if result is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã")
            return

        data_path, combination_summary = result
        print(f"\n‚úÖ –ë—É–¥–µ–º –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ {percentage}% –¥–∞–Ω–Ω—ã—Ö")

    else:
        # –û–±—ã—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        data_path = data_choice
        combination_summary = None

    # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüìä === –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• ===")
    df_check = pd.read_csv(data_path)
    showdown_count = (
        (df_check["Showdown_1"].notna()) & (df_check["Showdown_2"].notna())
    ).sum()
    total_rows = len(df_check)

    print(f"üìà –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {total_rows:,} —Å—Ç—Ä–æ–∫")
    print(f"üÉè –ó–∞–ø–∏—Å–µ–π —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∫–∞—Ä—Ç–∞–º–∏: {showdown_count:,}")
    print(f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç —à–æ—É–¥–∞—É–Ω–æ–≤: {showdown_count/total_rows*100:.1f}%")

    if showdown_count < 50:
        print("‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")
        print("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ü–∏—é –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤")
    else:
        print("‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")

    results = {}
    all_plots = []

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    max_sequence_length = 15  # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è –ø–æ–∫–µ—Ä–∞
    training_params = {"hidden_dim": 128, "num_layers": 3, "epochs": 25, "lr": 0.001}

    print(f"\nüéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:")
    print(f"   üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {max_sequence_length}")
    print(f"   üß† –°–∫—Ä—ã—Ç—ã—Ö –Ω–µ–π—Ä–æ–Ω–æ–≤: {training_params['hidden_dim']}")
    print(f"   üèóÔ∏è  –°–ª–æ–µ–≤ RWKV: {training_params['num_layers']}")
    print(f"   üìö –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: {training_params['epochs']}")
    print(f"   üìà Learning rate: {training_params['lr']}")

    # ======================================================================
    # 1. –ú–û–î–ï–õ–¨ –° –ö–ê–†–¢–ê–ú–ò –ò–ì–†–û–ö–ê
    # ======================================================================
    print(f"\n" + "=" * 80)
    print(f"üéØ 1. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –° –ö–ê–†–¢–ê–ú–ò –ò–ì–†–û–ö–ê (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)")
    print(f"=" * 80)

    try:
        print(f"üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞...")
        data_with_cards = prepare_sequence_hand_range_data_with_hm3(
            data_path,
            include_hole_cards=True,
            max_sequence_length=max_sequence_length,
            use_hm3_classification=True,  # –í–∫–ª—é—á–∞–µ–º HM3!
        )

        if data_with_cards is not None:
            print(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
            model_with_cards, history_with_cards = train_sequence_hand_range_model(
                data_with_cards, **training_params
            )

            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            print(f"üîç –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
            results["with_cards"] = evaluate_sequence_model_performance(
                model_with_cards, data_with_cards, include_hole_cards=True
            )

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
            fig1, plot_path1 = visualize_sequence_results(
                model_with_cards, data_with_cards, history_with_cards, True
            )
            all_plots.append(plot_path1)
            plt.show()

            # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predict_sequence_hand_ranges(
                model_with_cards, data_with_cards, sample_hands=3
            )

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path, best_path = save_sequence_model(
                model_with_cards, data_with_cards, results["with_cards"], True
            )

            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏ –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –∫–∞—Ä—Ç–∞–º–∏")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —Å –∫–∞—Ä—Ç–∞–º–∏: {e}")
        import traceback

        traceback.print_exc()

    # ======================================================================
    # 2. –ú–û–î–ï–õ–¨ –ë–ï–ó –ö–ê–†–¢ –ò–ì–†–û–ö–ê
    # ======================================================================
    print(f"\n" + "=" * 80)
    print(f"üé≤ 2. –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ë–ï–ó –ö–ê–†–¢ –ò–ì–†–û–ö–ê (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)")
    print(f"   üéØ –¶–µ–ª—å: —É–≥–∞–¥–∞—Ç—å –∫–∞—Ä—Ç—ã –ø–æ –ø–æ–≤–µ–¥–µ–Ω–∏—é –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–π—Å—Ç–≤–∏–π")
    print(f"=" * 80)

    try:
        print(f"üì• –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞...")
        data_without_cards = prepare_sequence_hand_range_data_with_hm3(
            data_path, include_hole_cards=False, max_sequence_length=max_sequence_length
        )

        if data_without_cards is not None:
            print(f"üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
            model_without_cards, history_without_cards = (
                train_sequence_hand_range_model(data_without_cards, **training_params)
            )

            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
            print(f"üîç –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
            results["without_cards"] = evaluate_sequence_model_performance(
                model_without_cards, data_without_cards, include_hole_cards=False
            )

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤...")
            fig2, plot_path2 = visualize_sequence_results(
                model_without_cards, data_without_cards, history_without_cards, False
            )
            all_plots.append(plot_path2)
            plt.show()

            # –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            predict_sequence_hand_ranges(
                model_without_cards, data_without_cards, sample_hands=3
            )

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path, best_path = save_sequence_model(
                model_without_cards, data_without_cards, results["without_cards"], False
            )

            print(f"‚úÖ –ú–æ–¥–µ–ª—å –±–µ–∑ –∫–∞—Ä—Ç –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –±–µ–∑ –∫–∞—Ä—Ç")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –±–µ–∑ –∫–∞—Ä—Ç: {e}")
        import traceback

        traceback.print_exc()

    # ======================================================================
    # 3. –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô
    # ======================================================================
    print(f"\n" + "=" * 80)
    print(f"üèÜ === –°–†–ê–í–ù–ï–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–´–• –ú–û–î–ï–õ–ï–ô ===")
    print(f"=" * 80)

    if "with_cards" in results and "without_cards" in results:
        with_cards_acc = results["with_cards"]["strength_accuracy"]
        without_cards_acc = results["without_cards"]["strength_accuracy"]

        with_cards_cat_acc = results["with_cards"]["category_accuracy"]
        without_cards_cat_acc = results["without_cards"]["category_accuracy"]

        with_cards_mse = results["with_cards"]["specific_mse"]
        without_cards_mse = results["without_cards"]["specific_mse"]

        print(f"üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–ª—ã —Ä—É–∫–∏:")
        print(f"   üéØ –° –∫–∞—Ä—Ç–∞–º–∏ –∏–≥—Ä–æ–∫–∞: {with_cards_acc:.3f}")
        print(f"   üé≤ –ë–µ–∑ –∫–∞—Ä—Ç –∏–≥—Ä–æ–∫–∞: {without_cards_acc:.3f}")
        print(f"   üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_acc - without_cards_acc:.3f}")

        print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π:")
        print(f"   üéØ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_cat_acc:.3f}")
        print(f"   üé≤ –ë–µ–∑ –∫–∞—Ä—Ç: {without_cards_cat_acc:.3f}")
        print(f"   üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_cat_acc - without_cards_cat_acc:.3f}")

        print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ MSE —Ä–∞–Ω–≥–æ–≤:")
        print(f"   üéØ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_mse:.4f}")
        print(f"   üé≤ –ë–µ–∑ –∫–∞—Ä—Ç: {without_cards_mse:.4f}")
        print(f"   üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_mse - without_cards_mse:.4f}")

        # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüß† === –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===")

        strength_diff = with_cards_acc - without_cards_acc
        if strength_diff > 0.1:
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ (+{strength_diff:.1%})")
            print(f"   üí° –≠—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ: –∑–Ω–∞—è –∫–∞—Ä—Ç—ã, –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –ª—É—á—à–µ")
        elif strength_diff > 0.05:
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å –∫–∞—Ä—Ç–∞–º–∏ –ª—É—á—à–µ (+{strength_diff:.1%})")
            print(f"   üí° –£–º–µ—Ä–µ–Ω–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ")
        elif abs(strength_diff) <= 0.05:
            print(
                f"ü§î –ú–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—É—é —Ç–æ—á–Ω–æ—Å—Ç—å (¬±{abs(strength_diff):.1%})"
            )
            print(
                f"   üí° –≠—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ: –º–æ–¥–µ–ª—å –Ω–∞—É—á–∏–ª–∞—Å—å —É–≥–∞–¥—ã–≤–∞—Ç—å –∫–∞—Ä—Ç—ã –ø–æ –ø–æ–≤–µ–¥–µ–Ω–∏—é!"
            )
            print(f"   üéØ –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            print(f"      - –ò–≥—Ä–æ–∫–∏ —Å–ª–∏—à–∫–æ–º –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã –≤ —Å–≤–æ–∏—Ö –¥–µ–π—Å—Ç–≤–∏—è—Ö")
            print(f"      - –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —Å–∏—Ç—É–∞—Ü–∏–µ–π –∏ —Å–∏–ª–æ–π —Ä—É–∫–∏")
            print(f"      - –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö")
        else:
            print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –±–µ–∑ –∫–∞—Ä—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ (+{abs(strength_diff):.1%})")
            print(f"   ü§î –≠—Ç–æ —Å—Ç—Ä–∞–Ω–Ω–æ –∏ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        with_cards_seqs = results["with_cards"]["total_sequences"]
        without_cards_seqs = results["without_cards"]["total_sequences"]

        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:")
        print(f"   üéØ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_seqs} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
        print(f"   üé≤ –ë–µ–∑ –∫–∞—Ä—Ç: {without_cards_seqs} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        comparison_report = {
            "timestamp": datetime.now().isoformat(),
            "data_file": data_path,
            "total_records": total_rows,
            "showdown_records": showdown_count,
            "sequence_params": {
                "max_sequence_length": max_sequence_length,
            },
            "training_params": training_params,
            "models": {
                "with_cards": {
                    "strength_accuracy": float(with_cards_acc),
                    "category_accuracy": float(with_cards_cat_acc),
                    "specific_mse": float(with_cards_mse),
                    "total_sequences": int(with_cards_seqs),
                },
                "without_cards": {
                    "strength_accuracy": float(without_cards_acc),
                    "category_accuracy": float(without_cards_cat_acc),
                    "specific_mse": float(without_cards_mse),
                    "total_sequences": int(without_cards_seqs),
                },
            },
            "differences": {
                "strength_accuracy_diff": float(strength_diff),
                "category_accuracy_diff": float(
                    with_cards_cat_acc - without_cards_cat_acc
                ),
                "specific_mse_diff": float(with_cards_mse - without_cards_mse),
            },
            "plots": all_plots,
        }

        report_path = f"results/sequence_comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, "w", encoding="utf-8") as f:
            final_report_safe = safe_json_serialize(final_report)
            json.dump(final_report_safe, f, indent=2, ensure_ascii=False)

        print(f"üìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    elif "with_cards" in results:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –° –∫–∞—Ä—Ç–∞–º–∏")
        print(
            f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏: {results['with_cards']['strength_accuracy']:.3f}"
        )
    elif "without_cards" in results:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –ë–ï–ó –∫–∞—Ä—Ç")
        print(
            f"   üé≤ –¢–æ—á–Ω–æ—Å—Ç—å —Å–∏–ª—ã —Ä—É–∫–∏: {results['without_cards']['strength_accuracy']:.3f}"
        )
    else:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å")
        return

    # ======================================================================
    # 4. –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï
    # ======================================================================
    print(f"\nüéâ === –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û ===")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–∞—Ö:")
    print(f"   ü§ñ models/     - –æ–±—É—á–µ–Ω–Ω—ã–µ RWKV –º–æ–¥–µ–ª–∏")
    print(f"   üìä plots/      - –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞")
    print(f"   üìã results/    - –æ—Ç—á–µ—Ç—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
    print(f"   üÉè results/poker_categories.json - —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ä—É–∫")

    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print(f"   üìö –ò–∑—É—á–∏—Ç–µ –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
    print(f"   üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ª–æ–≥–∏–∫–∏ –º–æ–¥–µ–ª–∏")
    print(f"   üìä –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)")
    print(f"   üéØ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")

    return results


def save_sequence_model(model, data_dict, performance, include_hole_cards):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_type = (
        "sequence_with_cards" if include_hole_cards else "sequence_without_cards"
    )

    model_name = f"hand_range_{model_type}"
    model_file = f"{model_name}_{timestamp}.pth"

    os.makedirs("models", exist_ok=True)
    model_path = os.path.join("models", model_file)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å —Å–æ –≤—Å–µ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    torch.save(
        {
            "model_state": model.state_dict(),
            "model_class": "SequenceHandRangeRWKV",
            "scaler": data_dict["scaler"],
            "encoders": data_dict.get("encoders", {}),
            "feature_columns": data_dict["feature_columns"],
            "input_dim": data_dict["input_dim"],
            "max_sequence_length": data_dict["max_sequence_length"],
            "include_hole_cards": include_hole_cards,
            "performance": performance,
            "timestamp": timestamp,
            "categories": PokerHandAnalyzer.get_all_categories(),
            "category_mapping": PokerHandAnalyzer.get_category_mapping(),
            "rank_names": PokerHandAnalyzer.get_rank_names(),
            "model_type": "sequence_based",
            "framework": "pytorch_rwkv",
        },
        model_path,
    )

    # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    best_model_path = os.path.join("models", f"{model_name}_best.pth")
    if os.path.exists(best_model_path):
        os.remove(best_model_path)

    import shutil

    shutil.copy2(model_path, best_model_path)

    print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:")
    print(f"   üìÅ {model_path}")
    print(f"   üîó {best_model_path} (–ª—É—á—à–∞—è)")

    return model_path, best_model_path


def process_all_files_with_sequences():
    """
    –ú–∞—Å—Å–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏
    """
    print(f"\nüöÄ === –ú–ê–°–°–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –° –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–Ø–ú–ò ===")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    result = combine_all_data_files()
    if result is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã")
        return

    combined_filename, combination_summary = result

    print(f"\nüéØ === –û–ë–£–ß–ï–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–´–• –ú–û–î–ï–õ–ï–ô –ù–ê –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–• –î–ê–ù–ù–´–• ===")
    print(f"üìÅ –§–∞–π–ª: {combined_filename}")
    print(f"üìä –®–æ—É–¥–∞—É–Ω–æ–≤: {combination_summary['total_showdowns']:,}")

    if combination_summary["total_showdowns"] < 100:
        print("‚ö†Ô∏è  –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π!")
        return

    results = {}
    all_plots = []

    max_sequence_length = 20  # –ë–æ–ª—å—à–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    training_params = {
        "hidden_dim": 256,  # –ë–æ–ª—å—à–µ –Ω–µ–π—Ä–æ–Ω–æ–≤
        "num_layers": 4,  # –ë–æ–ª—å—à–µ —Å–ª–æ–µ–≤
        "epochs": 30,  # –ë–æ–ª—å—à–µ —ç–ø–æ—Ö
        "lr": 0.0008,  # –ß—É—Ç—å –º–µ–Ω—å—à–µ lr
    }

    print(f"üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    for key, value in training_params.items():
        print(f"   {key}: {value}")
    print(f"   max_sequence_length: {max_sequence_length}")

    # –û–±—É—á–∞–µ–º –æ–±–µ –º–æ–¥–µ–ª–∏
    for model_type, include_cards in [("–ë–ï–ó –∫–∞—Ä—Ç", False), ("–° –∫–∞—Ä—Ç–∞–º–∏", True)]:
        print(f"\n{'='*80}")
        print(
            f"üé≤ –û–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ {model_type} –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
        )
        print(f"{'='*80}")

        try:
            data_dict = prepare_sequence_hand_range_data_with_hm3(
                combined_filename,
                include_hole_cards=include_cards,
                max_sequence_length=max_sequence_length,
            )

            if data_dict is not None:
                model, history = train_sequence_hand_range_model(
                    data_dict, **training_params
                )

                performance = evaluate_sequence_model_performance(
                    model, data_dict, include_hole_cards=include_cards
                )

                fig, plot_path = visualize_sequence_results(
                    model, data_dict, history, include_cards
                )
                all_plots.append(plot_path)
                plt.show()

                predict_sequence_hand_ranges(model, data_dict, sample_hands=5)

                model_path, best_path = save_sequence_model(
                    model, data_dict, performance, include_cards
                )

                model_key = "with_cards" if include_cards else "without_cards"

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ –æ–±—ã—á–Ω—ã–µ Python —Ç–∏–ø—ã –¥–ª—è JSON
                results[model_key] = {
                    "strength_accuracy": float(performance["strength_accuracy"]),
                    "category_accuracy": float(performance["category_accuracy"]),
                    "specific_mse": float(performance["specific_mse"]),
                    "total_sequences": int(performance["total_sequences"]),
                }

                print(f"‚úÖ –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å {model_type} –æ–±—É—á–µ–Ω–∞!")

            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏ {model_type}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_type}: {e}")
            import traceback

            traceback.print_exc()
            continue

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    if "with_cards" in results and "without_cards" in results:
        print(f"\nüèÜ === –§–ò–ù–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–´–• –ú–û–î–ï–õ–ï–ô ===")

        with_cards_acc = results["with_cards"]["strength_accuracy"]
        without_cards_acc = results["without_cards"]["strength_accuracy"]

        print(f"üéØ –° –∫–∞—Ä—Ç–∞–º–∏: {with_cards_acc:.3f}")
        print(f"üé≤ –ë–µ–∑ –∫–∞—Ä—Ç: {without_cards_acc:.3f}")
        print(f"üìà –†–∞–∑–Ω–∏—Ü–∞: {with_cards_acc - without_cards_acc:.3f}")

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
        final_report = {
            "timestamp": datetime.now().isoformat(),
            "model_type": "sequence_based_rwkv",
            "combined_data_summary": {
                "total_files": int(combination_summary["total_files"]),
                "total_records": int(combination_summary["total_records"]),
                "total_showdowns": int(combination_summary["total_showdowns"]),
                "combined_file": str(combination_summary["combined_file"]),
            },
            "sequence_params": {"max_length": int(max_sequence_length)},
            "training_params": {
                k: float(v) if isinstance(v, (int, float)) else str(v)
                for k, v in training_params.items()
            },
            "results": results,
            "plots": [str(p) for p in all_plots],
        }

        report_path = f"results/sequence_combined_training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(final_report, f, indent=2, ensure_ascii=False)

        print(f"üìã –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {report_path}")

    print(f"\nüéâ –ú–∞—Å—Å–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


# –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–∞–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏
    main_with_sequences()

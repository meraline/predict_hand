#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö 73 –∫–ª–∞—Å—Å–æ–≤ HM3
—Å —É—á–µ—Ç–æ–º –∏—Ö —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ —Å–∏–ª–µ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, OrderedDict
import json
import os
import sys
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª–∞—Å—Å—ã
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

class HM3OrdinalAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è 73 –∫–ª–∞—Å—Å–æ–≤ HM3 —Å —É—á–µ—Ç–æ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self):
        # –ü–æ–ª–Ω—ã–π —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –æ—Ç —Å–∏–ª—å–Ω–µ–π—à–∏—Ö –∫ —Å–ª–∞–±–µ–π—à–∏–º
        self.strength_mapping = {
            # –ö–ª–∞—Å—Å 4: –ú–û–ù–°–¢–†–´ (–∏–Ω–¥–µ–∫—Å—ã 0-13)
            "TwoCardStraightFlush": 4,
            "OneCardStraightFlush": 4, 
            "FourOfAKindWithPocketPair": 4,
            "FourOfAKindWithoutPocketPair": 4,
            "FourOfAKindOnBoard": 4,
            "OneCardFullHouseTopPair": 4,
            "OneCardFullHouseTripsOnBoard": 4,
            "FullHouseWithPocketPairNoTripsOnBoard": 4,
            "TwoCardFullHouseWithoutPocketPair": 4,
            "FullHouseWithPocketPairTripsOnBoard": 4,
            "ThreeFlushBoardNutFlush": 4,
            "FourFlushBoardNutFlush": 4,
            "TwoCardNutStraight": 4,
            "OneCardNutStraight": 4,
            
            # –ö–ª–∞—Å—Å 3: –°–ò–õ–¨–ù–´–ï (–∏–Ω–¥–µ–∫—Å—ã 14-23)
            "ThreeFlushBoardHighFlush": 3,
            "FourFlushBoardHighFlush": 3,
            "TwoCardStraight": 3,
            "OneCardStraight": 3,
            "HighSet": 3,
            "SecondSet": 3,
            "LowSet": 3,
            "HighTripsHighKicker": 3,
            "HighTripsLowKicker": 3,
            "TopTwoPair": 3,
            
            # –ö–ª–∞—Å—Å 2: –°–†–ï–î–ù–ò–ï (–∏–Ω–¥–µ–∫—Å—ã 24-42)
            "ThreeFlushBoardLowFlush": 2,
            "FourFlushBoardLowFlush": 2,
            "SecondTripsHighKicker": 2,
            "SecondTripsLowKicker": 2,
            "LowTripsHighKicker": 2,
            "LowTripsLowKicker": 2,
            "TripsOnBoard": 2,
            "TopPairPlusPair": 2,
            "NonTopTwoPair": 2,
            "PocketPairOverPairPlusLowerPairedBoard": 2,
            "PocketPairPlusHigherPairedBoard": 2,
            "PocketPairPlusLowerPairedBoard": 2,
            "TopPairPlusPairedBoard": 2,
            "SecondPairPlusPairedBoard": 2,
            "LowPairPlusPairedBoard": 2,
            "TwoPairsOnBoard": 2,
            "OverPair": 2,
            "TopPairTopKicker": 2,
            "TopPairGoodKicker": 2,
            
            # –ö–ª–∞—Å—Å 1: –°–õ–ê–ë–´–ï (–∏–Ω–¥–µ–∫—Å—ã 43-56)
            "TopPairWeakKicker": 1,
            "SecondPocketPair": 1,
            "SecondPairAceKicker": 1,
            "SecondPairNonAceKicker": 1,
            "LowPocketPair": 1,
            "BottomPairAceKicker": 1,
            "BottomPairNonAceKicker": 1,
            "PairedBoardNoOvercards": 1,
            "PairedBoardOneOvercard": 1,
            "PairedBoardTwoOvercards": 1,
            "TwoCardNutFlushDraw": 1,
            "TwoCardHighFlushDraw": 1,
            "OneCardNutFlushDraw": 1,
            "OneCardHighFlushDraw": 1,
            
            # –ö–ª–∞—Å—Å 0: –ú–£–°–û–†/–î–†–û (–∏–Ω–¥–µ–∫—Å—ã 57-72)
            "TwoCardLowFlushDraw": 0,
            "OneCardLowFlushDraw": 0,
            "TwoCardBackdoorNutFlushDraw": 0,
            "TwoCardBackdoorFlushDraw": 0,
            "OneCardBackDoorNutFlushDraw": 0,
            "OneCardBackDoorFlushDraw": 0,
            "TwoCardDoubleGutShotStraightDraw": 0,
            "TwoCardOpenEndedStraightDraw": 0,
            "OneCardOpenEndedStraightDraw": 0,
            "TwoCardGutshotStraightDraw": 0,
            "OneCardGutshotStraightDraw": 0,
            "TwoCardBackdoorStraightDraw": 0,
            "OneCardBackdoorStraightDraw": 0,
            "AceOnBoard": 0,
            "KingOnBoard": 0,
            "Other": 0
        }
        
        # –°–æ–∑–¥–∞–µ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        self.ordered_categories = list(self.strength_mapping.keys())
        self.category_to_index = {cat: i for i, cat in enumerate(self.ordered_categories)}
        
        # –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã
        self.strength_names = {
            0: "–ú—É—Å–æ—Ä/–î—Ä–æ",
            1: "–°–ª–∞–±—ã–µ",
            2: "–°—Ä–µ–¥–Ω–∏–µ",
            3: "–°–∏–ª—å–Ω—ã–µ",
            4: "–ú–æ–Ω—Å—Ç—Ä—ã"
        }
    
    def analyze_data(self, file_path):
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç–∏
        """
        print(f"üîç === –ê–ù–ê–õ–ò–ó HM3 –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –° –£–ß–ï–¢–û–ú –£–ü–û–†–Ø–î–û–ß–ï–ù–ù–û–°–¢–ò ===\n")
        print(f"üìÅ –§–∞–π–ª: {file_path}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        df = pd.read_csv(file_path)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º
        mask = (df['Showdown_1'].notna()) & (df['Showdown_2'].notna())
        df_showdown = df[mask].copy()
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üÉè –ó–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º: {len(df_showdown)} ({len(df_showdown)/len(df)*100:.1f}%)\n")
        
        if len(df_showdown) == 0:
            print("‚ùå –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º!")
            return None
        
        # –î–æ–±–∞–≤–ª—è–µ–º HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        print(f"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ HM3 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏...")
        from hand_range_prediction import add_hand_evaluation_to_dataframe
        df_analyzed = add_hand_evaluation_to_dataframe(df_showdown)
        
        # –ü–æ–¥—Å—á–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        hand_type_counts = df_analyzed['hand_type_hm3'].value_counts()
        total_hands = len(df_analyzed)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        analysis_results = self._detailed_analysis(hand_type_counts, total_hands)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._create_visualizations(analysis_results, hand_type_counts)
        
        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–æ–∫
        grouping_proposals = self._propose_groupings(analysis_results, hand_type_counts)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        if '10percent_quantiles' in grouping_proposals:
            print(f"\nüìä –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏...")
            self.visualize_10percent_grouping(
                grouping_proposals['10percent_quantiles'], 
                analysis_results['ordered_stats']
            )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._save_results(analysis_results, grouping_proposals)
        
        return analysis_results, grouping_proposals
    
    def _detailed_analysis(self, hand_type_counts, total_hands):
        """
        –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        """
        print(f"\nüìä === –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø ===")
        print(f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ä—É–∫: {len(hand_type_counts)}")
        print(f"–í—Å–µ–≥–æ —Ä—É–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_hands:,}\n")
        
        # –°–æ–∑–¥–∞–µ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        ordered_stats = []
        missing_categories = []
        
        for i, category in enumerate(self.ordered_categories):
            if category in hand_type_counts.index:
                count = hand_type_counts[category]
                percentage = count / total_hands * 100
                strength_class = self.strength_mapping[category]
                
                ordered_stats.append({
                    'index': i,
                    'category': category,
                    'count': count,
                    'percentage': percentage,
                    'strength_class': strength_class,
                    'strength_name': self.strength_names[strength_class],
                    'cumulative_percentage': 0  # –ó–∞–ø–æ–ª–Ω–∏–º –ø–æ–∑–∂–µ
                })
            else:
                missing_categories.append(category)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        cumsum = 0
        for stat in ordered_stats:
            cumsum += stat['percentage']
            stat['cumulative_percentage'] = cumsum
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã
        strength_distribution = defaultdict(lambda: {'count': 0, 'types': 0, 'categories': []})
        
        for stat in ordered_stats:
            sc = stat['strength_class']
            strength_distribution[sc]['count'] += stat['count']
            strength_distribution[sc]['types'] += 1
            strength_distribution[sc]['categories'].append(stat['category'])
        
        print("üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã:")
        for strength in sorted(strength_distribution.keys(), reverse=True):
            info = strength_distribution[strength]
            percentage = info['count'] / total_hands * 100
            print(f"\nüí™ –ö–ª–∞—Å—Å {strength} - {self.strength_names[strength]}:")
            print(f"   –í—Å–µ–≥–æ —Ä—É–∫: {info['count']:,} ({percentage:.1f}%)")
            print(f"   –¢–∏–ø–æ–≤ —Ä—É–∫: {info['types']}")
            
            # –¢–æ–ø-5 –≤ –∫–ª–∞—Å—Å–µ
            class_categories = sorted(
                [(cat, hand_type_counts[cat]) for cat in info['categories'] if cat in hand_type_counts.index],
                key=lambda x: x[1], reverse=True
            )[:5]
            
            print(f"   –¢–æ–ø-5 —Ç–∏–ø–æ–≤:")
            for cat, cnt in class_categories:
                print(f"      {cat}: {cnt} ({cnt/total_hands*100:.2f}%)")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–æ–Ω
        problems = self._analyze_problems(ordered_stats, missing_categories)
        
        # –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–∞
        balance_metrics = self._analyze_balance(ordered_stats)
        
        return {
            'ordered_stats': ordered_stats,
            'strength_distribution': dict(strength_distribution),
            'missing_categories': missing_categories,
            'problems': problems,
            'balance_metrics': balance_metrics,
            'total_hands': total_hands
        }
    
    def _analyze_problems(self, ordered_stats, missing_categories):
        """
        –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–æ–Ω –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏
        """
        print(f"\nüö® === –ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú–ù–´–• –ó–û–ù ===")
        
        problems = {
            'missing': missing_categories,
            'rare': [],      # < 10 –ø—Ä–∏–º–µ—Ä–æ–≤
            'scarce': [],    # < 50 –ø—Ä–∏–º–µ—Ä–æ–≤
            'sparse': [],    # < 0.1%
            'gaps': [],      # –ü—Ä–æ–º–µ–∂—É—Ç–∫–∏ –≤ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç–∏
            'imbalanced_regions': []
        }
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        prev_index = -1
        for stat in ordered_stats:
            # –†–µ–¥–∫–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
            if stat['count'] < 10:
                problems['rare'].append((stat['category'], stat['count']))
            elif stat['count'] < 50:
                problems['scarce'].append((stat['category'], stat['count']))
            
            # –†–µ–¥–∫–∏–µ –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É
            if stat['percentage'] < 0.1:
                problems['sparse'].append((stat['category'], stat['percentage']))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–∏
            if stat['index'] - prev_index > 1:
                gap_size = stat['index'] - prev_index - 1
                problems['gaps'].append({
                    'start': prev_index,
                    'end': stat['index'],
                    'size': gap_size,
                    'missing': self.ordered_categories[prev_index+1:stat['index']]
                })
            
            prev_index = stat['index']
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
        # –î–µ–ª–∏–º –Ω–∞ –∫–≤–∏–Ω—Ç–∏–ª–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É
        quintile_size = len(self.ordered_categories) // 5
        for q in range(5):
            start_idx = q * quintile_size
            end_idx = (q + 1) * quintile_size if q < 4 else len(self.ordered_categories)
            
            quintile_stats = [s for s in ordered_stats if start_idx <= s['index'] < end_idx]
            if quintile_stats:
                quintile_count = sum(s['count'] for s in quintile_stats)
                quintile_pct = sum(s['percentage'] for s in quintile_stats)
                
                problems['imbalanced_regions'].append({
                    'quintile': q + 1,
                    'range': f"{self.ordered_categories[start_idx]} - {self.ordered_categories[end_idx-1]}",
                    'count': quintile_count,
                    'percentage': quintile_pct,
                    'expected_pct': 20.0
                })
        
        # –í—ã–≤–æ–¥ –ø—Ä–æ–±–ª–µ–º
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(problems['missing'])}")
        if problems['missing']:
            print(f"   {problems['missing'][:5]}..." if len(problems['missing']) > 5 else f"   {problems['missing']}")
        
        print(f"\n‚ö†Ô∏è –†–µ–¥–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        print(f"   < 10 –ø—Ä–∏–º–µ—Ä–æ–≤: {len(problems['rare'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        print(f"   < 50 –ø—Ä–∏–º–µ—Ä–æ–≤: {len(problems['scarce'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        print(f"   < 0.1%: {len(problems['sparse'])} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        
        print(f"\nüï≥Ô∏è –ü—Ä–æ–º–µ–∂—É—Ç–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {len(problems['gaps'])}")
        for gap in problems['gaps'][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            print(f"   –ü—Ä–æ–º–µ–∂—É—Ç–æ–∫ {gap['start']}-{gap['end']}: {gap['size']} –∫–∞—Ç–µ–≥–æ—Ä–∏–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        
        print(f"\nüìä –î–∏—Å–±–∞–ª–∞–Ω—Å –ø–æ –∫–≤–∏–Ω—Ç–∏–ª—è–º —Å–∏–ª—ã:")
        for region in problems['imbalanced_regions']:
            deviation = region['percentage'] - region['expected_pct']
            print(f"   –ö–≤–∏–Ω—Ç–∏–ª—å {region['quintile']}: {region['percentage']:.1f}% (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation:+.1f}%)")
        
        return problems
    
    def _analyze_balance(self, ordered_stats):
        """
        –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –±–∞–ª–∞–Ω—Å–∞
        """
        counts = [s['count'] for s in ordered_stats]
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = {
            'total_categories': len(self.ordered_categories),
            'present_categories': len(ordered_stats),
            'coverage': len(ordered_stats) / len(self.ordered_categories) * 100,
            'min_count': min(counts),
            'max_count': max(counts),
            'mean_count': np.mean(counts),
            'median_count': np.median(counts),
            'std_count': np.std(counts),
            'cv': np.std(counts) / np.mean(counts),  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
            'imbalance_ratio': max(counts) / min(counts),
            'gini_coefficient': self._calculate_gini(counts),
            'entropy': self._calculate_entropy([s['percentage']/100 for s in ordered_stats])
        }
        
        # –ê–Ω–∞–ª–∏–∑ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏ (–≤ –∏–¥–µ–∞–ª–µ —Å–∏–ª—å–Ω—ã–µ —Ä—É–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∂–µ)
        strength_counts = defaultdict(list)
        for stat in ordered_stats:
            strength_counts[stat['strength_class']].append(stat['count'])
        
        avg_by_strength = {
            strength: np.mean(counts) 
            for strength, counts in strength_counts.items()
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–±—ã–≤–∞–µ—Ç –ª–∏ —á–∞—Å—Ç–æ—Ç–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º —Å–∏–ª—ã
        is_monotonic = all(
            avg_by_strength.get(i, 0) >= avg_by_strength.get(i+1, 0) 
            for i in range(4)
        )
        
        metrics['natural_monotonicity'] = is_monotonic
        metrics['avg_by_strength'] = avg_by_strength
        
        print(f"\nüìà === –ú–ï–¢–†–ò–ö–ò –ë–ê–õ–ê–ù–°–ê ===")
        print(f"–ü–æ–∫—Ä—ã—Ç–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {metrics['coverage']:.1f}%")
        print(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–∞–∫—Å/–º–∏–Ω: {metrics['imbalance_ratio']:.1f}:1")
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {metrics['cv']:.2f}")
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –î–∂–∏–Ω–∏: {metrics['gini_coefficient']:.3f}")
        print(f"–≠–Ω—Ç—Ä–æ–ø–∏—è: {metrics['entropy']:.3f}")
        print(f"–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {'‚úÖ –î–∞' if is_monotonic else '‚ùå –ù–µ—Ç'}")
        
        return metrics
    
    def _calculate_gini(self, values):
        """–†–∞—Å—á–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –î–∂–∏–Ω–∏"""
        sorted_values = sorted(values)
        n = len(values)
        cumsum = np.cumsum(sorted_values)
        return (2 * np.sum((i + 1) * sorted_values[i] for i in range(n))) / (n * cumsum[-1]) - (n + 1) / n
    
    def _calculate_entropy(self, probabilities):
        """–†–∞—Å—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏"""
        return -sum(p * np.log2(p) if p > 0 else 0 for p in probabilities)
    
    def _propose_groupings(self, analysis_results, hand_type_counts):
        """
        –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        """
        print(f"\nüéØ === –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø –ü–û –ì–†–£–ü–ü–ò–†–û–í–ö–ï ===")
        
        proposals = {}
        ordered_stats = analysis_results['ordered_stats']
        total_hands = analysis_results['total_hands']
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        proposals['uniform_count'] = self._create_uniform_count_groups(ordered_stats, target_groups=15)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º —Å–∏–ª—ã
        proposals['uniform_strength'] = self._create_uniform_strength_groups(ordered_stats, target_groups=15)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è (—É—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã)
        proposals['adaptive'] = self._create_adaptive_groups(ordered_stats, analysis_results['problems'])
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è (–ø–æ —Ç–∏–ø–∞–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–π)
        proposals['semantic'] = self._create_semantic_groups()
        
        # –ù–û–í–ê–Ø –°—Ç—Ä–∞—Ç–µ–≥–∏—è 5: –ü–æ 10% –∫–≤–∞–Ω—Ç–∏–ª—è–º
        proposals['10percent_quantiles'] = self._create_10percent_groups(ordered_stats)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        print(f"\nüìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏:")
        
        for strategy_name, groups in proposals.items():
            print(f"\nüìå –°—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy_name}")
            quality = self._evaluate_grouping_quality(groups, ordered_stats)
            
            print(f"   –ì—Ä—É–ø–ø: {quality['num_groups']}")
            print(f"   –ë–∞–ª–∞–Ω—Å —Ä–∞–∑–º–µ—Ä–æ–≤ (CV): {quality['size_cv']:.2f}")
            print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞: {'‚úÖ' if quality['preserves_order'] else '‚ùå'}")
            print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö: {quality['coverage']:.1f}%")
            print(f"   –ú–∏–Ω/–ú–∞–∫—Å —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã: {quality['min_size']}/{quality['max_size']}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        best_strategy = self._recommend_best_strategy(proposals, ordered_stats)
        print(f"\nüèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {best_strategy}")
        
        return proposals
    
    
    # 2. –ù–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ 10% –∫–≤–∞–Ω—Ç–∏–ª—è–º
    def _create_10percent_groups(self, ordered_stats):
        """
        –°–æ–∑–¥–∞–µ—Ç –≥—Ä—É–ø–ø—ã –ø–æ 10% –∫–≤–∞–Ω—Ç–∏–ª—è–º –¥–∞–Ω–Ω—ã—Ö —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ—Å—Ç–∏
        –ö–∞–∂–¥–∞—è –≥—Ä—É–ø–ø–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 10% –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä—É–∫
        """
        total_count = sum(s['count'] for s in ordered_stats)
        target_per_group = total_count * 0.1  # 10% –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        
        groups = []
        current_group = {
            'categories': [], 
            'total_count': 0, 
            'indices': [],
            'percentage': 0.0,
            'strength_classes': set()
        }
        
        cumulative_count = 0
        group_number = 1
        
        for stat in ordered_stats:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
            if current_group['total_count'] > 0 and cumulative_count >= target_per_group * group_number:
                # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
                current_group['percentage'] = current_group['total_count'] / total_count * 100
                groups.append(current_group)
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
                group_number += 1
                current_group = {
                    'categories': [], 
                    'total_count': 0, 
                    'indices': [],
                    'percentage': 0.0,
                    'strength_classes': set()
                }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
            current_group['categories'].append(stat['category'])
            current_group['total_count'] += stat['count']
            current_group['indices'].append(stat['index'])
            current_group['strength_classes'].add(stat['strength_class'])
            
            cumulative_count += stat['count']
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
        if current_group['categories']:
            current_group['percentage'] = current_group['total_count'] / total_count * 100
            groups.append(current_group)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        print(f"\nüìä 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–æ–∑–¥–∞–Ω–∞:")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä—É–ø–ø: {len(groups)}")
        
        for i, group in enumerate(groups):
            strength_desc = ", ".join([f"–ö–ª–∞—Å—Å {s}" for s in sorted(group['strength_classes'])])
            print(f"\n   –ì—Ä—É–ø–ø–∞ {i+1} ({group['percentage']:.1f}%):")
            print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(group['categories'])}")
            print(f"      –ü—Ä–∏–º–µ—Ä–æ–≤: {group['total_count']:,}")
            print(f"      –ò–Ω–¥–µ–∫—Å—ã: {min(group['indices'])}-{max(group['indices'])}")
            print(f"      –ö–ª–∞—Å—Å—ã —Å–∏–ª—ã: {strength_desc}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            sample_cats = group['categories'][:3]
            if len(group['categories']) > 3:
                print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(sample_cats)}...")
            else:
                print(f"      –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {', '.join(sample_cats)}")
        
        return groups

    
    def _create_uniform_count_groups(self, ordered_stats, target_groups=15):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä—É–ø–ø—ã —Å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤"""
        total_count = sum(s['count'] for s in ordered_stats)
        target_per_group = total_count / target_groups
        
        groups = []
        current_group = {'categories': [], 'total_count': 0, 'indices': []}
        
        for stat in ordered_stats:
            if current_group['total_count'] > 0 and \
               current_group['total_count'] + stat['count'] > target_per_group * 1.2:
                groups.append(current_group)
                current_group = {'categories': [], 'total_count': 0, 'indices': []}
            
            current_group['categories'].append(stat['category'])
            current_group['total_count'] += stat['count']
            current_group['indices'].append(stat['index'])
        
        if current_group['categories']:
            groups.append(current_group)
        
        return groups
    
    def _create_uniform_strength_groups(self, ordered_stats, target_groups=15):
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä—É–ø–ø—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É —Å–∏–ª—ã"""
        indices_per_group = len(self.ordered_categories) / target_groups
        
        groups = []
        current_group_id = 0
        current_group = {'categories': [], 'total_count': 0, 'indices': []}
        
        for stat in ordered_stats:
            expected_group = int(stat['index'] / indices_per_group)
            
            if expected_group > current_group_id and current_group['categories']:
                groups.append(current_group)
                current_group = {'categories': [], 'total_count': 0, 'indices': []}
                current_group_id = expected_group
            
            current_group['categories'].append(stat['category'])
            current_group['total_count'] += stat['count']
            current_group['indices'].append(stat['index'])
        
        if current_group['categories']:
            groups.append(current_group)
        
        return groups
    
    def _create_adaptive_groups(self, ordered_stats, problems):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–æ–Ω"""
        groups = []
        current_group = {'categories': [], 'total_count': 0, 'indices': []}
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥–∏ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        min_group_size = 100  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã
        rare_threshold = 50   # –ü–æ—Ä–æ–≥ –¥–ª—è —Ä–µ–¥–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        
        for stat in ordered_stats:
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ä–µ–¥–∫–∞—è, –≤—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
            if stat['count'] < rare_threshold:
                current_group['categories'].append(stat['category'])
                current_group['total_count'] += stat['count']
                current_group['indices'].append(stat['index'])
            else:
                # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –≥—Ä—É–ø–ø–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∞—è, –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é
                if current_group['total_count'] >= min_group_size:
                    if current_group['categories']:
                        groups.append(current_group)
                    current_group = {'categories': [], 'total_count': 0, 'indices': []}
                
                current_group['categories'].append(stat['category'])
                current_group['total_count'] += stat['count']
                current_group['indices'].append(stat['index'])
        
        if current_group['categories']:
            groups.append(current_group)
        
        return groups
    
    def _create_semantic_groups(self):
        """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–π"""
        semantic_groups = [
            {
                'name': 'StraightFlushes',
                'categories': [c for c in self.ordered_categories if 'StraightFlush' in c],
                'indices': []
            },
            {
                'name': 'Quads',
                'categories': [c for c in self.ordered_categories if 'FourOfAKind' in c],
                'indices': []
            },
            {
                'name': 'FullHouses',
                'categories': [c for c in self.ordered_categories if 'FullHouse' in c],
                'indices': []
            },
            {
                'name': 'Flushes',
                'categories': [c for c in self.ordered_categories if 'Flush' in c and 'Draw' not in c and 'Straight' not in c],
                'indices': []
            },
            {
                'name': 'Straights',
                'categories': [c for c in self.ordered_categories if 'Straight' in c and 'Flush' not in c and 'Draw' not in c],
                'indices': []
            },
            {
                'name': 'Sets',
                'categories': [c for c in self.ordered_categories if 'Set' in c],
                'indices': []
            },
            {
                'name': 'Trips',
                'categories': [c for c in self.ordered_categories if 'Trips' in c],
                'indices': []
            },
            {
                'name': 'TwoPairs',
                'categories': [c for c in self.ordered_categories if 'TwoPair' in c or 'PairPlus' in c],
                'indices': []
            },
            {
                'name': 'TopPairs',
                'categories': [c for c in self.ordered_categories if 'TopPair' in c and 'Plus' not in c],
                'indices': []
            },
            {
                'name': 'MiddlePairs',
                'categories': [c for c in self.ordered_categories if any(x in c for x in ['SecondPair', 'OverPair', 'PocketPair'])],
                'indices': []
            },
            {
                'name': 'WeakPairs',
                'categories': [c for c in self.ordered_categories if any(x in c for x in ['BottomPair', 'LowPair', 'WeakKicker'])],
                'indices': []
            },
            {
                'name': 'StrongDraws',
                'categories': [c for c in self.ordered_categories if 'Draw' in c and any(x in c for x in ['Nut', 'High', 'OpenEnded'])],
                'indices': []
            },
            {
                'name': 'WeakDraws',
                'categories': [c for c in self.ordered_categories if 'Draw' in c and any(x in c for x in ['Low', 'Gutshot', 'Backdoor'])],
                'indices': []
            },
            {
                'name': 'HighCards',
                'categories': [c for c in self.ordered_categories if any(x in c for x in ['AceOnBoard', 'KingOnBoard', 'Other'])],
                'indices': []
            }
        ]
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
        for group in semantic_groups:
            group['indices'] = [self.category_to_index[cat] for cat in group['categories'] if cat in self.category_to_index]
            group['total_count'] = 0  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –≥—Ä—É–ø–ø—ã
        semantic_groups = [g for g in semantic_groups if g['categories']]
        
        return semantic_groups
    
    def _evaluate_grouping_quality(self, groups, ordered_stats):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏"""
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏—è -> count
        cat_counts = {s['category']: s['count'] for s in ordered_stats}
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º total_count –¥–ª—è –≥—Ä—É–ø–ø
        for group in groups:
            if 'total_count' not in group or group['total_count'] == 0:
                group['total_count'] = sum(cat_counts.get(cat, 0) for cat in group['categories'])
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        group_sizes = [g['total_count'] for g in groups if g['total_count'] > 0]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
        preserves_order = True
        for i in range(1, len(groups)):
            prev_indices = groups[i-1].get('indices', [])
            curr_indices = groups[i].get('indices', [])
            if prev_indices and curr_indices:
                if max(prev_indices) >= min(curr_indices):
                    preserves_order = False
                    break
        
        # –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö
        covered_categories = set()
        for group in groups:
            covered_categories.update(group['categories'])
        
        coverage = len(covered_categories) / len([s['category'] for s in ordered_stats]) * 100
        
        return {
            'num_groups': len(groups),
            'size_cv': np.std(group_sizes) / np.mean(group_sizes) if group_sizes else 0,
            'preserves_order': preserves_order,
            'coverage': coverage,
            'min_size': min(group_sizes) if group_sizes else 0,
            'max_size': max(group_sizes) if group_sizes else 0
        }
    
    def _recommend_best_strategy(self, proposals, ordered_stats):
        """–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –ª—É—á—à—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é"""
        scores = {}
        
        for strategy_name, groups in proposals.items():
            quality = self._evaluate_grouping_quality(groups, ordered_stats)
            
            # –°–∫–æ—Ä–∏–Ω–≥ (–≤–µ—Å–∞ –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
            score = 0
            score += (1 - quality['size_cv']) * 30  # –ë–∞–ª–∞–Ω—Å —Ä–∞–∑–º–µ—Ä–æ–≤ (30%)
            score += (1 if quality['preserves_order'] else 0) * 40  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ (40%)
            score += quality['coverage'] / 100 * 20  # –ü–æ–∫—Ä—ã—Ç–∏–µ (20%)
            score += (15 - abs(quality['num_groups'] - 15)) / 15 * 10  # –ë–ª–∏–∑–æ—Å—Ç—å –∫ —Ü–µ–ª–µ–≤–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (10%)
            
            scores[strategy_name] = score
        
        return max(scores.items(), key=lambda x: x[1])[0]
    
    def _create_visualizations(self, analysis_results, hand_type_counts):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
        print(f"\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        ordered_stats = analysis_results['ordered_stats']
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
        plt.style.use('seaborn-v0_8-darkgrid')
        fig = plt.figure(figsize=(20, 16))
        
        # 1. –£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        ax1 = plt.subplot(3, 3, 1)
        indices = [s['index'] for s in ordered_stats]
        counts = [s['count'] for s in ordered_stats]
        colors = [plt.cm.RdYlGn_r(s['strength_class']/4) for s in ordered_stats]
        
        ax1.bar(indices, counts, color=colors, alpha=0.8)
        ax1.set_xlabel('–ò–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (0=—Å–∏–ª—å–Ω–µ–π—à–∞—è)')
        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax1.set_title('–£–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–∏–ª–µ')
        ax1.set_yscale('log')
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã
        ax2 = plt.subplot(3, 3, 2)
        strength_counts = defaultdict(int)
        for stat in ordered_stats:
            strength_counts[stat['strength_class']] += stat['count']
        
        strengths = sorted(strength_counts.keys(), reverse=True)
        counts = [strength_counts[s] for s in strengths]
        labels = [f"{s}: {self.strength_names[s]}" for s in strengths]
        colors = ['green', 'lightgreen', 'yellow', 'orange', 'red'][:len(strengths)]
        
        wedges, texts, autotexts = ax2.pie(counts, labels=labels, colors=colors, 
                                           autopct='%1.1f%%', startangle=90)
        ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã')
        
        # 3. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        ax3 = plt.subplot(3, 3, 3)
        cumsum = np.cumsum([s['count'] for s in ordered_stats])
        cumsum_pct = cumsum / cumsum[-1] * 100
        
        ax3.plot(indices, cumsum_pct, 'b-', linewidth=3)
        ax3.fill_between(indices, 0, cumsum_pct, alpha=0.3)
        ax3.set_xlabel('–ò–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
        ax3.set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π %')
        ax3.set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö')
        ax3.grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–≤–∞–Ω—Ç–∏–ª–∏
        for q in [25, 50, 75, 90, 95]:
            idx = np.argmax(cumsum_pct >= q)
            ax3.axhline(y=q, color='r', linestyle='--', alpha=0.5)
            ax3.axvline(x=indices[idx], color='r', linestyle='--', alpha=0.5)
            ax3.text(indices[idx]+1, q-2, f'{q}%', fontsize=8)
        
        # 4. Heatmap —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å–∏–ª–µ
        ax4 = plt.subplot(3, 3, 4)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è heatmap
        matrix_size = 10
        heatmap_data = np.zeros((5, matrix_size))
        
        for stat in ordered_stats:
            strength = stat['strength_class']
            position = int(stat['index'] / len(self.ordered_categories) * matrix_size)
            position = min(position, matrix_size - 1)
            heatmap_data[strength, position] += stat['count']
        
        im = ax4.imshow(heatmap_data, cmap='YlOrRd', aspect='auto')
        ax4.set_yticks(range(5))
        ax4.set_yticklabels([self.strength_names[i] for i in range(5)])
        ax4.set_xlabel('–ü–æ–∑–∏—Ü–∏—è –≤ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ')
        ax4.set_ylabel('–ö–ª–∞—Å—Å —Å–∏–ª—ã')
        ax4.set_title('–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è')
        plt.colorbar(im, ax=ax4)
        
        # 5. –¢–æ–ø-20 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        ax5 = plt.subplot(3, 3, 5)
        top20 = hand_type_counts.head(20)
        y_pos = np.arange(len(top20))
        
        bars = ax5.barh(y_pos, top20.values)
        ax5.set_yticks(y_pos)
        ax5.set_yticklabels(top20.index, fontsize=8)
        ax5.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
        ax5.set_title('–¢–æ–ø-20 –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Ç–∏–ø–æ–≤')
        ax5.invert_yaxis()
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º –ø–æ —Å–∏–ª–µ
        for i, (cat, bar) in enumerate(zip(top20.index, bars)):
            if cat in self.category_to_index:
                strength = self.strength_mapping[cat]
                bar.set_color(plt.cm.RdYlGn_r(strength/4))
        
        # 6. –†–µ–¥–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        ax6 = plt.subplot(3, 3, 6)
        rare_stats = [s for s in ordered_stats if s['count'] < 50]
        
        if rare_stats:
            rare_indices = [s['index'] for s in rare_stats]
            rare_counts = [s['count'] for s in rare_stats]
            
            ax6.scatter(rare_indices, rare_counts, c='red', alpha=0.6, s=50)
            ax6.set_xlabel('–ò–Ω–¥–µ–∫—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
            ax6.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
            ax6.set_title(f'–†–µ–¥–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (<50 –ø—Ä–∏–º–µ—Ä–æ–≤): {len(rare_stats)}')
            ax6.set_ylim(0, 55)
        
        # 7. –ë–∞–ª–∞–Ω—Å –ø–æ –∫–≤–∏–Ω—Ç–∏–ª—è–º
        ax7 = plt.subplot(3, 3, 7)
        quintile_data = analysis_results['problems']['imbalanced_regions']
        
        quintiles = [f"Q{d['quintile']}" for d in quintile_data]
        percentages = [d['percentage'] for d in quintile_data]
        
        bars = ax7.bar(quintiles, percentages)
        ax7.axhline(y=20, color='r', linestyle='--', label='–û–∂–∏–¥–∞–µ–º–æ–µ (20%)')
        ax7.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç –¥–∞–Ω–Ω—ã—Ö')
        ax7.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–≤–∏–Ω—Ç–∏–ª—è–º —Å–∏–ª—ã')
        ax7.legend()
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        for bar, pct in zip(bars, percentages):
            if abs(pct - 20) > 5:
                bar.set_color('red')
            elif abs(pct - 20) > 2:
                bar.set_color('orange')
            else:
                bar.set_color('green')
        
        # 8. –ü—Ä–æ–º–µ–∂—É—Ç–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö
        ax8 = plt.subplot(3, 3, 8)
        gaps = analysis_results['problems']['gaps']
        
        if gaps:
            gap_positions = [(g['start'] + g['end']) / 2 for g in gaps]
            gap_sizes = [g['size'] for g in gaps]
            
            ax8.bar(range(len(gaps)), gap_sizes)
            ax8.set_xlabel('–ü—Ä–æ–º–µ–∂—É—Ç–æ–∫ #')
            ax8.set_ylabel('–†–∞–∑–º–µ—Ä –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞')
            ax8.set_title(f'–ü—Ä–æ–º–µ–∂—É—Ç–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {len(gaps)}')
        
        # 9. –ú–µ—Ç—Ä–∏–∫–∏ –±–∞–ª–∞–Ω—Å–∞
        ax9 = plt.subplot(3, 3, 9)
        metrics = analysis_results['balance_metrics']
        
        metric_names = ['CV', 'Gini', 'Entropy', 'Imbalance\nRatio/100']
        metric_values = [
            metrics['cv'],
            metrics['gini_coefficient'],
            metrics['entropy'] / np.log2(len(ordered_stats)),  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
            min(metrics['imbalance_ratio'] / 100, 1)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        ]
        
        bars = ax9.bar(metric_names, metric_values)
        ax9.set_ylim(0, 1)
        ax9.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ (0-1)')
        ax9.set_title('–ú–µ—Ç—Ä–∏–∫–∏ –±–∞–ª–∞–Ω—Å–∞')
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        for bar, val in zip(bars, metric_values):
            if val < 0.3:
                bar.set_color('green')
            elif val < 0.6:
                bar.set_color('orange')
            else:
                bar.set_color('red')
        
        plt.tight_layout()
        plt.savefig('hm3_ordinal_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ hm3_ordinal_analysis.png")
        
        
    ######
    def save_10percent_grouping_config(self, groups, ordered_stats, timestamp):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç–∞ –¥–ª—è –≥—Ä—É–ø–ø
        group_colors = [
            '#006400',  # G1 - –¢–µ–º–Ω–æ-–∑–µ–ª–µ–Ω—ã–π (—Å–∏–ª—å–Ω–µ–π—à–∏–µ)
            '#228B22',  # G2 - –õ–µ—Å–Ω–æ–π –∑–µ–ª–µ–Ω—ã–π
            '#32CD32',  # G3 - –õ–∞–π–º–æ–≤—ã–π
            '#7CFC00',  # G4 - –ó–µ–ª–µ–Ω—ã–π –≥–∞–∑–æ–Ω
            '#ADFF2F',  # G5 - –ñ–µ–ª—Ç–æ-–∑–µ–ª–µ–Ω—ã–π
            '#FFD700',  # G6 - –ó–æ–ª–æ—Ç–æ–π
            '#FFA500',  # G7 - –û—Ä–∞–Ω–∂–µ–≤—ã–π
            '#FF8C00',  # G8 - –¢–µ–º–Ω–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π
            '#FF6347',  # G9 - –¢–æ–º–∞—Ç–Ω—ã–π
            '#DC143C'   # G10 - –ú–∞–ª–∏–Ω–æ–≤—ã–π (—Å–ª–∞–±–µ–π—à–∏–µ)
        ]
        
        config_10pct = {
            'strategy': '10percent_quantiles',
            'description': '10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ - –∫–∞–∂–¥–∞—è –≥—Ä—É–ø–ø–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 10% –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö',
            'num_groups': len(groups),
            'groups': [],
            'category_to_group_mapping': {},
            'visualization': {
                'color_scheme': 'gradient_green_to_red',
                'group_colors': {}
            },
            'summary_statistics': {
                'total_examples': int(sum(g['total_count'] for g in groups)),
                'total_categories': int(sum(len(g['categories']) for g in groups)),
                'average_group_size': float(np.mean([g['total_count'] for g in groups])),
                'std_group_size': float(np.std([g['total_count'] for g in groups]))
            }
        }
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
        for i, group in enumerate(groups):
            group_id = f'G{i+1}'
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –∫–ª–∞—Å—Å —Å–∏–ª—ã
            strength_composition = {}
            for cat in group['categories']:
                for stat in ordered_stats:
                    if stat['category'] == cat:
                        strength_class = stat['strength_class']
                        strength_name = self.strength_names[strength_class]
                        if strength_name not in strength_composition:
                            strength_composition[strength_name] = 0
                        strength_composition[strength_name] += int(stat['count'])  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int
                        break
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
            sorted_strengths = sorted(strength_composition.items(), key=lambda x: x[1], reverse=True)
            dominant_strength = sorted_strengths[0][0] if sorted_strengths else 'Unknown'
            
            # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π —Å–æ—Å—Ç–∞–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã
            total_in_group = sum(strength_composition.values())
            strength_percentages = {
                name: count / total_in_group * 100 
                for name, count in strength_composition.items()
            } if total_in_group > 0 else {}
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –∏–Ω–¥–µ–∫—Å—ã –≤ int
            indices_list = [int(idx) for idx in group['indices']]
            
            group_info = {
                'group_id': group_id,
                'group_index': i,
                'color': group_colors[i] if i < len(group_colors) else '#808080',
                'total_examples': int(group['total_count']),
                'percentage_of_data': float(group['percentage']),
                'num_categories': len(group['categories']),
                'categories': group['categories'],
                'index_range': {
                    'min': int(min(indices_list)),
                    'max': int(max(indices_list)),
                    'span': int(max(indices_list) - min(indices_list) + 1)
                },
                'strength_composition': {
                    'counts': {k: int(v) for k, v in strength_composition.items()},
                    'percentages': {k: round(float(v), 1) for k, v in strength_percentages.items()},
                    'dominant': dominant_strength
                },
                'average_strength_index': float(np.mean(indices_list)),
                'description': self._generate_group_description(i, group, dominant_strength)
            }
            
            config_10pct['groups'].append(group_info)
            
            # –ú–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∫ –≥—Ä—É–ø–ø–∞–º
            for cat in group['categories']:
                config_10pct['category_to_group_mapping'][cat] = {
                    'group_id': group_id,
                    'group_index': i,
                    'group_color': group_colors[i] if i < len(group_colors) else '#808080'
                }
            
            # –¶–≤–µ—Ç–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            config_10pct['visualization']['group_colors'][group_id] = group_colors[i] if i < len(group_colors) else '#808080'
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
        config_10pct['usage_recommendations'] = {
            'ordinal_regression': {
                'suitable': True,
                'reason': '–ì—Ä—É–ø–ø—ã —É–ø–æ—Ä—è–¥–æ—á–µ–Ω—ã –ø–æ —Å–∏–ª–µ —Ä—É–∫ –æ—Ç —Å–∏–ª—å–Ω–µ–π—à–∏—Ö –∫ —Å–ª–∞–±–µ–π—à–∏–º',
                'target_encoding': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ group_index –∫–∞–∫ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (0-9)'
            },
            'classification': {
                'suitable': True,
                'multiclass': True,
                'num_classes': len(groups),
                'class_balance': '–ü—Ä–∏–º–µ—Ä–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã (~10% –∫–∞–∂–¥—ã–π)'
            },
            'feature_importance': '–ì—Ä—É–ø–ø—ã –æ—Ç—Ä–∞–∂–∞—é—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–µ—Ä–∞—Ä—Ö–∏—é —Å–∏–ª—ã –ø–æ–∫–µ—Ä–Ω—ã—Ö —Ä—É–∫'
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        config_10pct_filename = f'hm3_10percent_grouping_{timestamp}.json'
        with open(config_10pct_filename, 'w', encoding='utf-8') as f:
            json.dump(config_10pct, f, indent=2, ensure_ascii=False)
        
        print(f"üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_10pct_filename}")
        
        # –°–æ–∑–¥–∞–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        simple_mapping = {
            'description': '10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ HM3 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏',
            'mapping': {}
        }
        
        for cat, info in config_10pct['category_to_group_mapping'].items():
            simple_mapping['mapping'][cat] = info['group_index']
        
        simple_filename = f'hm3_10pct_simple_mapping_{timestamp}.json'
        with open(simple_filename, 'w', encoding='utf-8') as f:
            json.dump(simple_mapping, f, indent=2, ensure_ascii=False)
        
        print(f"üéØ –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {simple_filename}")
        
        return config_10pct_filename, simple_filename

    def _generate_group_description(self, group_index, group, dominant_strength):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø—ã
        """
        descriptions = [
            "–°–∏–ª—å–Ω–µ–π—à–∏–µ —Ä—É–∫–∏ - –ø—Ä–µ–º–∏—É–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏",
            "–û—á–µ–Ω—å —Å–∏–ª—å–Ω—ã–µ —Ä—É–∫–∏ - –Ω–∞—Ç—Å—ã –∏ –æ–∫–æ–ª–æ–Ω–∞—Ç—Å–æ–≤—ã–µ",
            "–°–∏–ª—å–Ω—ã–µ —Ä—É–∫–∏ - —Ö–æ—Ä–æ—à–∏–µ –≥–æ—Ç–æ–≤—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏",
            "–°–∏–ª—å–Ω—ã–µ/—Å—Ä–µ–¥–Ω–∏–µ —Ä—É–∫–∏ - –º–∏–∫—Å —Å–∏–ª—å–Ω—ã—Ö –∏ —Å—Ä–µ–¥–Ω–∏—Ö",
            "–°—Ä–µ–¥–Ω–∏–µ —Ä—É–∫–∏ - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏",
            "–°—Ä–µ–¥–Ω–∏–µ/—Å–ª–∞–±—ã–µ —Ä—É–∫–∏ - –º–∏–∫—Å —Å—Ä–µ–¥–Ω–∏—Ö –∏ —Å–ª–∞–±—ã—Ö",
            "–°–ª–∞–±—ã–µ —Ä—É–∫–∏ - –º–∞—Ä–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏",
            "–°–ª–∞–±—ã–µ —Ä—É–∫–∏ –∏ —Å–∏–ª—å–Ω—ã–µ –¥—Ä–æ",
            "–û—á–µ–Ω—å —Å–ª–∞–±—ã–µ —Ä—É–∫–∏ –∏ –¥—Ä–æ",
            "–ú—É—Å–æ—Ä - —Å–ª–∞–±–µ–π—à–∏–µ —Ä—É–∫–∏ –∏ —Å–ª–∞–±—ã–µ –¥—Ä–æ"
        ]
        
        if group_index < len(descriptions):
            return f"{descriptions[group_index]} (–¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç: {dominant_strength})"
        else:
            return f"–ì—Ä—É–ø–ø–∞ {group_index + 1} (–¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç: {dominant_strength})"    
    
    
    # 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    def visualize_10percent_grouping(self, groups, ordered_stats):
        """
        –°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏
        """
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—É—é —Å—Ö–µ–º—É –¥–ª—è 10 –≥—Ä—É–ø–ø (–æ—Ç —Å–∏–ª—å–Ω—ã—Ö –∫ —Å–ª–∞–±—ã–º)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç –æ—Ç –∑–µ–ª–µ–Ω–æ–≥–æ (—Å–∏–ª—å–Ω—ã–µ) –∫ –∫—Ä–∞—Å–Ω–æ–º—É (—Å–ª–∞–±—ã–µ)
        group_colors = [
            '#006400',  # G1 - –¢–µ–º–Ω–æ-–∑–µ–ª–µ–Ω—ã–π (—Å–∏–ª—å–Ω–µ–π—à–∏–µ)
            '#228B22',  # G2 - –õ–µ—Å–Ω–æ–π –∑–µ–ª–µ–Ω—ã–π
            '#32CD32',  # G3 - –õ–∞–π–º–æ–≤—ã–π
            '#7CFC00',  # G4 - –ó–µ–ª–µ–Ω—ã–π –≥–∞–∑–æ–Ω
            '#ADFF2F',  # G5 - –ñ–µ–ª—Ç–æ-–∑–µ–ª–µ–Ω—ã–π
            '#FFD700',  # G6 - –ó–æ–ª–æ—Ç–æ–π
            '#FFA500',  # G7 - –û—Ä–∞–Ω–∂–µ–≤—ã–π
            '#FF8C00',  # G8 - –¢–µ–º–Ω–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π
            '#FF6347',  # G9 - –¢–æ–º–∞—Ç–Ω—ã–π
            '#DC143C'   # G10 - –ú–∞–ª–∏–Ω–æ–≤—ã–π (—Å–ª–∞–±–µ–π—à–∏–µ)
        ]
        
        plt.figure(figsize=(20, 12))
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥—Ä—É–ø–ø–∞—Ö
        ax1 = plt.subplot(2, 3, 1)
        
        group_sizes = [g['total_count'] for g in groups]
        group_labels = [f"G{i+1}" for i in range(len(groups))]
        
        bars = ax1.bar(range(len(groups)), group_sizes, color=group_colors[:len(groups)])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–∞ –∫–∞–∂–¥—ã–π —Å—Ç–æ–ª–±–µ—Ü
        for i, (bar, group) in enumerate(zip(bars, groups)):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{group["percentage"]:.1f}%',
                    ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        ax1.set_xticks(range(len(groups)))
        ax1.set_xticklabels(group_labels, fontsize=12, fontweight='bold')
        ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤', fontsize=12)
        ax1.set_title('10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞: —Ä–∞–∑–º–µ—Ä—ã –≥—Ä—É–ø–ø', fontsize=14, fontweight='bold')
        ax1.grid(axis='y', alpha=0.3)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –ª–∏–Ω–∏—é –¥–ª—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ 10%
        ideal_size = sum(group_sizes) * 0.1
        ax1.axhline(y=ideal_size, color='red', linestyle='--', alpha=0.5, label='–ò–¥–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (10%)')
        ax1.legend()
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: –°–æ—Å—Ç–∞–≤ –≥—Ä—É–ø–ø –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã (—É–ª—É—á—à–µ–Ω–Ω—ã–π)
        ax2 = plt.subplot(2, 3, 2)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ—Å—Ç–∞–≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã
        group_compositions = []
        for group in groups:
            composition = [0] * 5  # 5 –∫–ª–∞—Å—Å–æ–≤ —Å–∏–ª—ã
            
            for cat in group['categories']:
                for stat in ordered_stats:
                    if stat['category'] == cat:
                        composition[stat['strength_class']] += stat['count']
                        break
            
            group_compositions.append(composition)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        group_compositions_pct = []
        for comp in group_compositions:
            total = sum(comp)
            if total > 0:
                comp_pct = [c/total * 100 for c in comp]
            else:
                comp_pct = [0] * 5
            group_compositions_pct.append(comp_pct)
        
        # –°—Ç–µ–∫–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        bottom = np.zeros(len(groups))
        strength_colors = {
            4: '#006400',  # –ú–æ–Ω—Å—Ç—Ä—ã - —Ç–µ–º–Ω–æ-–∑–µ–ª–µ–Ω—ã–π
            3: '#32CD32',  # –°–∏–ª—å–Ω—ã–µ - —è—Ä–∫–æ-–∑–µ–ª–µ–Ω—ã–π
            2: '#FFD700',  # –°—Ä–µ–¥–Ω–∏–µ - –∑–æ–ª–æ—Ç–æ–π
            1: '#FFA500',  # –°–ª–∞–±—ã–µ - –æ—Ä–∞–Ω–∂–µ–≤—ã–π
            0: '#DC143C'   # –ú—É—Å–æ—Ä - –∫—Ä–∞—Å–Ω—ã–π
        }
        
        for strength_class in range(5):
            values = [comp[strength_class] for comp in group_compositions_pct]
            ax2.bar(range(len(groups)), values, bottom=bottom, 
                    color=strength_colors[strength_class], 
                    label=f'–ö–ª–∞—Å—Å {strength_class}: {self.strength_names[strength_class]}',
                    edgecolor='white', linewidth=0.5)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è –∑–Ω–∞—á–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            for i, val in enumerate(values):
                if val > 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±–æ–ª—å—à–µ 5%
                    ax2.text(i, bottom[i] + val/2, f'{val:.0f}%', 
                            ha='center', va='center', fontsize=9, fontweight='bold')
            
            bottom += values
        
        ax2.set_xticks(range(len(groups)))
        ax2.set_xticklabels([f"G{i+1}" for i in range(len(groups))], fontsize=12, fontweight='bold')
        ax2.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ—Å—Ç–∞–≤–∞', fontsize=12)
        ax2.set_title('–°–æ—Å—Ç–∞–≤ –≥—Ä—É–ø–ø –ø–æ –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—ã', fontsize=14, fontweight='bold')
        ax2.legend(loc='upper left', bbox_to_anchor=(1, 1))
        ax2.set_ylim(0, 100)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
        ax3 = plt.subplot(2, 3, 3)
        ax3.axis('off')
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        table_data = []
        for i, group in enumerate(groups):
            strength_classes = sorted(list(group['strength_classes']))
            dominant_class = max(set(strength_classes), key=strength_classes.count) if strength_classes else 0
            
            table_data.append([
                f'G{i+1}',
                f'{group["percentage"]:.1f}%',
                f'{len(group["categories"])}',
                f'{group["total_count"]:,}',
                self.strength_names[dominant_class]
            ])
        
        table = ax3.table(cellText=table_data,
                        colLabels=['–ì—Ä—É–ø–ø–∞', '% –¥–∞–Ω–Ω—ã—Ö', '–ö–∞—Ç–µ–≥–æ—Ä–∏–π', '–ü—Ä–∏–º–µ—Ä–æ–≤', '–î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –∫–ª–∞—Å—Å'],
                        cellLoc='center',
                        loc='center',
                        colColours=['lightgray']*5)
        
        table.auto_set_font_size(False)
        table.set_fontsize(11)
        table.scale(1.2, 1.5)
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º —è—á–µ–π–∫–∏ –≥—Ä—É–ø–ø
        for i in range(len(groups)):
            table[(i+1, 0)].set_facecolor(group_colors[i])
            table[(i+1, 0)].set_text_props(weight='bold', color='white')
        
        ax3.set_title('–°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≥—Ä—É–ø–ø–∞–º', fontsize=14, fontweight='bold', pad=20)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: –ü—Ä–∏–º–µ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
        ax4 = plt.subplot(2, 3, 4)
        
        y_positions = []
        for i, group in enumerate(groups):
            y_pos = len(groups) - i - 1
            y_positions.append(y_pos)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            sample_cats = group['categories'][:3]
            if len(group['categories']) > 3:
                text = f"G{i+1}: {', '.join(sample_cats)}..."
            else:
                text = f"G{i+1}: {', '.join(sample_cats)}"
            
            ax4.text(0.05, y_pos, text, fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor=group_colors[i], alpha=0.7),
                    color='white' if i < 3 else 'black', fontweight='bold')
        
        ax4.set_xlim(0, 1)
        ax4.set_ylim(-0.5, len(groups) - 0.5)
        ax4.axis('off')
        ax4.set_title('–ü—Ä–∏–º–µ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –≥—Ä—É–ø–ø–∞—Ö', fontsize=14, fontweight='bold')
        
        # –ì—Ä–∞—Ñ–∏–∫ 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã –ø–æ –≥—Ä—É–ø–ø–∞–º
        ax5 = plt.subplot(2, 3, 5)
        
        # –î–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π –∏–Ω–¥–µ–∫—Å —Å–∏–ª—ã
        avg_indices = []
        for group in groups:
            if group['indices']:
                avg_idx = np.mean(group['indices'])
                avg_indices.append(avg_idx)
            else:
                avg_indices.append(0)
        
        ax5.plot(range(len(groups)), avg_indices, 'ko-', linewidth=2, markersize=10)
        
        # –†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ—á–∫–∏
        for i, (x, y) in enumerate(zip(range(len(groups)), avg_indices)):
            ax5.plot(x, y, 'o', color=group_colors[i], markersize=12)
        
        ax5.set_xticks(range(len(groups)))
        ax5.set_xticklabels([f"G{i+1}" for i in range(len(groups))], fontsize=12, fontweight='bold')
        ax5.set_ylabel('–°—Ä–µ–¥–Ω–∏–π –∏–Ω–¥–µ–∫—Å —Å–∏–ª—ã', fontsize=12)
        ax5.set_title('–¢—Ä–µ–Ω–¥ —Å–∏–ª—ã –ø–æ –≥—Ä—É–ø–ø–∞–º', fontsize=14, fontweight='bold')
        ax5.grid(True, alpha=0.3)
        ax5.invert_yaxis()  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º, —á—Ç–æ–±—ã —Å–∏–ª—å–Ω—ã–µ –±—ã–ª–∏ –≤–≤–µ—Ä—Ö—É
        
        # –ì—Ä–∞—Ñ–∏–∫ 6: –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –¥–∏–∑–∞–π–Ω–æ–º
        ax6 = plt.subplot(2, 3, 6)
        
        percentages = [g['percentage'] for g in groups]
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–ª–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –¥–∏–∞–≥—Ä–∞–º–º—É
        explode = [0.05 if p > 12 else 0.02 for p in percentages]  # –í—ã–¥–µ–ª—è–µ–º –±–æ–ª—å—à–∏–µ –≥—Ä—É–ø–ø—ã
        
        wedges, texts, autotexts = ax6.pie(percentages, 
                                        labels=[f"G{i+1}" for i in range(len(groups))],
                                        colors=group_colors[:len(groups)],
                                        autopct=lambda pct: f'{pct:.1f}%' if pct > 5 else '',
                                        startangle=90,
                                        explode=explode,
                                        shadow=True)
        
        # –£–ª—É—á—à–∞–µ–º —Ç–µ–∫—Å—Ç
        for text in texts:
            text.set_fontsize(11)
            text.set_fontweight('bold')
        
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontsize(10)
            autotext.set_fontweight('bold')
        
        ax6.set_title('–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø', fontsize=14, fontweight='bold')
        
        # –û–±—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
        plt.suptitle('–ê–Ω–∞–ª–∏–∑ 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ HM3 –∫–∞—Ç–µ–≥–æ—Ä–∏–π', fontsize=16, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('hm3_10percent_grouping_improved.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"üìä –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: hm3_10percent_grouping_improved.png")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        print("\nüìã –°–í–û–î–ö–ê –ü–û 10% –ì–†–£–ü–ü–ò–†–û–í–ö–ï:")
        print("=" * 80)
        for i, group in enumerate(groups):
            strength_desc = ", ".join([f"{self.strength_names[s]}" for s in sorted(group['strength_classes'])])
            print(f"\nüéØ –ì—Ä—É–ø–ø–∞ {i+1} (G{i+1}) - {group['percentage']:.1f}% –¥–∞–Ω–Ω—ã—Ö:")
            print(f"   –¶–≤–µ—Ç: {group_colors[i]}")
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(group['categories'])}")
            print(f"   –ü—Ä–∏–º–µ—Ä–æ–≤: {group['total_count']:,}")
            print(f"   –ò–Ω–¥–µ–∫—Å—ã: {min(group['indices'])}-{max(group['indices'])}")
            print(f"   –ö–ª–∞—Å—Å—ã —Å–∏–ª—ã: {strength_desc}")
        print("=" * 80)
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ _save_results
    def _save_results(self, analysis_results, grouping_proposals):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π —Ç–∏–ø–æ–≤"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ numpy/pandas —Ç–∏–ø–æ–≤
        def convert_to_serializable(obj):
            if isinstance(obj, (np.integer, np.int64, np.int32)):
                return int(obj)
            elif isinstance(obj, (np.floating, np.float64, np.float32)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, pd.Series):
                return obj.tolist()
            elif isinstance(obj, set):
                return list(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(item) for item in obj]
            elif isinstance(obj, tuple):
                return list(obj)
            else:
                return obj
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è JSON —Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π
        json_results = {
            'timestamp': timestamp,
            'summary': {
                'total_hands': int(analysis_results['total_hands']),
                'categories_found': len(analysis_results['ordered_stats']),
                'categories_missing': len(analysis_results['missing_categories']),
                'balance_metrics': convert_to_serializable(analysis_results['balance_metrics']),
                'problems_summary': {
                    'rare_categories': len(analysis_results['problems']['rare']),
                    'scarce_categories': len(analysis_results['problems']['scarce']),
                    'gaps_count': len(analysis_results['problems']['gaps'])
                }
            },
            'strength_distribution': convert_to_serializable(analysis_results['strength_distribution']),
            'ordered_statistics': [
                convert_to_serializable({
                    'index': s['index'],
                    'category': s['category'],
                    'count': s['count'],
                    'percentage': s['percentage'],
                    'strength_class': s['strength_class'],
                    'cumulative_percentage': s['cumulative_percentage']
                })
                for s in analysis_results['ordered_stats']
            ],
            'grouping_proposals': convert_to_serializable(grouping_proposals)
        }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON
        json_filename = f'hm3_ordinal_analysis_{timestamp}.json'
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"   üìä –ì—Ä–∞—Ñ–∏–∫–∏: hm3_ordinal_analysis.png")
        print(f"   üìã –î–∞–Ω–Ω—ã–µ: {json_filename}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
        best_strategy = self._recommend_best_strategy(grouping_proposals, analysis_results['ordered_stats'])
        best_groups = grouping_proposals[best_strategy]
        
        grouping_config = {
            'strategy': best_strategy,
            'num_groups': len(best_groups),
            'category_to_group': {},
            'group_info': {}
        }
        
        for i, group in enumerate(best_groups):
            for cat in group['categories']:
                grouping_config['category_to_group'][cat] = i
            
            grouping_config['group_info'][str(i)] = convert_to_serializable({
                'categories': group['categories'],
                'size': len(group['categories']),
                'total_count': group['total_count']
            })
        
        config_filename = f'hm3_grouping_config_{timestamp}.json'
        with open(config_filename, 'w', encoding='utf-8') as f:
            json.dump(grouping_config, f, indent=2, ensure_ascii=False)
        
        print(f"   üéØ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏: {config_filename}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é 10% –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—è –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥
        if '10percent_quantiles' in grouping_proposals:
            groups_10pct = grouping_proposals['10percent_quantiles']
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥
            config_10pct_filename, simple_filename = self.save_10percent_grouping_config(
                groups_10pct, 
                analysis_results['ordered_stats'],
                timestamp
            )

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞ –∏–∑ –ø–∞–ø–∫–∏ data"""
    import argparse
    import glob
    
    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è 73 –∫–ª–∞—Å—Å–æ–≤ HM3')
    parser.add_argument('data_file', nargs='?', help='–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)')
    parser.add_argument('--output-dir', default='.', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--data-dir', default='data', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: data)')
    
    args = parser.parse_args()
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—â–µ–º –≤ –ø–∞–ø–∫–µ data
    if args.data_file and os.path.exists(args.data_file):
        selected_file = args.data_file
    else:
        # –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ data
        data_dir = args.data_dir
        if not os.path.exists(data_dir):
            data_dir = "."
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
        patterns = [
            os.path.join(data_dir, "parsed_*.csv"),
            os.path.join(data_dir, "*poker*.csv"),
            os.path.join(data_dir, "*PDOM*.csv"),
            os.path.join(data_dir, "*.csv")
        ]
        
        data_files = []
        for pattern in patterns:
            files = glob.glob(pattern)
            # –ò—Å–∫–ª—é—á–∞–µ–º —Ñ–∞–π–ª—ã –∏–∑ –ø–æ–¥–ø–∞–ø–∫–∏ combined
            files = [f for f in files if 'combined' not in os.path.dirname(f)]
            data_files.extend(files)
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        data_files = sorted(list(set(data_files)))
        
        if not data_files:
            print(f"‚ùå CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ {data_dir}!")
            return 1
        
        if len(data_files) == 1:
            selected_file = data_files[0]
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {selected_file}")
        else:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏
            print(f"\nüìÅ –ù–∞–π–¥–µ–Ω–æ {len(data_files)} —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {data_dir}:")
            print("=" * 80)
            
            file_info = []
            total_size = 0
            
            for i, file_path in enumerate(data_files):
                size_mb = os.path.getsize(file_path) / 1024 / 1024
                total_size += size_mb
                file_info.append((i, file_path, size_mb))
                
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É (–±–æ–ª—å—à–∏–µ –ø–µ—Ä–≤—ã–º–∏)
            file_info.sort(key=lambda x: x[2], reverse=True)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            for idx, (orig_idx, file_path, size_mb) in enumerate(file_info):
                if idx < 20:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-20
                    print(f"{orig_idx+1:3d}. {os.path.basename(file_path):50s} {size_mb:8.1f} MB")
            
            if len(data_files) > 20:
                print(f"\n... –∏ –µ—â–µ {len(data_files) - 20} —Ñ–∞–π–ª–æ–≤")
            
            print("=" * 80)
            print(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size:.1f} MB")
            print(f"\nüí° –°–æ–≤–µ—Ç: –≤—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö")
            print(f"   –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ 'all' –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤")
            
            # –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞
            while True:
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞ (1-{}) –∏–ª–∏ 'all' –¥–ª—è –≤—Å–µ—Ö: ".format(len(data_files))).strip()
                
                if choice.lower() == 'all':
                    print("\nüîÑ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
                    all_dfs = []
                    total_showdowns = 0
                    
                    for file_path in data_files:
                        try:
                            print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ {os.path.basename(file_path)}...", end='', flush=True)
                            df = pd.read_csv(file_path)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
                            df['source_file'] = os.path.basename(file_path)
                            
                            # –°—á–∏—Ç–∞–µ–º —à–æ—É–¥–∞—É–Ω—ã
                            showdowns = ((df['Showdown_1'].notna()) & (df['Showdown_2'].notna())).sum()
                            total_showdowns += showdowns
                            
                            all_dfs.append(df)
                            print(f" ‚úì ({len(df)} —Å—Ç—Ä–æ–∫, {showdowns} —à–æ—É–¥–∞—É–Ω–æ–≤)")
                            
                        except Exception as e:
                            print(f" ‚úó –û—à–∏–±–∫–∞: {e}")
                    
                    if not all_dfs:
                        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞!")
                        return 1
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                    print(f"\nüîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ {len(all_dfs)} —Ñ–∞–π–ª–æ–≤...")
                    combined_df = pd.concat(all_dfs, ignore_index=True)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    temp_file = f"temp_combined_for_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                    combined_df.to_csv(temp_file, index=False)
                    
                    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {len(combined_df)} —Å—Ç—Ä–æ–∫, {total_showdowns} —à–æ—É–¥–∞—É–Ω–æ–≤")
                    selected_file = temp_file
                    break
                    
                try:
                    idx = int(choice) - 1
                    if 0 <= idx < len(data_files):
                        selected_file = data_files[idx]
                        print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {selected_file}")
                        break
                    else:
                        print(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä. –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ {len(data_files)}")
                except ValueError:
                    print(f"‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–ª–∏ 'all'")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = HM3OrdinalAnalyzer()
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    os.makedirs(args.output_dir, exist_ok=True)
    
    # –ú–µ–Ω—è–µ–º —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    original_dir = os.getcwd()
    os.chdir(args.output_dir)
    
    try:
        # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {os.path.basename(selected_file)}")
        analysis_results, grouping_proposals = analyzer.analyze_data(selected_file)
        
        if analysis_results:
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏")
            print(f"   –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å –æ—Ä–¥–∏–Ω–∞–ª—å–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–µ–π")
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ —Å–æ–∑–¥–∞–≤–∞–ª–∏
            if 'temp_combined_for_analysis' in selected_file:
                os.remove(selected_file)
                print(f"üóëÔ∏è  –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")
            
            return 0
        else:
            print(f"\n‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è")
            return 1
            
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –∏—Å—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        os.chdir(original_dir)


if __name__ == "__main__":
    exit(main())
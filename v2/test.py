#!/usr/bin/env python3
"""
–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
"""

import os
import sys
import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from hand_range_prediction import *
from your_fixed_functions import *  # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

def debug_data_preparation():
    """–û—Ç–ª–∞–¥–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("üîç === –û–¢–õ–ê–î–ö–ê –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–• ===")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª
    data_files = find_data_files()
    if not data_files:
        print("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö!")
        return
    
    data_file = data_files[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª
    print(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª: {data_file}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥
    hm3_mapping_path = 'hm3_10pct_simple_mapping_20250612_072153.json'
    if not os.path.exists(hm3_mapping_path):
        print(f"‚ùå –§–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {hm3_mapping_path}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_csv(data_file)
    print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–∞:")
    print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    print(f"   –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)[:10]}...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —à–æ—É–¥–∞—É–Ω—ã
    showdown_mask = (df['Showdown_1'].notna()) & (df['Showdown_2'].notna())
    print(f"   –ó–∞–ø–∏—Å–µ–π —Å —à–æ—É–¥–∞—É–Ω–æ–º: {showdown_mask.sum()} ({showdown_mask.sum()/len(df)*100:.1f}%)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä—É–∫–∏
    if 'HandID' in df.columns:
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä—É–∫: {df['HandID'].nunique()}")
    elif 'Hand' in df.columns:
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä—É–∫: {df['Hand'].nunique()}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"\nüîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    data_dict = prepare_two_stage_data(data_file, hm3_mapping_path)
    
    if data_dict is None:
        print("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö!")
        return
    
    print(f"\n‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
    print(f"   Train sequences: {len(data_dict['train_sequences'])}")
    print(f"   Val sequences: {len(data_dict['val_sequences'])}")
    print(f"   Test sequences: {len(data_dict['test_sequences'])}")
    print(f"   Feature columns: {len(data_dict['feature_columns'])}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –≥—Ä—É–ø–ø (train):")
    train_targets = data_dict['final_targets']['train']
    unique, counts = np.unique(train_targets, return_counts=True)
    for group, count in zip(unique, counts):
        print(f"   –ì—Ä—É–ø–ø–∞ {group}: {count} ({count/len(train_targets)*100:.1f}%)")
    
    return data_dict


def debug_preflop_model(data_dict):
    """–û—Ç–ª–∞–¥–∫–∞ –ø—Ä–µ—Ñ–ª–æ–ø –º–æ–¥–µ–ª–∏"""
    print("\nüîç === –û–¢–õ–ê–î–ö–ê –ü–†–ï–§–õ–û–ü –ú–û–î–ï–õ–ò ===")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ç–µ—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å
    print(f"\nüß† –°–æ–∑–¥–∞–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –ø—Ä–µ—Ñ–ª–æ–ø –º–æ–¥–µ–ª–∏...")
    
    class SimplePreflopModel(nn.Module):
        def __init__(self, input_dim):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, 64)
            self.fc2 = nn.Linear(64, 169)  # 169 –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö —Ä—É–∫
            self.sigmoid = nn.Sigmoid()
            
        def forward(self, x):
            # –ë–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            x = x.mean(dim=1)
            x = torch.relu(self.fc1(x))
            x = self.sigmoid(self.fc2(x))
            return x
    
    model = SimplePreflopModel(len(data_dict['feature_columns'])).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.MSELoss()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –¥–∞—Ç–∞—Å–µ—Ç
    train_sequences = data_dict['train_sequences']
    
    print(f"üìä –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏...")
    losses = []
    
    for epoch in range(10):
        epoch_losses = []
        
        for i, seq in enumerate(train_sequences[:50]):  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 50 –ø—Ä–∏–º–µ—Ä–æ–≤
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            available_cols = [col for col in data_dict['feature_columns'] if col in seq.columns]
            if not available_cols:
                continue
                
            features = seq[available_cols].fillna(0).values
            if len(features) == 0:
                continue
                
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            features = data_dict['scaler'].transform(features)
            features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)
            
            # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é —Ü–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
            target = torch.rand(1, 169).to(device)
            target = target / target.sum(dim=1, keepdim=True)
            
            # Forward pass
            optimizer.zero_grad()
            output = model(features_tensor)
            loss = criterion(output, target)
            
            # Backward pass
            loss.backward()
            optimizer.step()
            
            epoch_losses.append(loss.item())
        
        avg_loss = np.mean(epoch_losses) if epoch_losses else 0
        losses.append(avg_loss)
        print(f"   –≠–ø–æ—Ö–∞ {epoch+1}/10: Loss = {avg_loss:.4f}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plt.figure(figsize=(8, 5))
    plt.plot(losses)
    plt.title('–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å: Loss –ø–æ —ç–ø–æ—Ö–∞–º')
    plt.xlabel('–≠–ø–æ—Ö–∞')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.show()
    
    print(f"\n‚úÖ –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
    return model


def debug_final_model(data_dict):
    """–û—Ç–ª–∞–¥–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print("\nüîç === –û–¢–õ–ê–î–ö–ê –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    train_targets = data_dict['final_targets']['train']
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö:")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(train_targets)}")
    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {np.unique(train_targets)}")
    print(f"   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {type(train_targets[0]) if train_targets else 'N/A'}")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –¥–∞—Ç–∞—Å–µ—Ç
    from torch.utils.data import TensorDataset
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 100 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    sample_sequences = data_dict['train_sequences'][:100]
    sample_targets = train_targets[:100]
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    X = []
    y = []
    
    for i, seq in enumerate(sample_sequences):
        if i >= len(sample_targets):
            break
            
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        last_row_features = []
        for col in data_dict['feature_columns']:
            if col in seq.columns:
                val = seq[col].iloc[-1] if len(seq) > 0 else 0
                last_row_features.append(val if pd.notna(val) else 0)
            else:
                last_row_features.append(0)
        
        X.append(last_row_features)
        y.append(sample_targets[i])
    
    X = np.array(X, dtype=np.float32)
    y = np.array(y, dtype=np.int64)
    
    print(f"\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"   X shape: {X.shape}")
    print(f"   y shape: {y.shape}")
    print(f"   y —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ: {np.unique(y)}")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    X = data_dict['scaler'].transform(X)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    class SimpleClassifier(nn.Module):
        def __init__(self, input_dim, num_classes=10):
            super().__init__()
            self.fc1 = nn.Linear(input_dim, 64)
            self.fc2 = nn.Linear(64, 32)
            self.fc3 = nn.Linear(32, num_classes)
            self.dropout = nn.Dropout(0.2)
            
        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = self.dropout(x)
            x = torch.relu(self.fc2(x))
            x = self.dropout(x)
            x = self.fc3(x)
            return x
    
    model = SimpleClassifier(X.shape[1]).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.CrossEntropyLoss()
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã
    X_tensor = torch.tensor(X).to(device)
    y_tensor = torch.tensor(y).to(device)
    
    # –û–±—É—á–µ–Ω–∏–µ
    print(f"\nüß† –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
    losses = []
    accuracies = []
    
    for epoch in range(20):
        model.train()
        optimizer.zero_grad()
        
        outputs = model(X_tensor)
        loss = criterion(outputs, y_tensor)
        
        loss.backward()
        optimizer.step()
        
        # –¢–æ—á–Ω–æ—Å—Ç—å
        _, predicted = torch.max(outputs, 1)
        accuracy = (predicted == y_tensor).float().mean().item()
        
        losses.append(loss.item())
        accuracies.append(accuracy)
        
        if epoch % 5 == 0:
            print(f"   –≠–ø–æ—Ö–∞ {epoch+1}/20: Loss = {loss.item():.4f}, Accuracy = {accuracy:.3f}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    ax1.plot(losses)
    ax1.set_title('Loss –ø–æ —ç–ø–æ—Ö–∞–º')
    ax1.set_xlabel('–≠–ø–æ—Ö–∞')
    ax1.set_ylabel('Loss')
    ax1.grid(True)
    
    ax2.plot(accuracies)
    ax2.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ —ç–ø–æ—Ö–∞–º')
    ax2.set_xlabel('–≠–ø–æ—Ö–∞')
    ax2.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()
    
    print(f"\n‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    print(f"   –§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracies[-1]:.3f}")
    
    return model


def main_debug():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–ª–∞–¥–∫–∏"""
    print("üîç === –û–¢–õ–ê–î–ö–ê –î–í–£–•–≠–¢–ê–ü–ù–û–ô –°–ò–°–¢–ï–ú–´ ===\n")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏
    setup_directories()
    
    # 1. –û—Ç–ª–∞–¥–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    data_dict = debug_data_preparation()
    if data_dict is None:
        return
    
    # 2. –û—Ç–ª–∞–¥–∫–∞ –ø—Ä–µ—Ñ–ª–æ–ø –º–æ–¥–µ–ª–∏
    preflop_model = debug_preflop_model(data_dict)
    
    # 3. –û—Ç–ª–∞–¥–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    final_model = debug_final_model(data_dict)
    
    print("\n‚úÖ –û—Ç–ª–∞–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üìä –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (–º–∞–ª–æ —à–æ—É–¥–∞—É–Ω–æ–≤)")
    print("   2. –£–≤–µ–ª–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö (–æ–±—ä–µ–¥–∏–Ω–∏—Ç–µ —Ñ–∞–π–ª—ã)")
    print("   3. –£–ø—Ä–æ—Å—Ç–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–µ–π")
    print("   4. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞—Ä—Ç")


if __name__ == "__main__":
    main_debug()